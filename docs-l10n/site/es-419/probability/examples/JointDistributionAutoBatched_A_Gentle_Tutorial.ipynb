{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3puWgvKeyWu"
      },
      "source": [
        "# Distribuciones conjuntas mediante procesamiento automático por lotes: un sencillo tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrwVQsM9TiUw"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CpDUTVKYTowI"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltPJCG6pAUoc"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzaOJSXagzMY"
      },
      "source": [
        "### Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIvB2CSBe49Z"
      },
      "source": [
        "TensorFlow Probability (TFP) ofrece una serie de abstracciones `JointDistribution` que facilitan la inferencia probabilística al permitir al usuario expresar fácilmente un modelo gráfico probabilístico en una forma casi matemática; la abstracción genera métodos para tomar muestras del modelo y evaluar la probabilidad logarítmica de las muestras del modelo. En este tutorial, revisamos variantes de \"procesamiento automático por lotes\", que se desarrollaron después de las abstracciones originales `JointDistribution`. En comparación con las abstracciones originales, sin procesamiento automático por lotes, las versiones con procesamiento automático por lotes son más sencillas de usar y más ergonómicas, lo que permite expresar muchos modelos con menos texto repetitivo. En esta colaboración, exploramos un modelo simple con (quizás tedioso) detalle, dejando en claro los problemas que resuelve el procesamiento automático por lotes y (con suerte) enseñando al lector más sobre los conceptos de forma de TFP a lo largo del camino.\n",
        "\n",
        "Antes de la introducción del procesamiento automático por lotes, existían algunas variantes diferentes de `JointDistribution`, correspondientes a diferentes estilos sintácticos para expresar modelos probabilísticos: `JointDistributionSequential`, `JointDistributionNamed` y `JointDistributionCoroutine`. El procesamiento automático por lotes existe como un mixin, por lo que ahora tenemos variantes `AutoBatched` de todos estos. En este tutorial, exploramos las diferencias entre `JointDistributionSequential` y `JointDistributionSequentialAutoBatched`; sin embargo, todo lo que hacemos aquí se puede aplicar a las otras variantes esencialmente sin cambios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiR4-VOt9NFX"
      },
      "source": [
        "### Dependencias y requisitos previos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coUnDhkpT5_6"
      },
      "outputs": [],
      "source": [
        "#@title Import and set ups{ display-mode: \"form\" }\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfd = tfp.distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KohBmaTn5W7I"
      },
      "source": [
        "### Requisito previo: un problema de regresión bayesiana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vChyK0vr9XD8"
      },
      "source": [
        "Veamos un ejemplo sencillo de regresión bayesiana:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "m & \\sim \\text{Normal}(0, 1) \\\\\n",
        "b & \\sim \\text{Normal}(0, 1) \\\\\n",
        "Y & \\sim \\text{Normal}(mX + b, 1)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "En este modelo, `m` y `b` se extraen de normales estándar, y las observaciones `Y` se extraen de una distribución normal cuya media depende de las variables aleatorias `m` y `b` de algunas covariables (no aleatorias) `X` (Para simplificar, en este ejemplo asumimos que se conoce la escala de todas las variables aleatorias).\n",
        "\n",
        "Para realizar inferencias en este modelo, necesitaríamos conocer las covariables `X` y las observaciones `Y`, pero para los fines de este tutorial, solo necesitaremos `X`, por lo que definimos una `X` ficticia simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIpJ_cXUVabB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.arange(7)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIBpupyt9GTT"
      },
      "source": [
        "### Desiderata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uzL_uI9tqO"
      },
      "source": [
        "En la inferencia probabilística, a menudo queremos realizar dos operaciones básicas:\n",
        "\n",
        "- `sample`: extraer muestras del modelo.\n",
        "- `log_prob`: calcular la probabilidad logarítmica de una muestra del modelo.\n",
        "\n",
        "La contribución clave de las abstracciones `JointDistribution` de TFP (así como de muchos otros enfoques de programación probabilística) es que permite a los usuarios escribir un modelo *una vez* y acceder a cálculos `sample` y `log_prob`.\n",
        "\n",
        "Teniendo en cuenta que tenemos 7 puntos en nuestro conjunto de datos (`X.shape = (7,)`), ahora podemos establecer los desiderata para una excelente `JointDistribution`:\n",
        "\n",
        "- `sample()` debería producir una lista de `Tensors` que tienen forma `[(), (), (7,)`], correspondientes a la pendiente escalar, el sesgo escalar y las observaciones vectoriales, respectivamente.\n",
        "- `log_prob(sample())` debería producir un escalar: la probabilidad logarítmica de una pendiente, sesgo y observaciones particulares.\n",
        "- `sample([5, 3])` debería producir una lista de `Tensors` que tengan forma `[(5, 3), (5, 3), (5, 3, 7)]`, representando un `(5, 3)` - *lote* de muestras del modelo.\n",
        "- `log_prob(sample([5, 3]))` debería producir un `Tensor` con forma (5, 3).\n",
        "\n",
        "Ahora veremos una sucesión de modelos `JointDistribution`, veremos cómo alcanzar los desiderata anteriores y, con suerte, aprenderemos un poco más sobre las formas de TFP a lo largo del proceso.\n",
        "\n",
        "Alerta de spoiler: el enfoque que satisface los desiderata anteriores sin agregar elementos repetitivos es el [procesamiento automático por lotes](#scrollTo=_h7sJ2bkfOS7). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiII0ypZcyTY"
      },
      "source": [
        "### Primer intento; `JointDistributionSequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY501q-QVR9g"
      },
      "outputs": [],
      "source": [
        "jds = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzNPPqJ-BwA-"
      },
      "source": [
        "Esto es prácticamente una traducción directa del modelo al código. La pendiente `m` y el sesgo `b` son sencillos. `Y` se define con una función `lambda`: el patrón general es que una función `lambda` de $k$ argumentos en un `JointDistributionSequential` (JDS) utiliza las distribuciones $k$ anteriores en el modelo. Nótese que el orden es \"inverso\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIvsQSOD81N"
      },
      "source": [
        "Llamaremos `sample_distributions`, que devuelve tanto una muestra *como* las \"subdistribuciones\" subyacentes que se utilizaron para generar la muestra. (Podríamos haber producido solo la muestra llamando a `sample`; más adelante en el tutorial será conveniente tener también las distribuciones). La muestra que se produjo está bien:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y05IrsfiaxCh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-1.668757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.6585061>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([ 0.18573815, -1.79962   , -1.8106272 , -3.5971394 , -6.6625295 ,\n",
              "        -7.308844  , -9.832693  ], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists, sample = jds.sample_distributions()\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7E1WkoCEB12"
      },
      "source": [
        "Pero `log_prob` produce un resultado con una forma no deseada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR0lbgjNay4X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              "array([-4.4777603, -4.6775575, -4.7430477, -4.647725 , -4.5746684,\n",
              "       -4.4368567, -4.480562 ], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mMIs28LEJqN"
      },
      "source": [
        "Y la multiplicidad de muestras no funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbfRiIsfc9Hf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  jds.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnvtz3SQHrVL"
      },
      "source": [
        "Intentemos entender qué está pasando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp30JPCmHyuz"
      },
      "source": [
        "### Una breve reseña: forma de lote y de evento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w24fZn3kH2uF"
      },
      "source": [
        "En TFP, una distribución de probabilidad ordinaria (no una `JointDistribution`) tiene una *forma de evento* y una *forma de lote*, y comprender la diferencia es crucial para usar TFP de forma eficiente:\n",
        "\n",
        "- La forma de evento describe la forma de una única extracción de la distribución; la extracción puede depender de todas las dimensiones. Para distribuciones escalares, la forma de evento es []. Para una MultivariateNormal de 5 dimensiones, la forma de evento es [5].\n",
        "- La forma de lote describe extracciones independientes, no distribuidas de manera idéntica, también conocida como \"lote\" de distribuciones. Representar un lote de distribuciones en un único objeto Python es una de las formas clave en que TFP logra eficiencia a escala.\n",
        "\n",
        "Para nuestros propósitos, un hecho crítico a tener en cuenta es que si llamamos `log_prob` en una sola muestra de una distribución, el resultado siempre tendrá una forma que coincida (es decir, que tiene como dimensiones más a la derecha) la forma de *lote*.\n",
        "\n",
        "Para obtener una descripción más detallada de las formas, consulte el [tutorial \"Explicación de las formas de distribuciones de TensorFlow\"](https://www.tensorflow.org/probability/examples/Understanding_TensorFlow_Distributions_Shapes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONZMjl-KtTz"
      },
      "source": [
        "### ¿Por qué `log_prob(sample())` no produce un escalar? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUKyGzkOJiuD"
      },
      "source": [
        "Usemos nuestro conocimiento sobre la forma de lote y de evento para explorar qué está sucediendo con `log_prob(sample())`. Aquí está nuestra muestra nuevamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijRGAnSBJwCG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-1.668757>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.6585061>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([ 0.18573815, -1.79962   , -1.8106272 , -3.5971394 , -6.6625295 ,\n",
              "        -7.308844  , -9.832693  ], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAzBAsu3OoLv"
      },
      "source": [
        "Y aquí están nuestras distribuciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xtIUKf8Nq3G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
              " <tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
              " <tfp.distributions.Normal 'JointDistributionSequential_sample_distributions_Normal' batch_shape=[7] event_shape=[] dtype=float32>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkLnoZyFeU_"
      },
      "source": [
        "La probabilidad logarítmica se calcula mediante la suma de las probabilidades logarítmicas de las subdistribuciones en los elementos (coincidentes) de las partes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XTDKVMPO5qg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=-2.3113134>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=-1.1357536>,\n",
              " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
              " array([-1.0306933, -1.2304904, -1.2959809, -1.200658 , -1.1276014,\n",
              "        -0.9897899, -1.0334952], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_prob_parts = [dist.log_prob(s) for (dist, s) in zip(dists, sample)]\n",
        "log_prob_parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoWsVGx8N1IJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(log_prob_parts) - jds.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJFvR4ZNFngd"
      },
      "source": [
        "Entonces, un nivel de explicación es que el cálculo de probabilidad logarítmica devuelve un tensor 7 porque el tercer subcomponente de `log_prob_parts` es un tensor 7. ¿Pero por qué?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdpKnguOPOrr"
      },
      "source": [
        "Bueno, vemos que el último elemento de `dists`, que corresponde a nuestra distribución sobre `Y` en la formulación matemática, tiene una `batch_shape` de `[7]`. En otras palabras, nuestra distribución sobre `Y` es un lote de 7 normales independientes (con medias diferentes y, en este caso, la misma escala)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WXzlR_diTuZ"
      },
      "source": [
        "Ahora entendemos lo que está mal: en JDS, la distribución sobre `Y` tiene `batch_shape=[7]`, una muestra de JDS representa escalares `b` `m` \"lote\" de 7 normales independientes, y `log_prob` calcula 7 probabilidades logarítmicas separadas, cada una de las cuales representa la probabilidad logarítmica de extraer `m` y `b`, y una sola observación `Y[i]` en algún `X[i]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9RI0oxCi_En"
      },
      "source": [
        "### Cómo arreglar `log_prob(sample())` con `Independent`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOL1hllzjDcF"
      },
      "source": [
        "Recuerde que `dists[2]` tiene `event_shape=[]` y `batch_shape=[7]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA05J9VwjCLu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Normal 'JointDistributionSequential_sample_distributions_Normal' batch_shape=[7] event_shape=[] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dists[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xQ5ORIqjPAz"
      },
      "source": [
        "Al utilizar la metadistribución `Independent` de TFP, que convierte dimensiones de lote en dimensiones de evento, podemos convertir esto en una distribución con `event_shape=[7]` y `batch_shape=[]` (le cambiaremos el nombre `y_dist_i` porque es una distribución en `Y`, con `_i` en pie para nuestro envoltorio `Independent`): "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa_SPItTjLBO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Independent 'IndependentJointDistributionSequential_sample_distributions_Normal' batch_shape=[] event_shape=[7] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i = tfd.Independent(dists[2], reinterpreted_batch_ndims=1)\n",
        "y_dist_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrRjuDhhmBEr"
      },
      "source": [
        "Ahora, la `log_prob` de un vector 7 es un escalar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9yZs-kwdLGa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-7.9087086>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i.log_prob(sample[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNEen4Ujkhh"
      },
      "source": [
        "A nivel interno, `Independent` suma sobre el lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYr1McJkWFx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dist_i.log_prob(sample[2]) - tf.reduce_sum(dists[2].log_prob(sample[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00lD003YkojA"
      },
      "source": [
        "Y, de hecho, podemos usar esto para construir un nuevo `jds_i` (la `i` nuevamente significa `Independent`) donde `log_prob` devuelve un escalar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jwoSeNWkhT6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-11.355776>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_i = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m*X + b, scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "jds_i.log_prob(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYY3CNBXlAIZ"
      },
      "source": [
        "Un par de notas:\n",
        "\n",
        "- `jds_i.log_prob(s)` *no* es lo mismo que `tf.reduce_sum(jds.log_prob(s))`. El primero produce la probabilidad logarítmica \"correcta\" de la distribución conjunta. Este último suma sobre un tensor 7, cada elemento del cual es la suma de la probabilidad logarítmica de `m`, `b` y un solo elemento de la probabilidad logarítmica de `Y`, por lo que sobrecuenta `m` y `b`. (`log_prob(m) + log_prob(b) + log_prob(Y)` devuelve un resultado en lugar de generar una excepción porque TFP sigue las reglas de transmisión de TF y NumPy; agregar un escalar a un vector produce un resultado del tamaño de un vector).\n",
        "- En este caso particular, podríamos haber resuelto el problema y lograr el mismo resultado usando `MultivariateNormalDiag` en lugar de `Independent(Normal(...))`. `MultivariateNormalDiag` es una distribución con valores vectoriales (es decir, ya tiene forma de evento vectorial). De hecho, `MultivariateNormalDiag` podría implementarse (pero no se implementa) como una composición de `Independent` y `Normal`. Vale la pena recordar que dado un vector `V`, las muestras de `n1 = Normal(loc=V)` y `n2 = MultivariateNormalDiag(loc=V)` son indistinguibles; la diferencia entre estas distribuciones es que `n1.log_prob(n1.sample())` es un vector y `n2.log_prob(n2.sample())` es un escalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-iFi65ZmvpB"
      },
      "source": [
        "### ¿Varias muestras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZcEBJS_nAhA"
      },
      "source": [
        "Extraer varias muestras todavía no funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkvYmB3jm2sI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  jds_i.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Jh0MTCn0Mr"
      },
      "source": [
        "Pensemos en por qué. Cuando llamamos `jds_i.sample([5, 3])` primero extraeremos muestras para `m` y `b`, cada una con forma `(5, 3)`. A continuación, intentaremos construir una distribución `Normal` mediante:\n",
        "\n",
        "```\n",
        "tfd.Normal(loc=m*X + b, scale=1.)\n",
        "```\n",
        "\n",
        "Pero si `m` tiene forma `(5, 3)` y `X` tiene forma `7`, no podemos multiplicarlos y, de hecho, este es el error al que nos estamos enfrentando:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei9Z2Nozp8Dy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3] vs. [7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "m = tfd.Normal(0., 1.).sample([5, 3])\n",
        "try:\n",
        "  m * X\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uqaIx2LlaeP"
      },
      "source": [
        "Para resolver este problema, pensemos en qué propiedades debe tener la distribución sobre `Y`. Si hemos llamado `jds_i.sample([5, 3])`, entonces sabemos que `m` y `b` tendrán la forma `(5, 3)`. ¿Qué forma debería producir una llamada a `sample` en la distribución `Y`? La respuesta obvia es `(5, 3, 7)`: para cada punto del lote, queremos una muestra del mismo tamaño que `X`. Podemos lograr esto mediante el uso de las capacidades de difusión de TensorFlow, agregando dimensiones adicionales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-22Bg8Yfr6tg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([5, 3, 1])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m[..., tf.newaxis].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k21MOvlsHGe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([5, 3, 7])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(m[..., tf.newaxis] * X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AEBbcjVsXQR"
      },
      "source": [
        "Al agregar un eje tanto a `m` como a `b`, podemos definir un nuevo JDS que admita múltiples muestras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rJ9WCVQsW0S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[-1.1133379 ,  0.16390413, -0.24177533],\n",
              "        [-1.1312429 , -0.6224666 , -1.8182136 ],\n",
              "        [-0.31343174, -0.32932565,  0.5164407 ],\n",
              "        [-0.0119963 , -0.9079621 ,  2.3655841 ],\n",
              "        [-0.26293617,  0.8229698 ,  0.31098196]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[-0.02876974,  1.0872147 ,  1.0138507 ],\n",
              "        [ 0.27367726, -1.331534  , -0.09084719],\n",
              "        [ 1.3349475 , -0.68765205,  1.680652  ],\n",
              "        [ 0.75436825,  1.3050154 , -0.9415123 ],\n",
              "        [-1.2502679 , -0.25730947,  0.74611956]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3, 7), dtype=float32, numpy=\n",
              " array([[[-1.8258233e+00, -3.0641669e-01, -2.7595463e+00, -1.6952467e+00,\n",
              "          -4.8197951e+00, -5.2986512e+00, -6.6931367e+00],\n",
              "         [ 3.6438566e-01,  1.0067395e+00,  1.4542470e+00,  8.1155670e-01,\n",
              "           1.8868095e+00,  2.3877139e+00,  1.0195159e+00],\n",
              "         [-8.3624744e-01,  1.2518480e+00,  1.0943471e+00,  1.3052304e+00,\n",
              "          -4.5756745e-01, -1.0668410e-01, -7.0669651e-02]],\n",
              " \n",
              "        [[-3.1788960e-01,  9.2615485e-03, -3.0963073e+00, -2.2846246e+00,\n",
              "          -3.2269263e+00, -6.0213070e+00, -7.4806519e+00],\n",
              "         [-3.9149747e+00, -3.5155020e+00, -1.5669601e+00, -5.0759468e+00,\n",
              "          -4.5065498e+00, -5.6719379e+00, -4.8012795e+00],\n",
              "         [ 1.3053948e-01, -8.0493152e-01, -4.7845001e+00, -4.9721808e+00,\n",
              "          -7.1365709e+00, -9.6198196e+00, -9.7951422e+00]],\n",
              " \n",
              "        [[ 2.0621397e+00,  3.4639853e-01,  7.0252883e-01, -1.4311566e+00,\n",
              "           3.3790007e+00,  1.1619035e+00, -8.9105040e-01],\n",
              "         [-7.8956139e-01, -8.5023916e-01, -9.7148323e-01, -2.6229355e+00,\n",
              "          -2.7150445e+00, -2.4633870e+00, -2.1841538e+00],\n",
              "         [ 7.7627432e-01,  2.2401071e+00,  3.7601702e+00,  2.4245868e+00,\n",
              "           4.0690269e+00,  4.0605016e+00,  5.1753912e+00]],\n",
              " \n",
              "        [[ 1.4275590e+00,  3.3346462e+00,  1.5374103e+00, -2.2849756e-01,\n",
              "           9.1219616e-01, -3.1220305e-01, -3.2643962e-01],\n",
              "         [-3.1910419e-02, -3.8848895e-01,  9.9946201e-02, -2.3619974e+00,\n",
              "          -1.8507402e+00, -3.6830821e+00, -5.4907336e+00],\n",
              "         [-7.1941972e-02,  2.1602919e+00,  4.9575748e+00,  4.2317696e+00,\n",
              "           9.3528280e+00,  1.0526063e+01,  1.5262107e+01]],\n",
              " \n",
              "        [[-2.3257759e+00, -2.5343289e+00, -3.5342445e+00, -4.0423255e+00,\n",
              "          -3.2361765e+00, -3.3434000e+00, -2.6849220e+00],\n",
              "         [ 1.5006512e-02, -1.9866472e-01,  7.6781356e-01,  1.6228745e+00,\n",
              "           1.4191239e+00,  2.6655579e+00,  4.4663467e+00],\n",
              "         [ 2.6599693e+00,  1.2663836e+00,  1.7162113e+00,  1.4839669e+00,\n",
              "           2.0559487e+00,  2.5976877e+00,  2.5977583e+00]]], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m[..., tf.newaxis]*X + b[..., tf.newaxis], scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "shaped_sample = jds_ia.sample([5, 3])\n",
        "shaped_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fsYEy6Fla0o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-12.483114 , -10.139662 , -11.514159 ],\n",
              "       [-11.656767 , -17.201958 , -12.132455 ],\n",
              "       [-17.838818 ,  -9.474525 , -11.24898  ],\n",
              "       [-13.95219  , -12.490049 , -17.123957 ],\n",
              "       [-14.487818 , -11.3755455, -10.576363 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ArLyKqJtY3Z"
      },
      "source": [
        "Como verificación adicional, verificaremos que la probabilidad logarítmica para un único punto del lote coincida con la que teníamos antes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_2lIJyJtpyW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(jds_ia.log_prob(shaped_sample)[3, 1] -\n",
        " jds_i.log_prob([shaped_sample[0][3, 1],\n",
        "                 shaped_sample[1][3, 1],\n",
        "                 shaped_sample[2][3, 1, :]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h7sJ2bkfOS7"
      },
      "source": [
        "<a id=\"AutoBatching-For-The-Win\"></a>\n",
        "\n",
        "### Procesamiento automático por lotes para ganar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7nqIUMxuKzw"
      },
      "source": [
        "¡Excelente! Ahora tenemos una versión de JointDistribution que maneja todos nuestros desiderata: `log_prob` devuelve un escalar gracias al uso de `tfd.Independent`, y las muestras múltiples funcionan ahora que hemos arreglado la difusión mediante la adición de ejes adicionales.\n",
        "\n",
        "¿Qué pasaría si le dijera que hay una manera que es mejor y más fácil? Existe y se llama `JointDistributionSequentialAutoBatched` (JDSAB):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZtVljb0fRx2"
      },
      "outputs": [],
      "source": [
        "jds_ab = tfd.JointDistributionSequentialAutoBatched([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpvjnvXqu2Mk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-12.954952>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(jds.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js3luiUfns_R"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-12.191533 , -10.43885  , -16.371655 ],\n",
              "       [-13.292994 , -11.97949  , -16.788685 ],\n",
              "       [-15.987699 , -13.435732 , -10.6029   ],\n",
              "       [-10.184758 , -11.969714 , -14.275676 ],\n",
              "       [-12.740775 , -11.5654125, -12.990162 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shaped_sample = jds_ab.sample([5, 3])\n",
        "jds_ab.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ppa6F6bdkv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(shaped_sample) - jds_ia.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy-kuUbYwFB3"
      },
      "source": [
        "¿Cómo funciona esto? Si bien puede tratar de [leer el código](https://github.com/tensorflow/probability/blob/main/tensorflow_probability/python/distributions/joint_distribution_auto_batched.py#L426) para comprenderlo en profundidad, le brindaremos una breve descripción general que es suficiente para la mayoría de los casos de uso:\n",
        "\n",
        "- Recuerde que nuestro primer problema fue que nuestra distribución para `Y` tenía `batch_shape=[7]` y `event_shape=[]` y usamos `Independent` para convertir la dimensión de lote en una dimensión de evento. JDSAB ignora las formas por lotes de las distribuciones de componentes; en lugar de eso, trata la forma de lote como una propiedad general del modelo, que se supone que es `[]` (a menos que se especifique lo contrario al establecer `batch_ndims > 0`). El efecto es equivalente al uso de tfd.Independent para convertir *todas* las dimensiones de lote de distribuciones de componentes en dimensiones de eventos, como lo hicimos manualmente anteriormente.\n",
        "- Nuestro segundo problema fue la necesidad de manipular las formas de `m` y `b` para que pudieran difundirse correctamente con `X` al crear múltiples muestras. Con JDSAB, usted escribe un modelo para generar una sola muestra y nosotros \"levantamos\" todo el modelo para generar múltiples muestras con ayuda de [vectorized_map](https://www.tensorflow.org/api_docs/python/tf/vectorized_map) de TensorFlow. (Esta característica es análoga al [vmap](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap) de JAX)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUsWfVGqJiph"
      },
      "source": [
        "Al explorar el problema de la forma de lote con más detalle, podemos comparar las formas de lote de nuestra distribución conjunta \"mala\" original `jds`, nuestras distribuciones fijadas por lotes `jds_i` y `jds_ia`, y nuestro `jds_ab` con lotes automáticos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "298I732fJDk5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([7])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBmdWrUuJGx0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_i.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD71eqN2JMhx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TensorShape([]), TensorShape([]), TensorShape([])]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ia.batch_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHmvRcxBJOAZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.batch_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozegq0diJuOL"
      },
      "source": [
        "Vemos que el `jds` original tiene subdistribuciones con diferentes formas de lote. `jds_i` y `jds_ia` solucionan este problema mediante la creación de subdistribuciones con la misma forma de lote (vacía). `jds_ab` tiene solo una forma de lote única (vacía)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMm55xqV1dz6"
      },
      "source": [
        "Vale la pena señalar que `JointDistributionSequentialAutoBatched` ofrece generalidad adicional de forma gratuita. Supongamos que hacemos que las covariables `X` (y, de forma implícita, las observaciones `Y`) sean bidimensionales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WfK-XbR1tXU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
              "       [ 7,  8,  9, 10, 11, 12, 13]])"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.arange(14).reshape((2, 7))\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnnkZooSj2C"
      },
      "source": [
        "Nuestro `JointDistributionSequentialAutoBatched` funciona sin cambios (necesitamos redefinir el modelo porque `jds_ab.log_prob` almacena en caché la forma de `X`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WwMvoY71qph"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[ 0.1813647 , -0.85994506,  0.27593774],\n",
              "        [-0.73323774,  1.1153806 ,  0.8841938 ],\n",
              "        [ 0.5127983 , -0.29271227,  0.63733214],\n",
              "        [ 0.2362284 , -0.919168  ,  1.6648189 ],\n",
              "        [ 0.26317367,  0.73077047,  2.5395133 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[ 0.09636458,  2.0138032 , -0.5054413 ],\n",
              "        [ 0.63941646, -1.0785882 , -0.6442188 ],\n",
              "        [ 1.2310615 , -0.3293852 ,  0.77637213],\n",
              "        [ 1.2115169 , -0.98906034, -0.07816773],\n",
              "        [-1.1318136 ,  0.510014  ,  1.036522  ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 3, 2, 7), dtype=float32, numpy=\n",
              " array([[[[-1.9685398e+00, -1.6832136e+00, -6.9127172e-01,\n",
              "            8.5992378e-01, -5.3123581e-01,  3.1584005e+00,\n",
              "            2.9044402e+00],\n",
              "          [-2.5645006e-01,  3.1554163e-01,  3.1186538e+00,\n",
              "            1.4272424e+00,  1.2843871e+00,  1.2266440e+00,\n",
              "            1.2798605e+00]],\n",
              " \n",
              "         [[ 1.5973477e+00, -5.3631151e-01,  6.8143606e-03,\n",
              "           -1.4910895e+00, -2.1568544e+00, -2.0513713e+00,\n",
              "           -3.1663666e+00],\n",
              "          [-4.9448099e+00, -2.8385928e+00, -6.9027486e+00,\n",
              "           -5.6543546e+00, -7.2378774e+00, -8.1577444e+00,\n",
              "           -9.3582869e+00]],\n",
              " \n",
              "         [[-2.1233239e+00,  5.8853775e-02,  1.2024102e+00,\n",
              "            1.6622503e+00, -1.9197327e-01,  1.8647723e+00,\n",
              "            6.4322817e-01],\n",
              "          [ 3.7549341e-01,  1.5853541e+00,  2.4594500e+00,\n",
              "            2.1952972e+00,  1.7517658e+00,  2.9666045e+00,\n",
              "            2.5468128e+00]]],\n",
              " \n",
              " \n",
              "        [[[ 8.9906776e-01,  6.7375046e-01,  7.3354661e-01,\n",
              "           -9.9894643e-01, -3.4606690e+00, -3.4810467e+00,\n",
              "           -4.4315586e+00],\n",
              "          [-3.0670738e+00, -6.3628020e+00, -6.2538433e+00,\n",
              "           -6.8091092e+00, -7.7134805e+00, -8.6319380e+00,\n",
              "           -8.6904278e+00]],\n",
              " \n",
              "         [[-2.2462025e+00, -3.3060855e-01,  1.8974400e-01,\n",
              "            3.1422038e+00,  4.1483402e+00,  3.5642972e+00,\n",
              "            4.8709240e+00],\n",
              "          [ 4.7880130e+00,  5.8790064e+00,  9.6695948e+00,\n",
              "            7.8112822e+00,  1.2022618e+01,  1.2411858e+01,\n",
              "            1.4323385e+01]],\n",
              " \n",
              "         [[-1.0189297e+00, -7.8115642e-01,  1.6466728e+00,\n",
              "            8.2378983e-01,  3.0765080e+00,  3.0170646e+00,\n",
              "            5.1899948e+00],\n",
              "          [ 6.5285158e+00,  7.8038850e+00,  6.4155884e+00,\n",
              "            9.0899811e+00,  1.0040427e+01,  9.1404457e+00,\n",
              "            1.0411951e+01]]],\n",
              " \n",
              " \n",
              "        [[[ 4.5557004e-01,  1.4905317e+00,  1.4904103e+00,\n",
              "            2.9777462e+00,  2.8620450e+00,  3.4745665e+00,\n",
              "            3.8295493e+00],\n",
              "          [ 3.9977460e+00,  5.7173767e+00,  7.8421035e+00,\n",
              "            6.3180594e+00,  6.0838981e+00,  8.2257290e+00,\n",
              "            9.6548376e+00]],\n",
              " \n",
              "         [[-7.0750320e-01, -3.5972297e-01,  4.3136525e-01,\n",
              "           -2.3301599e+00, -5.0374687e-01, -2.8338656e+00,\n",
              "           -3.4453444e+00],\n",
              "          [-3.1258626e+00, -3.4687450e+00, -1.2045374e+00,\n",
              "           -4.0196013e+00, -5.8831010e+00, -4.2965469e+00,\n",
              "           -4.1388311e+00]],\n",
              " \n",
              "         [[ 2.1969774e+00,  2.4614549e+00,  2.2314475e+00,\n",
              "            1.8392437e+00,  2.8367062e+00,  4.8600502e+00,\n",
              "            4.2273531e+00],\n",
              "          [ 6.1879644e+00,  5.1792760e+00,  6.1141996e+00,\n",
              "            5.6517797e+00,  8.9979610e+00,  7.5938139e+00,\n",
              "            9.7918644e+00]]],\n",
              " \n",
              " \n",
              "        [[[ 1.5249090e+00,  1.1388919e+00,  8.6903995e-01,\n",
              "            3.0762129e+00,  1.5128503e+00,  3.5204377e+00,\n",
              "            2.4760864e+00],\n",
              "          [ 3.4166217e+00,  3.5930209e+00,  3.1694956e+00,\n",
              "            4.5797420e+00,  4.5271711e+00,  2.8774328e+00,\n",
              "            4.7288942e+00]],\n",
              " \n",
              "         [[-2.3095846e+00, -2.0595703e+00, -3.0093951e+00,\n",
              "           -3.8594103e+00, -4.9681158e+00, -6.4256043e+00,\n",
              "           -5.5345035e+00],\n",
              "          [-6.4306297e+00, -7.0924540e+00, -8.4075985e+00,\n",
              "           -1.0417805e+01, -1.1727266e+01, -1.1196255e+01,\n",
              "           -1.1333830e+01]],\n",
              " \n",
              "         [[-7.0419472e-01,  1.4568675e+00,  3.7946482e+00,\n",
              "            4.8489718e+00,  6.6498446e+00,  9.0224218e+00,\n",
              "            1.1153137e+01],\n",
              "          [ 1.0060651e+01,  1.1998097e+01,  1.5326431e+01,\n",
              "            1.7957514e+01,  1.8323889e+01,  2.0160881e+01,\n",
              "            2.1269085e+01]]],\n",
              " \n",
              " \n",
              "        [[[-2.2360647e-01, -1.3632748e+00, -7.2704530e-01,\n",
              "            2.3558271e-01, -1.0381399e+00,  1.9387857e+00,\n",
              "           -3.3694571e-01],\n",
              "          [ 1.6015106e-01,  1.5284677e+00, -4.8567140e-01,\n",
              "           -1.7770648e-01,  2.1919653e+00,  1.3015286e+00,\n",
              "            1.3877077e+00]],\n",
              " \n",
              "         [[ 1.3688663e+00,  2.6602898e+00,  6.6657305e-01,\n",
              "            4.6554832e+00,  5.7781887e+00,  4.9115267e+00,\n",
              "            4.8446012e+00],\n",
              "          [ 5.1983776e+00,  6.2297459e+00,  6.3848300e+00,\n",
              "            8.4291229e+00,  7.1309576e+00,  1.0395646e+01,\n",
              "            8.5736713e+00]],\n",
              " \n",
              "         [[ 1.2675294e+00,  5.2844582e+00,  5.1331611e+00,\n",
              "            8.9993315e+00,  1.0794343e+01,  1.4039831e+01,\n",
              "            1.5731170e+01],\n",
              "          [ 1.9084715e+01,  2.2191265e+01,  2.3481146e+01,\n",
              "            2.5803375e+01,  2.8632090e+01,  3.0234968e+01,\n",
              "            3.1886738e+01]]]], dtype=float32)>]"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab = tfd.JointDistributionSequentialAutoBatched([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Normal(loc=m*X + b, scale=1.) # Y\n",
        "])\n",
        "\n",
        "shaped_sample = jds_ab.sample([5, 3])\n",
        "shaped_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLvHMTpnSyvH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-28.90071 , -23.052422, -19.851362],\n",
              "       [-19.775568, -25.894997, -20.302256],\n",
              "       [-21.10754 , -23.667885, -20.973007],\n",
              "       [-19.249458, -20.87892 , -20.573763],\n",
              "       [-22.351208, -25.457762, -24.648403]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jds_ab.log_prob(shaped_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI40r2oETnVP"
      },
      "source": [
        "Por otro lado, nuestro `JointDistributionSequential` cuidadosamente elaborado ya no funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfYkdBIi0wJl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incompatible shapes: [5,3,1] vs. [2,7] [Op:Mul]\n"
          ]
        }
      ],
      "source": [
        "jds_ia = tfd.JointDistributionSequential([\n",
        "    tfd.Normal(loc=0., scale=1.),   # m\n",
        "    tfd.Normal(loc=0., scale=1.),   # b\n",
        "    lambda b, m: tfd.Independent(   # Y\n",
        "        tfd.Normal(loc=m[..., tf.newaxis]*X + b[..., tf.newaxis], scale=1.),\n",
        "        reinterpreted_batch_ndims=1)\n",
        "])\n",
        "\n",
        "try:\n",
        "  jds_ia.sample([5, 3])\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLERQvFNTwQJ"
      },
      "source": [
        "Para solucionar este problema, tendríamos que agregar un segundo `tf.newaxis` para que `m` y `b` coincidan con la forma, y ​​aumentar `reinterpreted_batch_ndims` a 2 en la llamada a `Independent`. En este caso, dejar que la maquinaria de procesamiento automático por lotes se encargue de los problemas de forma es más rápido, más fácil y más ergonómico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgCF6yJXpHE"
      },
      "source": [
        "Una vez más, observamos que si bien este bloc de notas exploró `JointDistributionSequentialAutoBatched`, las otras variantes de `JointDistribution` tienen `AutoBatched` equivalente. (Para los usuarios de `JointDistributionCoroutine`, `JointDistributionCoroutineAutoBatched` tiene el beneficio adicional de que ya no necesita especificar nodos `Root`; si nunca ha usado `JointDistributionCoroutine`, puede ignorar esta instrucción con seguridad)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHacIM0iUW09"
      },
      "source": [
        "### Reflexiones finales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAC7GDWUaaY"
      },
      "source": [
        "En este bloc de notas, presentamos `JointDistributionSequentialAutoBatched` y trabajamos en detalle con un ejemplo simple. ¡Esperamos que haya aprendido algo sobre las formas de TFP y sobre el procesamiento automático por lotes!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "JointDistributionAutoBatched_A_Gentle_Tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
