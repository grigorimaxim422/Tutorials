{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVKYfpQVYPaJ"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Probability Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "htHLjlnLYSoB"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcriL2xPrG3_"
      },
      "source": [
        "# Explicación de las formas de TensorFlow Distributions\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/probability/examples/Understanding_TensorFlow_Distributions_Shapes\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/probability/examples/Understanding_TensorFlow_Distributions_Shapes.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/probability/examples/Understanding_TensorFlow_Distributions_Shapes.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/probability/examples/Understanding_TensorFlow_Distributions_Shapes.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6t0EUihrG4B"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v2.enable_v2_behavior()\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD5lzFZerG4H"
      },
      "source": [
        "## Conceptos básicos\n",
        "\n",
        "Hay tres conceptos importantes asociados con las formas de TensorFlow Distributions:\n",
        "\n",
        "- La *forma de evento* describe la forma de una única extracción de la distribución; la extracción puede depender de todas las dimensiones. Para distribuciones escalares, la forma de evento es `[]`. Para una MultivariateNormal de 5 dimensiones, la forma de evento es `[5]`.\n",
        "- La *forma del lote* describe extracciones independientes, no distribuidas de manera idéntica, también conocidas como un \"lote\" de distribuciones.\n",
        "- La *forma de muestra* describe extracciones independientes y distribuidas de forma idéntica de lotes de la familia de distribución.\n",
        "\n",
        "La forma de evento y la forma de lote son propiedades de un objeto `Distribution`, mientras que la forma de muestra se asocia con una llamada específica a `sample` o `log_prob`.\n",
        "\n",
        "El propósito de este bloc de notas es ilustrar estos conceptos a través de ejemplos, por lo tanto, si no le resulta evidente a primera vista, no se preocupe.\n",
        "\n",
        "Para obtener otra descripción general conceptual de estos conceptos, consulte [esta publicación de blog](https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU34kIHDrG4I"
      },
      "source": [
        "### Una nota sobre TensorFlow Eager\n",
        "\n",
        "Todo este bloc de notas se escribió con [TensorFlow Eager](https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html). Ninguno de los conceptos que se presentan *depende* de Eager, aunque con Eager, las formas de eventos y lotes de distribución se evalúan (y por lo tanto se conocen) cuando el objeto `Distribution` se crea en Python, mientras que en el modo de grafo (no Eager), es posible definir distribuciones cuyas formas de evento y lote son indeterminadas hasta que se ejecuta el grafo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeirD-0JrG4K"
      },
      "source": [
        "## Distribuciones escalares\n",
        "\n",
        "Como señalamos anteriormente, un objeto `Distribution` tiene formas definidas de eventos y lotes. Comenzaremos con una utilidad para describir distribuciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq8guNPtrG4M"
      },
      "outputs": [],
      "source": [
        "def describe_distributions(distributions):\n",
        "  print('\\n'.join([str(d) for d in distributions]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06CafVXWrG4Q"
      },
      "source": [
        "En esta sección, exploraremos distribuciones *escalares*: distribuciones con una forma de evento de `[]`. Un ejemplo típico es la distribución de Poisson, especificada por una `rate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdz1OMg7rG4S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Poisson(\"One_Poisson_Scalar_Batch\", batch_shape=[], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Poisson(\"Three_Poissons\", batch_shape=[3], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Poisson(\"Two_by_Three_Poissons\", batch_shape=[2, 3], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Poisson(\"One_Poisson_Vector_Batch\", batch_shape=[1], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Poisson(\"One_Poisson_Expanded_Batch\", batch_shape=[1, 1], event_shape=[], dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "poisson_distributions = [\n",
        "    tfd.Poisson(rate=1., name='One Poisson Scalar Batch'),\n",
        "    tfd.Poisson(rate=[1., 10., 100.], name='Three Poissons'),\n",
        "    tfd.Poisson(rate=[[1., 10., 100.,], [2., 20., 200.]],\n",
        "                name='Two-by-Three Poissons'),\n",
        "    tfd.Poisson(rate=[1.], name='One Poisson Vector Batch'),\n",
        "    tfd.Poisson(rate=[[1.]], name='One Poisson Expanded Batch')\n",
        "]\n",
        "\n",
        "describe_distributions(poisson_distributions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPVIsC9rG4a"
      },
      "source": [
        "La distribución de Poisson es una distribución escalar, por lo que la forma de su evento es siempre `[]`. Si especificamos más tarifas, estas aparecerán en forma de lote. El último par de ejemplos es interesante: solo hay una tasa única, pero debido a que esa tasa está incorporada en un arreglo numpy con una forma no vacía, esa forma se convierte en la forma de lote."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFlXG9O5rG4b"
      },
      "source": [
        "La distribución Normal estándar también es escalar. Su forma de evento es `[]`, igual que la de Poisson, pero jugaremos con ella para ver nuestro primer ejemplo de *transmisión*. La Normal se especifica mediante los parámetros `loc` y `scale`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5PXRPM1rG4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Normal(\"Standard\", batch_shape=[], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Normal(\"Standard_Vector_Batch\", batch_shape=[1], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Normal(\"Different_Locs\", batch_shape=[4], event_shape=[], dtype=float32)\n",
            "tfp.distributions.Normal(\"Broadcasting_Scale\", batch_shape=[2, 4], event_shape=[], dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "normal_distributions = [\n",
        "    tfd.Normal(loc=0., scale=1., name='Standard'),\n",
        "    tfd.Normal(loc=[0.], scale=1., name='Standard Vector Batch'),\n",
        "    tfd.Normal(loc=[0., 1., 2., 3.], scale=1., name='Different Locs'),\n",
        "    tfd.Normal(loc=[0., 1., 2., 3.], scale=[[1.], [5.]],\n",
        "               name='Broadcasting Scale')\n",
        "]\n",
        "\n",
        "describe_distributions(normal_distributions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh70eNXHrG4i"
      },
      "source": [
        "El interesante ejemplo anterior es la distribución `Broadcasting Scale`. El parámetro `loc` tiene forma `[4]` y el parámetro `scale` tiene forma `[2, 1]`. Si usamos [las reglas de difusión de Numpy](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html), la forma de lote es `[2, 4]`. Una forma equivalente (pero menos elegante y no recomendada) de definir la distribución `\"Broadcasting Scale\"` sería la siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G5JNBzQrG4j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Normal(\"Normal\", batch_shape=[2, 4], event_shape=[], dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "describe_distributions(\n",
        "    [tfd.Normal(loc=[[0., 1., 2., 3], [0., 1., 2., 3.]],\n",
        "                scale=[[1., 1., 1., 1.], [5., 5., 5., 5.]])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hSBWsokrG4p"
      },
      "source": [
        "Podemos ver por qué la notación de difusión es útil, aunque también es una fuente de dolores de cabeza y errores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trGxojHwrG4r"
      },
      "source": [
        "### Muestreo de distribuciones escalares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDJqRz-qrG4t"
      },
      "source": [
        "Hay dos cosas principales que podemos hacer con las distribuciones: podemos ejecutar `sample` y calcular `log_prob`. Exploremos primero el muestreo. La regla básica es que cuando tomamos muestras de una distribución, el tensor resultante tiene la forma `[sample_shape, batch_shape, event_shape]`, donde `batch_shape` y `event_shape` son proporcionadas por el objeto `Distribution`, y `sample_shape` es proporcionada por la llamada a `sample`. Para distribuciones escalares, `event_shape = []`, por lo que el tensor devuelto por la muestra tendrá la forma `[sample_shape, batch_shape]`. Pongámoslo a prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TbeP0btrG4u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Poisson(\"One_Poisson_Scalar_Batch\", batch_shape=[], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1,)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2,)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5)\n",
            "\n",
            "tfp.distributions.Poisson(\"Three_Poissons\", batch_shape=[3], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 3)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 3)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 3)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 3)\n",
            "\n",
            "tfp.distributions.Poisson(\"Two_by_Three_Poissons\", batch_shape=[2, 3], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 2, 3)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 2, 3)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 2, 3)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 2, 3)\n",
            "\n",
            "tfp.distributions.Poisson(\"One_Poisson_Vector_Batch\", batch_shape=[1], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 1)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 1)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 1)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 1)\n",
            "\n",
            "tfp.distributions.Poisson(\"One_Poisson_Expanded_Batch\", batch_shape=[1, 1], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 1, 1)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 1, 1)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 1, 1)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 1, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def describe_sample_tensor_shape(sample_shape, distribution):\n",
        "    print('Sample shape:', sample_shape)\n",
        "    print('Returned sample tensor shape:',\n",
        "          distribution.sample(sample_shape).shape)\n",
        "\n",
        "def describe_sample_tensor_shapes(distributions, sample_shapes):\n",
        "    started = False\n",
        "    for distribution in distributions:\n",
        "      print(distribution)\n",
        "      for sample_shape in sample_shapes:\n",
        "        describe_sample_tensor_shape(sample_shape, distribution)\n",
        "      print()\n",
        "\n",
        "sample_shapes = [1, 2, [1, 5], [3, 4, 5]]\n",
        "describe_sample_tensor_shapes(poisson_distributions, sample_shapes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiJK8UBorG40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Normal(\"Standard\", batch_shape=[], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1,)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2,)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5)\n",
            "\n",
            "tfp.distributions.Normal(\"Standard_Vector_Batch\", batch_shape=[1], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 1)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 1)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 1)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 1)\n",
            "\n",
            "tfp.distributions.Normal(\"Different_Locs\", batch_shape=[4], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 4)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 4)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 4)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 4)\n",
            "\n",
            "tfp.distributions.Normal(\"Broadcasting_Scale\", batch_shape=[2, 4], event_shape=[], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 2, 4)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 2, 4)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 2, 4)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 2, 4)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "describe_sample_tensor_shapes(normal_distributions, sample_shapes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDRB80oLrG48"
      },
      "source": [
        "Eso es todo lo que hay que decir sobre `sample`: los tensores de muestra devueltos tienen forma `[sample_shape, batch_shape, event_shape]`.\n",
        "\n",
        "### Cálculo de `log_prob` para distribuciones escalares\n",
        "\n",
        "Ahora echemos un vistazo a `log_prob`, que es algo más complicado. `log_prob` toma como entrada un tensor (no vacío) que representa las ubicaciones en las que calcular `log_prob` para la distribución. En el caso más sencillo, este tensor tendrá una forma de la forma `[sample_shape, batch_shape, event_shape]`, donde `batch_shape` y `event_shape` coinciden con las formas de lote y evento de la distribución. Recuerde una vez más que para distribuciones escalares, `event_shape = []`, por lo que el tensor de entrada tiene forma `[sample_shape, batch_shape]` En este caso, obtenemos un tensor de forma `[sample_shape, batch_shape]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgNIiFf9rG49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Poisson 'Three_Poissons' batch_shape=[3] event_shape=[] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons = tfd.Poisson(rate=[1., 10., 100.], name='Three Poissons')\n",
        "three_poissons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpN5WGog0WwC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -2.0785608,   -3.2223587],\n",
              "       [-364.73938  ,   -2.0785608,  -95.39484  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons.log_prob([[1., 10., 100.], [100., 10., 1]])  # sample_shape is [2]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4szFj9lkrG5F"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 2, 3), dtype=float32, numpy=\n",
              "array([[[[  -1.       ,   -2.0785608,   -3.2223587],\n",
              "         [-364.73938  ,   -2.0785608,  -95.39484  ]]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons.log_prob([[[[1., 10., 100.], [100., 10., 1.]]]])  # sample_shape is [1, 1, 2]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG_n9BHsrG5M"
      },
      "source": [
        "Observe cómo en el primer ejemplo, la entrada y la salida tienen forma `[2, 3]` y en el segundo ejemplo tienen forma `[1, 1, 2, 3]`.\n",
        "\n",
        "Eso sería todo lo que habría que decir, si no fuera por la difusión. Estas son las reglas una vez que tomamos en cuenta la difusión. Lo describimos con total generalidad y observamos simplificaciones para distribuciones escalares:\n",
        "\n",
        "1. Defina `n = len(batch_shape) + len(event_shape)`. (Para distribuciones escalares, `len(event_shape)=0`.)\n",
        "2. Si el tensor de entrada `t` tiene menos de `n` dimensiones, rellene su forma mediante la incorporación de dimensiones de tamaño `1` a la izquierda hasta que tenga exactamente `n` dimensiones. Llame al tensor `t'` resultante.\n",
        "3. Difunda las `n` dimensiones más a la derecha de `t'` contra `[batch_shape, event_shape]` de la distribución para la que se está calculando una `log_prob`. Más detalladamente: para las dimensiones donde `t'` ya coincide con la distribución, no haga nada, y para las dimensiones donde `t'` tiene un singleton, replique ese singleton el número de veces correspondiente. Cualquier otra situación es un error. (Para distribuciones escalares, solo difundimos contra `batch_shape`, ya que event_shape = `[]`).\n",
        "4. Ahora finalmente podemos calcular `log_prob`. El tensor resultante tendrá forma `[sample_shape, batch_shape]`, donde `sample_shape` se define como cualquier dimensión de `t` o `t'` a la izquierda de las `n` dimensiones más a la derecha: `sample_shape = shape(t)[:-n]`.\n",
        "\n",
        "Esto puede ser un desastre si no sabe lo que significa, así que trabajemos con algunos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwDVaeRHrG5O"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-16.104412 ,  -2.0785608, -69.05272  ], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons.log_prob([10.])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAImEhtdrG5U"
      },
      "source": [
        "El tensor `[10.]` (con forma `[1]`) se difunde a través de `batch_shape` de 3, por lo que evaluamos la probabilidad logarítmica de los tres Poisson en el valor 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daDAG6p2rG5V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[-1.0000000e+00, -7.6974149e+00, -9.5394836e+01],\n",
              "        [-1.6104412e+01, -2.0785608e+00, -6.9052719e+01]],\n",
              "\n",
              "       [[-3.6473938e+02, -1.4348087e+02, -3.2223587e+00],\n",
              "        [-5.9131279e+03, -3.6195427e+03, -1.4069575e+03]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons.log_prob([[[1.], [10.]], [[100.], [1000.]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REEX-DgBrG5b"
      },
      "source": [
        "En el ejemplo anterior, el tensor de entrada tiene forma `[2, 2, 1]`, mientras que el objeto de distribuciones tiene una forma de lote de 3. Entonces, para cada una de las dimensiones de muestra `[2, 2]`, el valor único proporcionado obtiene difusiones a cada uno de los tres Poisson.\n",
        "\n",
        "Una forma posiblemente útil de pensarlo: debido a que `three_poissons` tiene `batch_shape = [2, 3]`, una llamada a `log_prob` debe tomar un tensor cuya última dimensión sea 1 o 3; cualquier otra cosa es un error. (Las reglas de difusión de numpy tratan el caso especial de un escalar como totalmente equivalente a un tensor de forma `[1]`).\n",
        "\n",
        "Pongamos a prueba nuestras habilidades experimentando con la distribución de Poisson más compleja con `batch_shape = [2, 3]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkSWkwYarG5d"
      },
      "outputs": [],
      "source": [
        "poisson_2_by_3 = tfd.Poisson(\n",
        "    rate=[[1., 10., 100.,], [2., 20., 200.]],\n",
        "    name='Two-by-Three Poissons')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YFRkkssrG5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [  -1.3068528,  -17.004269 , -194.70169  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob(1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqQXvOexrG5i"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [  -1.3068528,  -17.004269 , -194.70169  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([1.])  # Exactly equivalent to above, demonstrating the scalar special case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nCuYQC5rG5m"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [  -1.3068528,  -17.004269 , -194.70169  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[1., 1., 1.], [1., 1., 1.]])  # Another way to write the same thing. No broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PgG6udBrG5p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[ -1.       ,  -2.0785608,  -3.2223587],\n",
              "       [ -1.3068528,  -5.14709  , -33.90767  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[1., 10., 100.]])  # Input is [1, 3] broadcast to [2, 3]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm7ejyoArG5s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[ -1.       ,  -2.0785608,  -3.2223587],\n",
              "       [ -1.3068528,  -5.14709  , -33.90767  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[1., 10., 100.], [1., 10., 100.]])  # Equivalent to above. No broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVMSGVvGrG5w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [  -1.3068528,  -14.701683 , -190.09653  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[1., 1., 1.], [2., 2., 2.]])  # No broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVEpi5QErG5z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [  -1.3068528,  -14.701683 , -190.09653  ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[1.], [2.]])  # Equivalent to above. Input shape [2, 1] broadcast to [2, 3]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW2tApDGrG53"
      },
      "source": [
        "Los ejemplos anteriores implicaban la difusión del lote, pero la forma de la muestra estaba vacía. Supongamos que tenemos una colección de valores y queremos obtener la probabilidad logarítmica de cada valor en cada punto del lote. Podríamos hacerlo manualmente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03DvnmK2rG53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "        [  -1.3068528,  -17.004269 , -194.70169  ]],\n",
              "\n",
              "       [[  -1.6931472,   -6.087977 ,  -91.48282  ],\n",
              "        [  -1.3068528,  -14.701683 , -190.09653  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[[1., 1., 1.], [1., 1., 1.]], [[2., 2., 2.], [2., 2., 2.]]])  # Input shape [2, 2, 3]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkpJQ0dJrG56"
      },
      "source": [
        "O podríamos dejar que la difusión se encargue de la última dimensión del lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ6OsodCrG57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "        [  -1.3068528,  -17.004269 , -194.70169  ]],\n",
              "\n",
              "       [[  -1.6931472,   -6.087977 ,  -91.48282  ],\n",
              "        [  -1.3068528,  -14.701683 , -190.09653  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[[1.], [1.]], [[2.], [2.]]])  # Input shape [2, 2, 1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZFx8pThrG5-"
      },
      "source": [
        "También podríamos (aunque quizás no resulte tan natural) dejar que la difusión maneje solo la primera dimensión del lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoGs7GBSrG5_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "        [  -1.3068528,  -17.004269 , -194.70169  ]],\n",
              "\n",
              "       [[  -1.6931472,   -6.087977 ,  -91.48282  ],\n",
              "        [  -1.3068528,  -14.701683 , -190.09653  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[[1., 1., 1.]], [[2., 2., 2.]]])  # Input shape [2, 1, 3]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOP4OhGDrG6C"
      },
      "source": [
        "O podríamos dejar que la difusión maneje *ambas* dimensiones del lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnG2f4tZrG6E"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "        [  -1.3068528,  -17.004269 , -194.70169  ]],\n",
              "\n",
              "       [[  -1.6931472,   -6.087977 ,  -91.48282  ],\n",
              "        [  -1.3068528,  -14.701683 , -190.09653  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob([[[1.]], [[2.]]])  # Input shape [2, 1, 1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1s1drAwrG6K"
      },
      "source": [
        "Lo que acabamos de explicar funcionaba bien cuando solo queríamos dos valores, pero supongamos que tuviéramos una larga lista de valores y quisiéramos evaluarlos en cada punto del lote. Para eso, la siguiente notación, que agrega dimensiones adicionales de tamaño 1 al lado derecho de la forma, es extremadamente útil:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUxbYZN_rG6K"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
              "array([[[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "        [  -1.3068528,  -17.004269 , -194.70169  ]],\n",
              "\n",
              "       [[  -1.6931472,   -6.087977 ,  -91.48282  ],\n",
              "        [  -1.3068528,  -14.701683 , -190.09653  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "poisson_2_by_3.log_prob(tf.constant([1., 2.])[..., tf.newaxis, tf.newaxis])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se893aIurG6M"
      },
      "source": [
        "Este es un ejemplo de [notación de segmento con pasos](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/strided-slice), que vale la pena conocer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNDhHqJmrG6N"
      },
      "source": [
        "Si retomamos `three_poissons` para completar, el mismo ejemplo se ve así:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKP7OmQsrG6N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [ -16.104412 ,   -2.0785608,  -69.05272  ],\n",
              "       [-149.47777  ,  -43.34851  ,  -18.219261 ],\n",
              "       [-364.73938  , -143.48087  ,   -3.2223587]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons.log_prob([[1.], [10.], [50.], [100.]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK_9DwSdrG6R"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
              "array([[  -1.       ,   -7.697415 ,  -95.39484  ],\n",
              "       [ -16.104412 ,   -2.0785608,  -69.05272  ],\n",
              "       [-149.47777  ,  -43.34851  ,  -18.219261 ],\n",
              "       [-364.73938  , -143.48087  ,   -3.2223587]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_poissons.log_prob(tf.constant([1., 10., 50., 100.])[..., tf.newaxis])  # Equivalent to above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhL17DW5rG6T"
      },
      "source": [
        "## Distribuciones multivariadas\n",
        "\n",
        "Pasemos ahora a las distribuciones multivariadas, que tienen forma de evento no vacía. Veamos distribuciones multinomiales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOdGa5n9rG6T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Multinomial(\"One_Multinomial\", batch_shape=[], event_shape=[3], dtype=float32)\n",
            "tfp.distributions.Multinomial(\"Two_Multinomials_Same_Probs\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
            "tfp.distributions.Multinomial(\"Two_Multinomials_Same_Counts\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
            "tfp.distributions.Multinomial(\"Two_Multinomials_Different_Everything\", batch_shape=[2], event_shape=[3], dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "multinomial_distributions = [\n",
        "    # Multinomial is a vector-valued distribution: if we have k classes,\n",
        "    # an individual sample from the distribution has k values in it, so the\n",
        "    # event_shape is `[k]`.\n",
        "    tfd.Multinomial(total_count=100., probs=[.5, .4, .1],\n",
        "                    name='One Multinomial'),\n",
        "    tfd.Multinomial(total_count=[100., 1000.], probs=[.5, .4, .1],\n",
        "                    name='Two Multinomials Same Probs'),\n",
        "    tfd.Multinomial(total_count=100., probs=[[.5, .4, .1], [.1, .2, .7]],\n",
        "                    name='Two Multinomials Same Counts'),\n",
        "    tfd.Multinomial(total_count=[100., 1000.],\n",
        "                    probs=[[.5, .4, .1], [.1, .2, .7]],\n",
        "                    name='Two Multinomials Different Everything')\n",
        "\n",
        "]\n",
        "\n",
        "describe_distributions(multinomial_distributions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQ8gK7irG6W"
      },
      "source": [
        "Observe cómo en los últimos tres ejemplos, batch_shape es siempre `[2]`, pero podemos usar la difusión para tener un `total_count` compartido o `probs` compartidas (o ninguno de los dos), porque en el fondo se difunden para que tengan la misma forma.\n",
        "\n",
        "El muestreo es sencillo, dado lo que ya sabemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSr362qjrG6W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Multinomial(\"One_Multinomial\", batch_shape=[], event_shape=[3], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 3)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 3)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 3)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 3)\n",
            "\n",
            "tfp.distributions.Multinomial(\"Two_Multinomials_Same_Probs\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 2, 3)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 2, 3)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 2, 3)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 2, 3)\n",
            "\n",
            "tfp.distributions.Multinomial(\"Two_Multinomials_Same_Counts\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 2, 3)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 2, 3)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 2, 3)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 2, 3)\n",
            "\n",
            "tfp.distributions.Multinomial(\"Two_Multinomials_Different_Everything\", batch_shape=[2], event_shape=[3], dtype=float32)\n",
            "Sample shape: 1\n",
            "Returned sample tensor shape: (1, 2, 3)\n",
            "Sample shape: 2\n",
            "Returned sample tensor shape: (2, 2, 3)\n",
            "Sample shape: [1, 5]\n",
            "Returned sample tensor shape: (1, 5, 2, 3)\n",
            "Sample shape: [3, 4, 5]\n",
            "Returned sample tensor shape: (3, 4, 5, 2, 3)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "describe_sample_tensor_shapes(multinomial_distributions, sample_shapes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjXgxPXCrG6Z"
      },
      "source": [
        "El cálculo de las probabilidades logarítmicas es igualmente sencillo. Trabajemos un ejemplo con distribuciones Normales Multivariadas diagonales. (Las multinomiales no se llevan muy bien con la difusión, ya que las restricciones en los recuentos y las probabilidades implican que la difusión a menudo producirá valores inadmisibles). Usaremos un lote de 2 distribuciones tridimensionales con la misma media, pero diferentes escalas (desviaciones estándar):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnywBQdZrG6Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[2] event_shape=[3] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_multivariate_normals = tfd.MultivariateNormalDiag(loc=[1., 2., 3.], scale_diag=tf.ones([2, 3]) * [[1.], [2.]])\n",
        "two_multivariate_normals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9xE21IirG6b"
      },
      "source": [
        "Ahora evaluemos la probabilidad logarítmica de cada punto del lote en su media y en una media desplazada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBOLH33PrG6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[-2.7568154, -4.836257 ],\n",
              "       [-8.756816 , -6.336257 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_multivariate_normals.log_prob([[[1., 2., 3.]], [[3., 4., 5.]]])  # Input has shape [2,1,3]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPDC6y3qrG6e"
      },
      "source": [
        "De manera exactamente equivalente, podemos usar [https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/strided-slice](notación de segmento con pasos) para insertar una dimensión extra de forma=1 en medio de una constante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9m9GMezrG6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[-2.7568154, -4.836257 ],\n",
              "       [-8.756816 , -6.336257 ]], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_multivariate_normals.log_prob(\n",
        "    tf.constant([[1., 2., 3.], [3., 4., 5.]])[:, tf.newaxis, :])  # Equivalent to above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJA07wN7rG6i"
      },
      "source": [
        "Por otro lado, si no insertamos la dimensión adicional, pasamos `[1., 2., 3.]` al primer punto del lote y `[3., 4., 5.]` al segundo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaX1unvPrG6i"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-2.7568154, -6.336257 ], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_multivariate_normals.log_prob(tf.constant([[1., 2., 3.], [3., 4., 5.]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnhW86vcUfT8"
      },
      "source": [
        "## Técnicas de manipulación de formas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EYcFW7OrG6m"
      },
      "source": [
        "### El biyector Reshape\n",
        "\n",
        "El biyector `Reshape` sirve para remodelar la *event_shape* de una distribución. Veamos un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YT_lQCarG6m"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Multinomial 'Multinomial' batch_shape=[] event_shape=[6] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "six_way_multinomial = tfd.Multinomial(total_count=1000., probs=[.3, .25, .2, .15, .08, .02])\n",
        "six_way_multinomial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5a5uXQsUpMs"
      },
      "source": [
        "Creamos una multinomial con una forma de evento de `[6]`. El biyector Reshape nos permite tratar esto como una distribución con una forma de evento de `[2, 3]`.\n",
        "\n",
        "Un `Bijector` representa una función diferenciable uno a uno en un subconjunto abierto de ${\\mathbb R}^n$. `Bijectors` se usan junto con `TransformedDistribution`, que modela una distribución $p(y)$ en términos de una distribución base $p(x)$ y un `Bijector` que representa $Y = g(X)$. Veámoslo en acción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wttfn9Q-rG6o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.TransformedDistribution 'reshapeMultinomial' batch_shape=[] event_shape=[2, 3] dtype=float32>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_multinomial = tfd.TransformedDistribution(\n",
        "    distribution=six_way_multinomial,\n",
        "    bijector=tfb.Reshape(event_shape_out=[2, 3]))\n",
        "transformed_multinomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh6l4XZdrG6p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-178.21973>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "six_way_multinomial.log_prob([500., 100., 100., 150., 100., 50.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nMHlVrArG6r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-178.21973>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_multinomial.log_prob([[500., 100., 100.], [150., 100., 50.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZNZ02OrG6t"
      },
      "source": [
        "Esto es lo *único* que puede hacer el biyector `Reshape`: no puede convertir dimensiones de eventos en dimensiones de lotes ni viceversa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de7ek-FerG6t"
      },
      "source": [
        "### La distribución Independent\n",
        "\n",
        "La distribución `Independent` sirve para tratar una colección de distribuciones independientes, no necesariamente idénticas (también conocidas como un lote de) como una distribución única. De manera más concisa, `Independent` permite convertir dimensiones en `batch_shape` en dimensiones en `event_shape`. Lo ilustraremos con el ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLwioZPRrG6t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Bernoulli 'Two_By_Five_Bernoulli' batch_shape=[2, 5] event_shape=[] dtype=int32>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_by_five_bernoulli = tfd.Bernoulli(\n",
        "    probs=[[.05, .1, .15, .2, .25], [.3, .35, .4, .45, .5]],\n",
        "    name=\"Two By Five Bernoulli\")\n",
        "two_by_five_bernoulli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-okVviR3rG6v"
      },
      "source": [
        "Podemos pensar en esto como un arreglo de monedas de dos por cinco con las probabilidades de cara asociadas. Evaluemos la probabilidad de un conjunto particular y arbitrario de unos y ceros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yq9jTGIrG6x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
              "array([[-2.9957323 , -0.10536051, -0.16251892, -1.609438  , -0.2876821 ],\n",
              "       [-0.35667497, -0.4307829 , -0.91629076, -0.79850775, -0.6931472 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern = [[1., 0., 0., 1., 0.], [0., 0., 1., 1., 1.]]\n",
        "two_by_five_bernoulli.log_prob(pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9CA19oPrG6y"
      },
      "source": [
        "Podemos utilizar `Independent` para convertir esto en dos \"conjuntos de Bernoulli de cinco\" diferentes, lo cual es útil si queremos considerar una \"fila\" de lanzamientos de monedas que aparecen en un patrón determinado como un resultado único:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iR23BMBrG6z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tfp.distributions.Independent 'Two_Sets_Of_Five' batch_shape=[2] event_shape=[5] dtype=int32>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_sets_of_five = tfd.Independent(\n",
        "    distribution=two_by_five_bernoulli,\n",
        "    reinterpreted_batch_ndims=1,\n",
        "    name=\"Two Sets Of Five\")\n",
        "two_sets_of_five"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRrkesaPrG67"
      },
      "source": [
        "Matemáticamente, estamos calculando la probabilidad logarítmica de cada \"conjunto\" de cinco al sumar las probabilidades logarítmicas de los cinco lanzamientos de moneda \"independientes\" del conjunto, que es de donde la distribución obtiene su nombre:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcM6OgKNrG66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-5.160732 , -3.1954036], dtype=float32)>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_sets_of_five.log_prob(pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krpnUVL9rG7A"
      },
      "source": [
        "Podemos ir aún más lejos y usar `Independent` para crear una distribución donde los eventos individuales sean un conjunto de Bernoulli de dos por cinco:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXSsoidirG7A"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-8.356134>"
            ]
          },
          "execution_count": 0,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_set_of_two_by_five = tfd.Independent(\n",
        "    distribution=two_by_five_bernoulli, reinterpreted_batch_ndims=2,\n",
        "    name=\"One Set Of Two By Five\")\n",
        "one_set_of_two_by_five.log_prob(pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfbfHA4hrG7F"
      },
      "source": [
        "Vale la pena señalar que desde la perspectiva de `sample` el uso de `Independent` no cambia nada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ3NhQEZrG7F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfp.distributions.Bernoulli(\"Two_By_Five_Bernoulli\", batch_shape=[2, 5], event_shape=[], dtype=int32)\n",
            "Sample shape: [3, 5]\n",
            "Returned sample tensor shape: (3, 5, 2, 5)\n",
            "\n",
            "tfp.distributions.Independent(\"Two_Sets_Of_Five\", batch_shape=[2], event_shape=[5], dtype=int32)\n",
            "Sample shape: [3, 5]\n",
            "Returned sample tensor shape: (3, 5, 2, 5)\n",
            "\n",
            "tfp.distributions.Independent(\"One_Set_Of_Two_By_Five\", batch_shape=[], event_shape=[2, 5], dtype=int32)\n",
            "Sample shape: [3, 5]\n",
            "Returned sample tensor shape: (3, 5, 2, 5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "describe_sample_tensor_shapes(\n",
        "    [two_by_five_bernoulli,\n",
        "     two_sets_of_five,\n",
        "     one_set_of_two_by_five],\n",
        "    [[3, 5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usTT7v0trG7H"
      },
      "source": [
        "Para terminar, sugerimos que el lector analice las diferencias y similitudes entre un lote vectorial de distribuciones `Normal` y una distribución `MultivariateNormalDiag` desde una perspectiva de muestreo y probabilidad logarítmica. ¿Cómo podemos usar `Independent` para construir una `MultivariateNormalDiag` a partir de un lote de mensajes `Normal`? (Tenga en cuenta que `MultivariateNormalDiag` en realidad no se implementa de esta manera)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Understanding_TensorFlow_Distributions_Shapes.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
