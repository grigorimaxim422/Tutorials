{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUvWu41mtXa"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "su2RaORHpReL"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztQK2uFpXT-"
      },
      "source": [
        "# Visualización de datos de imágenes en TensorBoard\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/image_summaries\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tensorboard/image_summaries.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tensorboard/image_summaries.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tensorboard/image_summaries.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXRFe_qp5C3"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Utilizando la **API de resumen de imágenes de TensorFlow,** puede registrar fácilmente tensores e imágenes arbitrarias y visualizarlos en TensorBoard. Esto puede ser extremadamente útil para tomar muestras y examinar sus datos de entrada, o para [visualizar las ponderaciones de las capas](http://cs231n.github.io/understanding-cnn/) y [los tensores generados](https://hub.packtpub.com/generative-adversarial-networks-using-keras/). También puede registrar datos de diagnóstico como imágenes que pueden ser útiles en el curso del desarrollo de su modelo.\n",
        "\n",
        "En este tutorial, aprenderá a utilizar la API de resumen de imágenes para visualizar tensores como imágenes. También aprenderá a tomar una imagen arbitraria, convertirla en un tensor y visualizarla en TensorBoard. Trabajará mediante un ejemplo simple pero real que utiliza Resúmenes de imágenes para ayudarle a comprender el rendimiento de su modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG-nnZK9qW9z"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3U5gdCw_nSG3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1qIKtOBrqc9Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.2\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import io\n",
        "import itertools\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq0gyXOGZ3-h"
      },
      "source": [
        "# Descargar el conjunto de datos Fashion-MNIST\n",
        "\n",
        "Va a construir una red neuronal sencilla para clasificar las imágenes del conjunto de datos [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist). Este conjunto de datos contiene 70,000 imágenes en escala de grises de 28x28 sobre productos de moda pertenecientes a 10 categorías, con 7,000 imágenes por categoría.\n",
        "\n",
        "Primero, descargue los datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VmEQwCon3i7m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download the data. The data is already divided into train and test.\n",
        "# The labels are integers representing classes.\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = \\\n",
        "    fashion_mnist.load_data()\n",
        "\n",
        "# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNsjMY0364j4"
      },
      "source": [
        "## Visualizar una sola imagen\n",
        "\n",
        "Para comprender cómo funciona la API de resumen de imágenes, ahora va a registrar simplemente la primera imagen de entrenamiento de su conjunto de entrenamiento en TensorBoard.\n",
        "\n",
        "Antes de hacerlo, examine la forma que adoptan sus datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FxMPcdmvBn9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape:  (28, 28)\n",
            "Label:  9 -> Ankle boot\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape: \", train_images[0].shape)\n",
        "print(\"Label: \", train_labels[0], \"->\", class_names[train_labels[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F8zbUKfBuUt"
      },
      "source": [
        "Observe que la forma de cada imagen del conjunto de datos es un tensor de rango 2 de forma (28, 28), que representa la altura y el ancho.\n",
        "\n",
        "Sin embargo, `tf.summary.image()` espera un tensor de rango 4 que contenga `(batch_size, height, width, channels)`. Por lo tanto, es necesario remodelar los tensores.\n",
        "\n",
        "Está registrando sólo una imagen, así que `batch_size` es 1. Las imágenes se muestran en escala de grises, lo que significa que `channels` es 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yPh-7EWB8IK"
      },
      "outputs": [],
      "source": [
        "# Reshape the image for the Summary API.\n",
        "img = np.reshape(train_images[0], (-1, 28, 28, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAdJDY3FCCwt"
      },
      "source": [
        "Ahora está listo para registrar esta imagen y visualizarla en TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJNpyVyxbVtT"
      },
      "outputs": [],
      "source": [
        "# Clear out any prior log data.\n",
        "!rm -rf logs\n",
        "\n",
        "# Sets up a timestamped log directory.\n",
        "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Creates a file writer for the log directory.\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Using the file writer, log the reshaped image.\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", img, step=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rngALbRogXe6"
      },
      "source": [
        "Ahora, utilice TensorBoard para examinar la imagen. Espere unos segundos a que la interfaz de usuario gire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_X-wIy-lD9f"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8n8YqGlT3-c"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_single.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34enxJjjgWi7"
      },
      "source": [
        "El panel \"Series temporales\" muestra la imagen que acaba de registrar. Es una \"bota tobillera\".\n",
        "\n",
        "La imagen se escala a un tamaño predeterminado para facilitar su visualización. Si desea ver la imagen original sin escalar, marque \"Mostrar tamaño real de la imagen\" en la parte inferior del panel \"Configuración\" situado a la derecha.\n",
        "\n",
        "Pruebe con los controles deslizantes de brillo y contraste para ver cómo afectan a los pixeles de la imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjACE1lAsqUd"
      },
      "source": [
        "## Visualización de múltiples imágenes\n",
        "\n",
        "Registrar un tensor está muy bien, pero ¿y si quisiera registrar múltiples ejemplos de entrenamiento?\n",
        "\n",
        "Simplemente especifique el número de imágenes que desea registrar al pasar los datos a `tf.summary.image()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHUjCXbetIpb"
      },
      "outputs": [],
      "source": [
        "with file_writer.as_default():\n",
        "  # Don't forget to reshape.\n",
        "  images = np.reshape(train_images[0:25], (-1, 28, 28, 1))\n",
        "  tf.summary.image(\"25 training data examples\", images, max_outputs=25, step=0)\n",
        "\n",
        "%tensorboard --logdir logs/train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr6LFQG9UD6z"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_multiple.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-7sZs3XuBBy"
      },
      "source": [
        "## Registro de datos de imágenes arbitrarias\n",
        "\n",
        "¿Y si desea visualizar una imagen que no es un tensor, como una imagen generada por [matplotlib](https://matplotlib.org/)?\n",
        "\n",
        "Se necesita algo de código fuente para convertir el gráfico en un tensor, pero después de esto, estará listo.\n",
        "\n",
        "En el siguiente código, registrará las primeras 25 imágenes como una agradable cuadrícula utilizando la función `subplot()` de matplotlib. A continuación, verá la cuadrícula en TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5U_5WKt8bdQ"
      },
      "outputs": [],
      "source": [
        "# Clear out prior logging data.\n",
        "!rm -rf logs/plots\n",
        "\n",
        "logdir = \"logs/plots/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def image_grid():\n",
        "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "  # Create a figure to contain the plot.\n",
        "  figure = plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "    # Start next subplot.\n",
        "    plt.subplot(5, 5, i + 1, title=class_names[train_labels[i]])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "  \n",
        "  return figure\n",
        "\n",
        "# Prepare the plot\n",
        "figure = image_grid()\n",
        "# Convert to image and log\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "%tensorboard --logdir logs/plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_tIghRsXY7S"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_arbitrary.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZx70BC1zhgW"
      },
      "source": [
        "## Construir un clasificador de imágenes\n",
        "\n",
        "Ahora ponga todo esto junto con un ejemplo real. Después de todo, ¡usted está aquí para hacer aprendizaje automático y no para dibujar imágenes bonitas!\n",
        "\n",
        "Va a utilizar resúmenes de imágenes para comprender lo bien que funciona su modelo mientras entrena un clasificador sencillo para el conjunto de datos Moda-MNIST.\n",
        "\n",
        "En primer lugar, cree un modelo muy simple y compílelo, establezca el optimizador y la función de pérdida. El paso de la compilación también especifica que desea registrar la precisión del clasificador a lo largo del proceso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R74hPWJHzgvZ"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdT_PpZB1UMn"
      },
      "source": [
        "Al entrenar un clasificador, es útil ver la [matriz de confusión](https://en.wikipedia.org/wiki/Confusion_matrix). La matriz de confusión le da un conocimiento detallado del rendimiento de su clasificador en los datos de prueba.\n",
        "\n",
        "Definir una función que calcula la matriz de confusión. Utilizará una conveniente función [Scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) para hacerlo, y luego la representará gráficamente utilizando matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBiXP8-UO8t6"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Compute the labels from the normalized confusion matrix.\n",
        "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lOAl_v26QGq"
      },
      "source": [
        "Ahora está listo para entrenar al clasificador y registrar regularmente la matriz de confusión a lo largo del proceso.\n",
        "\n",
        "Esto es lo que deberá hacer:\n",
        "\n",
        "1. Cree la retrollamada [Keras TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) para registrar las métricas básicas\n",
        "2. Crear un [Keras LambdaCallback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback) para registrar la matriz de confusión al final de cada época.\n",
        "3. Entrene el modelo utilizando Model.fit(), asegurándose de pasar ambas retrollamadas\n",
        "\n",
        "Conforme avanza el entrenamiento, desplácese hacia abajo para ver cómo se pone en marcha el TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utd-vH6hn5RY"
      },
      "outputs": [],
      "source": [
        "# Clear out prior logging data.\n",
        "!rm -rf logs/image\n",
        "\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXQ7-9CF0TPA"
      },
      "outputs": [],
      "source": [
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(test_images)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "  # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6CV7dy-oJZu"
      },
      "outputs": [],
      "source": [
        "# Start TensorBoard.\n",
        "%tensorboard --logdir logs/image\n",
        "\n",
        "# Train the classifier.\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=5,\n",
        "    verbose=0, # Suppress chatty output\n",
        "    callbacks=[tensorboard_callback, cm_callback],\n",
        "    validation_data=(test_images, test_labels),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7PnxGf8Ur6F"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_accuracy.png?raw=1\"/> -->\n",
        "\n",
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/images_cm.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6URWgszz9Jut"
      },
      "source": [
        "Observe que la precisión aumenta tanto en los conjuntos de entrenamiento como en los de validación. Es una buena señal. Pero, ¿cómo se comporta el modelo en subconjuntos específicos de los datos?\n",
        "\n",
        "Desplácese por el panel \"Series temporales\" para visualizar las matrices de confusión registradas. Marque \"Mostrar tamaño real de la imagen\" en la parte inferior del panel \"Configuración\" para ver la matriz de confusión a tamaño completo.\n",
        "\n",
        "De forma predeterminada, el panel muestra el resumen de imágenes del último paso o época registrado. Utilice el control deslizante para ver matrices de confusión anteriores. Observe cómo la matriz cambia significativamente conforme avanza el entrenamiento, con cuadrados más oscuros que se unen a lo largo de la diagonal, y el resto de la matriz tendiendo hacia el 0 y el blanco. ¡Esto significa que su clasificador está mejorando a medida que avanza el entrenamiento! ¡Gran trabajo!\n",
        "\n",
        "La matriz de confusión muestra que este sencillo modelo tiene algunos problemas. A pesar de los grandes progresos, las camisas, las camisetas y los jerseys se confunden entre sí. El modelo necesita más trabajo.\n",
        "\n",
        "Si le interesa, intente mejorar este modelo con una [red convolucional](https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a) (CNN)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_summaries.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
