{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tghWegsjhpkt"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rSGJWC5biBiG"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Iyf5gv5oBq"
      },
      "source": [
        "# Preprocesamiento de datos con TensorFlow Transform\n",
        "\n",
        "***El componente de ingeniería de características de TensorFlow Extended (TFX)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ST8dI25wbA"
      },
      "source": [
        "Nota: Recomendamos ejecutar este tutorial en un bloc de notas de Colab, ¡no es necesario configurarlo! Simplemente haga clic en \"Ejecutar en Google Colab\".\n",
        "\n",
        "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/transform/simple\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/transform/simple.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "<td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tfx/tutorials/transform/simple.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "<td><a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tfx/tutorials/transform/simple.ipynb\"><img width=\"32px\" src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPt5BHTwy_0F"
      },
      "source": [
        "Este bloc de notas de Colab de ejemplo proporciona un ejemplo muy simple de cómo se puede usar <a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/transform/get_started/\">TensorFlow Transform</a> (<code>tf.Transform</code>) para preprocesar datos de manera que se use exactamente el mismo código tanto para entrenar un modelo como para hacer inferencias en producción.\n",
        "\n",
        "TensorFlow Transform es una biblioteca que permite preprocesar datos de entrada para TensorFlow, lo que incluye la creación de características que requieren un paso completo sobre el conjunto de datos de entrenamiento. Por ejemplo, mediante el uso de TensorFlow Transform podría hacer lo siguiente:\n",
        "\n",
        "- Normalizar un valor de entrada a través del uso de la media y la desviación estándar\n",
        "- Convertir cadenas a números enteros mediante la generación de un vocabulario sobre todos los valores de entrada\n",
        "- Convertir valores flotantes en enteros al asignarlos a cubos, en función de la distribución de datos observada\n",
        "\n",
        "TensorFlow tiene soporte integrado para manipulaciones en un solo ejemplo o un lote de ejemplos. `tf.Transform` amplía estas capacidades para permitir pasos completos sobre todo el conjunto de datos de entrenamiento.\n",
        "\n",
        "La salida de `tf.Transform` se exporta como un grafo de TensorFlow que se puede usar tanto para entrenamiento como para servicio. Usar el mismo grafo tanto para el entrenamiento como para el servicio sirve para evitar sesgos, ya que se aplican las mismas transformaciones en ambas etapas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8lD3uQm8m5"
      },
      "source": [
        "### Actualización de pip\n",
        "\n",
        "Para evitar actualizar Pip en un sistema cuando se ejecuta localmente, verifique que se esté ejecutando en Colab. Por supuesto, los sistemas locales se pueden actualizar por separado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmiQXNLZm8z-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiBxgnc-m8-X"
      },
      "source": [
        "### Instale TensorFlow Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2CTKbMNm9I4"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tensorflow_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0mXLOJR_-dv"
      },
      "outputs": [],
      "source": [
        "# This cell is only necessary because packages were installed while python was\n",
        "# running. It avoids the need to restart the runtime when running in Colab.\n",
        "import pkg_resources\n",
        "import importlib\n",
        "\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptgLn2RYuK3"
      },
      "source": [
        "## Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4QXVIM7iglN"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata\n",
        "from tensorflow_transform.tf_metadata import schema_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxOxaaOYRfl7"
      },
      "source": [
        "## Datos: cree algunos datos ficticios\n",
        "\n",
        "Crearemos algunos datos ficticios simples para nuestro ejemplo simple:\n",
        "\n",
        "- `raw_data` son los datos sin procesar iniciales que vamos a preprocesar\n",
        "- `raw_data_metadata` contiene el esquema que nos indica los tipos de cada una de las columnas en `raw_data`. En este caso, es muy sencillo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R236Tkf_ON3"
      },
      "outputs": [],
      "source": [
        "raw_data = [\n",
        "      {'x': 1, 'y': 1, 's': 'hello'},\n",
        "      {'x': 2, 'y': 2, 's': 'world'},\n",
        "      {'x': 3, 'y': 3, 's': 'hello'}\n",
        "  ]\n",
        "\n",
        "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
        "    schema_utils.schema_from_feature_spec({\n",
        "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
        "        's': tf.io.FixedLenFeature([], tf.string),\n",
        "    }))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xexbWmQEBUBZ"
      },
      "source": [
        "## Transformación: cree una función de preprocesamiento\n",
        "\n",
        "La <em>función de preprocesamiento</em> es el concepto más importante de tf.Transform. Una función de preprocesamiento es la que realmente ejecuta la transformación del conjunto de datos. Acepta y devuelve un diccionario de tensores, donde tensor significa <a><code>Tensor</code></a> o <a><code>SparseTensor</code></a>. Hay dos grupos principales de llamadas API que normalmente constituyen el núcleo de una función de preprocesamiento:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zadh6MXLS3eD"
      },
      "source": [
        "1. **TensorFlow Ops:** cualquier función que acepte y devuelva tensores, lo que generalmente significa operaciones de TensorFlow. Estas agregan operaciones de TensorFlow al grafo que transforma datos sin procesar en datos transformados, un vector de características a la vez. Estas se ejecutarán para cada ejemplo, tanto durante el entrenamiento como durante el servicio.\n",
        "2. **Tensorflow Transform Analyzers/Mappers:** cualquiera de los analizadores/asignadores que ofrece tf.Transform. Estos también aceptan y devuelven tensores y, por lo general, contienen una combinación de operaciones de Tensorflow y cálculos de Beam, pero a diferencia de las operaciones de TensorFlow, solo se ejecutan en la canalización de Beam durante el análisis, lo que requiere un paso completo por todo el conjunto de datos de entrenamiento. El cálculo de Beam se ejecuta solo una vez (antes del entrenamiento, durante el análisis) y, por lo general, hace un recorrido completo por todo el conjunto de datos de entrenamiento. Se encargan de crear tensores `tf.constant`, que se agregan a su grafo. Por ejemplo, `tft.min` calcula el mínimo de un tensor sobre el conjunto de datos de entrenamiento.\n",
        "\n",
        "Atención: Cuando aplique su función de preprocesamiento para servir inferencias, las constantes creadas por los analizadores durante el entrenamiento no cambiarán. Si sus datos tienen componentes de tendencia o estacionalidad, planifique en consecuencia.\n",
        "\n",
        "Nota: No es posible llamar directamente la `preprocessing_fn`. Esto significa que llamar `preprocessing_fn(raw_data)` no funcionará. En su lugar, se debe pasar a la API Transform Beam como se muestra en las siguientes celdas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2wANNF_2dCR"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"Preprocess input columns into transformed columns.\"\"\"\n",
        "    x = inputs['x']\n",
        "    y = inputs['y']\n",
        "    s = inputs['s']\n",
        "    x_centered = x - tft.mean(x)\n",
        "    y_normalized = tft.scale_to_0_1(y)\n",
        "    s_integerized = tft.compute_and_apply_vocabulary(s)\n",
        "    x_centered_times_y_normalized = (x_centered * y_normalized)\n",
        "    return {\n",
        "        'x_centered': x_centered,\n",
        "        'y_normalized': y_normalized,\n",
        "        's_integerized': s_integerized,\n",
        "        'x_centered_times_y_normalized': x_centered_times_y_normalized,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSl9qyTCbBKR"
      },
      "source": [
        "## Sintaxis\n",
        "\n",
        "Está casi listo para armar todo y usar <a target=\"_blank\" href=\"https://beam.apache.org/\">Apache Beam</a> para ejecutarlo.\n",
        "\n",
        "Apache Beam usa una <a target=\"_blank\" href=\"https://beam.apache.org/documentation/programming-guide/#applying-transforms\">sintaxis especial para definir e invocar transformaciones</a>. Por ejemplo, en esta línea:\n",
        "\n",
        "```\n",
        "result = pass_this | 'name this step' >> to_this_call\n",
        "```\n",
        "\n",
        "El método `to_this_call` se invoca y se pasa el objeto llamado `pass_this`, y <a target=\"_blank\" href=\"https://stackoverflow.com/questions/50519662/what-does-the-redirection-mean-in-apache-beam-python\">esta operación se conocerá como <code>name this step</code> en un seguimiento de pila</a>. El resultado de la llamada a `to_this_call` se devuelve en `result`. A menudo verá etapas de una canalización encadenadas de esta manera:\n",
        "\n",
        "```\n",
        "result = apache_beam.Pipeline() | 'first step' >> do_this_first() | 'second step' >> do_this_last()\n",
        "```\n",
        "\n",
        "y como comenzó con una nueva canalización, puede continuar así:\n",
        "\n",
        "```\n",
        "next_result = result | 'doing more stuff' >> another_function()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kLDSxOQ8xgg"
      },
      "source": [
        "## Unimos todo\n",
        "\n",
        "Ahora estamos listos para transformar nuestros datos. Usaremos Apache Beam con un ejecutor directo y proporcionaremos tres entradas:\n",
        "\n",
        "1. `raw_data`: los datos de entrada sin procesar que creamos anteriormente\n",
        "2. `raw_data_metadata`: el esquema de los datos sin procesar\n",
        "3. `preprocessing_fn`: la función que creamos para ejecutar nuestra transformación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAF9w7RTZU7c"
      },
      "outputs": [],
      "source": [
        "def main(output_dir):\n",
        "  # Ignore the warnings\n",
        "  with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "    transformed_dataset, transform_fn = (  # pylint: disable=unused-variable\n",
        "        (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\n",
        "            preprocessing_fn))\n",
        "\n",
        "  transformed_data, transformed_metadata = transformed_dataset  # pylint: disable=unused-variable\n",
        "\n",
        "  # Save the transform_fn to the output_dir\n",
        "  _ = (\n",
        "      transform_fn\n",
        "      | 'WriteTransformFn' >> tft_beam.WriteTransformFn(output_dir))\n",
        "\n",
        "  return transformed_data, transformed_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZPQl0X19ni2"
      },
      "outputs": [],
      "source": [
        "output_dir = pathlib.Path(tempfile.mkdtemp())\n",
        "\n",
        "transformed_data, transformed_metadata = main(str(output_dir))\n",
        "\n",
        "print('\\nRaw data:\\n{}\\n'.format(pprint.pformat(raw_data)))\n",
        "print('Transformed data:\\n{}'.format(pprint.pformat(transformed_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO6LyTneNndy"
      },
      "source": [
        "## ¿Es esta la respuesta correcta?\n",
        "\n",
        "Anteriormente, usamos `tf.Transform` para hacer esto:\n",
        "\n",
        "```\n",
        "x_centered = x - tft.mean(x)\n",
        "y_normalized = tft.scale_to_0_1(y)\n",
        "s_integerized = tft.compute_and_apply_vocabulary(s)\n",
        "x_centered_times_y_normalized = (x_centered * y_normalized)\n",
        "```\n",
        "\n",
        "- **x_centered**: con la entrada de `[1, 2, 3]` la media de x es 2, y la restamos de x para centrar nuestros valores de x en 0. Entonces, nuestro resultado de `[-1.0, 0.0, 1.0]` es correcto.\n",
        "- **y_normalized**: queríamos escalar nuestros valores de y entre 0 y 1. Nuestra entrada fue `[1, 2, 3]`, por lo que nuestro resultado de `[0.0, 0.5, 1.0]` es correcto.\n",
        "- **s_integerized**: queríamos asignar nuestras cadenas a índices en un vocabulario, y solo había 2 palabras en nuestro vocabulario (\"hola\" y \"mundo\"). Entonces, con la entrada de `[\"hello\", \"world\", \"hello\"]` nuestro resultado de `[0, 1, 0]` es correcto. Dado que \"hola\" aparece con mayor frecuencia en estos datos, será la primera entrada en el vocabulario.\n",
        "- **x_centered_times_y_normalized**: queríamos crear una nueva característica al cruzar `x_centered` con `y_normalized` mediante una multiplicación. Tenga en cuenta que esto multiplica los resultados, no los valores originales, y nuestro nuevo resultado de `[-0.0, 0.0, 1.0]` es correcto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXw790Sr8Jws"
      },
      "source": [
        "## Use la `transform_fn` resultante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We4Mafrq8id6"
      },
      "outputs": [],
      "source": [
        "!ls -l {output_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoaaAXxk_vWP"
      },
      "source": [
        "El directorio `transform_fn/` contiene una implementación `tf.saved_model` con todas las constantes de los resultados del análisis de transformación de tensorflow integrados en el grafo.\n",
        "\n",
        "Es posible cargar esto directamente con `tf.saved_model.load`, pero no es fácil de usar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz8dqFW6ANJQ"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(str(output_dir/'transform_fn'))\n",
        "loaded.signatures['serving_default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCugaxMiBosA"
      },
      "source": [
        "Una mejor opción sería cargarlo con `tft.TFTransformOutput`. El método `TFTransformOutput.transform_features_layer` devuelve un objeto `tft.TransformFeaturesLayer` que se puede usar para aplicar la transformación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNd4r2gJ75nx"
      },
      "outputs": [],
      "source": [
        "tf_transform_output = tft.TFTransformOutput(output_dir)\n",
        "\n",
        "tft_layer = tf_transform_output.transform_features_layer()\n",
        "tft_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se-M1zx49kTY"
      },
      "source": [
        "El objeto `tft.TransformFeaturesLayer` espera un diccionario de funciones por lotes. Por lo tanto, debe crear un `Dict[str, tf.Tensor]` de `List[Dict[str, Any]]` en `raw_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nyE1fVj82Gp"
      },
      "outputs": [],
      "source": [
        "raw_data_batch = {\n",
        "    's': tf.constant([ex['s'] for ex in raw_data]),\n",
        "    'x': tf.constant([ex['x'] for ex in raw_data], dtype=tf.float32),\n",
        "    'y': tf.constant([ex['y'] for ex in raw_data], dtype=tf.float32),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "016sJ_cD_gVC"
      },
      "source": [
        "Puede usar `tft.TransformFeaturesLayer` por sí solo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIXJYE0Z9Mrs"
      },
      "outputs": [],
      "source": [
        "transformed_batch = tft_layer(raw_data_batch)\n",
        "\n",
        "{key: value.numpy() for key, value in transformed_batch.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBfO5cp-8pqb"
      },
      "source": [
        "## Exporte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3SN7D-FzrZ3"
      },
      "source": [
        "Un caso de uso más típico sería usar `tf.Transform` para aplicar la transformación a los conjuntos de datos de entrenamiento y evaluación (consulte el [siguiente tutorial](census.ipynb) para ver un ejemplo). Luego, después del entrenamiento, antes de exportar el modelo, adjunte `tft.TransformFeaturesLayer` como primera capa para que pueda exportarlo como parte de su `tf.saved_model`. Continúe leyendo para ver un ejemplo concreto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYV_oy5s9Dn9"
      },
      "source": [
        "### Un modelo de entrenamiento de ejemplo\n",
        "\n",
        "A continuación, se muestra un modelo que cumple con las siguientes características:\n",
        "\n",
        "1. toma el lote transformado,\n",
        "2. los apila todos juntos en una matriz simple `(batch, features)`,\n",
        "3. los ejecuta a través de algunas capas densas, y\n",
        "4. produce 10 salidas lineales.\n",
        "\n",
        "En un caso de uso real, se aplicaría una codificación única a la función `s_integerized`.\n",
        "\n",
        "Podría entrenar este modelo en un conjunto de datos transformado por `tf.Transform`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWiEo1ZUzp4x"
      },
      "outputs": [],
      "source": [
        "class StackDict(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    values = [\n",
        "        tf.cast(v, tf.float32)\n",
        "        for k,v in sorted(inputs.items(), key=lambda kv: kv[0])]\n",
        "    return tf.stack(values, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0QJpoWT1aUD"
      },
      "outputs": [],
      "source": [
        "class TrainedModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__(self)\n",
        "    self.concat = StackDict()\n",
        "    self.body = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    x = self.concat(inputs)\n",
        "    return self.body(x, training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkMwREIx2fkD"
      },
      "outputs": [],
      "source": [
        "trained_model = TrainedModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBwnbh1Q-TBK"
      },
      "source": [
        "Imaginemos que entrenamos el modelo.\n",
        "\n",
        "```\n",
        "trained_model.compile(loss=..., optimizer='adam')\n",
        "trained_model.fit(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notFxUC0AFs6"
      },
      "source": [
        "Este modelo se ejecuta en las entradas transformadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2KJ8nGt228O"
      },
      "outputs": [],
      "source": [
        "trained_model_output = trained_model(transformed_batch)\n",
        "trained_model_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzWs35Ki6M5c"
      },
      "source": [
        "### Un ejemplo de envoltorio de exportación\n",
        "\n",
        "Imaginemos que hemos entrenado el modelo anterior y queremos exportarlo.\n",
        "\n",
        "Será conveniente incluir la función de transformación en el modelo exportado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe-nbN123qUt"
      },
      "outputs": [],
      "source": [
        "class ExportModel(tf.Module):\n",
        "  def __init__(self, trained_model, input_transform):\n",
        "    self.trained_model = trained_model\n",
        "    self.input_transform = input_transform\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, inputs, training=None):\n",
        "    x = self.input_transform(inputs)\n",
        "    return self.trained_model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLUIO-Y87AC0"
      },
      "outputs": [],
      "source": [
        "export_model = ExportModel(trained_model=trained_model,\n",
        "                           input_transform=tft_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFDYQDgU7ozE"
      },
      "source": [
        "Este modelo combinado funciona con los datos sin procesar y produce exactamente los mismos resultados que llamar directamente al modelo entrenado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqwHTex27ILk"
      },
      "outputs": [],
      "source": [
        "export_model_output = export_model(raw_data_batch)\n",
        "export_model_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQ6_Dfd7xws"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(abs(export_model_output - trained_model_output)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r-lH_nh8PM-"
      },
      "source": [
        "Este `export_model` incluye `tft.TransformFeaturesLayer` y es completamente autónomo. Puede guardarlo y restaurarlo en otro entorno y seguir obteniendo exactamente el mismo resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK17CShl8F7s"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp(suffix='tft')\n",
        "\n",
        "tf.saved_model.save(export_model, model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTF-yRnA9yrL"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load(model_dir)\n",
        "\n",
        "reloaded_model_output = reloaded(raw_data_batch)\n",
        "reloaded_model_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFx1I6FQ9_mj"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(abs(export_model_output - reloaded_model_output)).numpy()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tghWegsjhpkt",
        "cSl9qyTCbBKR",
        "NO6LyTneNndy"
      ],
      "name": "simple.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
