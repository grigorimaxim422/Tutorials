{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq-riZs-TJGt"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LEvnopDoTC4M"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSRG6qmtTRSk"
      },
      "source": [
        "# API de escritura de metadatos de TensorFlow Lite\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlzjEt4Txr0x"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/convert/metadata_writer_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/lite/models/convert/metadata_writer_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0gwEhfRYat6"
      },
      "source": [
        "El formato de [metadatos del modelo TensorFlow Lite](https://www.tensorflow.org/lite/models/convert/metadata) es un estándar de descripción del modelo. Éste cuenta con una rica semántica para la información general del modelo, las entradas/salidas y los archivos asociados, por lo que el modelo es autodescriptivo e intercambiable.\n",
        "\n",
        "Los Metadatos de Modelo se usan actualmente en los dos casos de uso principales siguientes:\n",
        "\n",
        "1. **Habilitar la inferencia sencilla de modelos utilizando la [Librería de tareas](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview) de TensorFlow Lite y las [herramientas de codificación](https://www.tensorflow.org/lite/inference_with_metadata/codegen)**. Los metadatos del modelo contienen la información obligatoria necesaria durante la inferencia, como los archivos de etiquetas en la clasificación de imágenes, la frecuencia de muestreo de la entrada de audio en la clasificación de audio y el tipo de tokenizador para procesar la cadena de entrada en los modelos de lenguaje natural.\n",
        "\n",
        "2. **Habilitar que los creadores de modelos incluyan documentación**, como la descripción de las entradas/salidas del modelo o cómo usarlo. Los usuarios del modelo pueden consultar esta documentación a través de herramientas de visualización como [Netron](https://netron.app/).\n",
        "\n",
        "La API del escritor de metadatos de TensorFlow Lite ofrece una API fácil de usar para crear metadatos de modelo para tareas de ML populares soportadas por la librería de tareas TFLite. Este bloc de notas muestra ejemplos sobre cómo se deben rellenar los metadatos para las siguientes tareas a continuación:\n",
        "\n",
        "- [Clasificadores de imágenes](#image_classifiers)\n",
        "- [Detectores de objetos](#object_detectors)\n",
        "- [Segmentadores de imágenes](#image_segmenters)\n",
        "- [Clasificadores de lenguaje natural](#nl_classifiers)\n",
        "- [Clasificadores de audio](#audio_classifiers)\n",
        "\n",
        "Los escritores de metadatos para los clasificadores de lenguaje natural BERT y los contestadores de preguntas BERT estarán disponibles próximamente.\n",
        "\n",
        "Si desea añadir metadatos para casos de uso no soportados, use la [API de Python Flatbuffers](https://www.tensorflow.org/lite/models/convert/metadata#adding_metadata). Consulte los tutoriales [aquí](https://www.tensorflow.org/lite/models/convert/metadata#adding_metadata).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRIGdA4T6tO"
      },
      "source": [
        "## Requisitos previos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVTD2KSyotBK"
      },
      "source": [
        "Instale el paquete Pypi de soporte de TensorFlow Lite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-8xSrSvUg-6"
      },
      "outputs": [],
      "source": [
        "!pip install tflite-support-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYS87Odpxef"
      },
      "source": [
        "## Crear metadatos de modelo para la librería de tareas y Codegen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLxv541TqTim"
      },
      "source": [
        "<a name=\"image_classifiers\"></a>\n",
        "\n",
        "### Clasificadores de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s41TjCGlsyEF"
      },
      "source": [
        "Vea los [requisitos de compatibilidad del modelo de clasificador de imágenes](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier#model_compatibility_requirements) para más detalles sobre el formato de modelo compatible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KsPKmg8T9-8"
      },
      "source": [
        "Paso 1: Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhgNqEtWrwB3"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WBgiFdsiIQ"
      },
      "source": [
        "Paso 2: Descargue el clasificador de imágenes de ejemplo [mobilenet_v2_1.0_224.tflite](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite), y el [archivo de etiqueta](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WgSBbNet-Tt"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite -o mobilenet_v2_1.0_224.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt -o mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALtlz7woweHe"
      },
      "source": [
        "Paso 3: Cree el escritor de metadatos y rellénelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SMEBBt2r-W6"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"mobilenet_v2_1.0_224.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"mobilenet_labels.txt\"\n",
        "_SAVE_TO_PATH = \"mobilenet_v2_1.0_224_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhhTDkr-uf0n"
      },
      "source": [
        "<a name=\"object_detectors\"></a>\n",
        "\n",
        "### Detectores de objetos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL9GssnTuf0n"
      },
      "source": [
        "Vea los [requisitos de compatibilidad del modelo de detector de objetos](https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector#model_compatibility_requirements) para más detalles sobre el formato de modelo admitido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-HUTEtHuf0n"
      },
      "source": [
        "Paso 1: Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_NIROeouf0o"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM6jijiUuf0o"
      },
      "source": [
        "Paso 2: Descargue el detector de objetos de ejemplo, [ssd_mobilenet_v1.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite), y el [archivo label](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i_BBfGzuf0o"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite -o ssd_mobilenet_v1.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt -o ssd_mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9T3eSDwsnd"
      },
      "source": [
        "Paso 3: Cree el escritor de metadatos y rellénelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMGGeJfCuf0p"
      },
      "outputs": [],
      "source": [
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        "_MODEL_PATH = \"ssd_mobilenet_v1.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"ssd_mobilenet_labels.txt\"\n",
        "_SAVE_TO_PATH = \"ssd_mobilenet_v1_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT0Oa0SU6uGS"
      },
      "source": [
        "<a name=\"image_segmenters\"></a>\n",
        "\n",
        "### Segmentadores de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaFQmg-S6uGW"
      },
      "source": [
        "Vea los [requisitos de compatibilidad del modelo de segmentador de imágenes](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_segmenter#model_compatibility_requirements) para más detalles sobre el formato de modelo compatible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiktANhj6uGX"
      },
      "source": [
        "Paso 1: Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Lrw3op6uGX"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_segmenter\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFs8Oyi6uGX"
      },
      "source": [
        "Paso 2: Descargue el segmentador de imágenes de ejemplo, [deeplabv3.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/deeplabv3.tflite), y el [archivo de etiquetas](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/labelmap.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feQDH0bN6uGY"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/deeplabv3.tflite -o deeplabv3.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_segmenter/labelmap.txt -o deeplabv3_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LhiAbJM6uGY"
      },
      "source": [
        "Paso 3: Cree el escritor de metadatos y rellénelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yot8xLI46uGY"
      },
      "outputs": [],
      "source": [
        "ImageSegmenterWriter = image_segmenter.MetadataWriter\n",
        "_MODEL_PATH = \"deeplabv3.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"deeplabv3_labels.txt\"\n",
        "_SAVE_TO_PATH = \"deeplabv3_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageSegmenterWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnvM80e7AG-h"
      },
      "source": [
        "<a name=\"nl_classifiers\"></a> ###clasificadores de lenguaje natural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfOPhFwOAG-k"
      },
      "source": [
        "Vea los [requisitos de compatibilidad del modelo de clasificador de lenguaje natural](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier#model_compatibility_requirements) para más detalles sobre el formato del modelo admitido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJ7tvuwAG-k"
      },
      "source": [
        "Paso 1: Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FGVyb2iAG-k"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import nl_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIg7rATpAG-l"
      },
      "source": [
        "Paso 2: Descargue el clasificador de lenguaje natural de ejemplo, [movie_review.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/movie_review.tflite), el [archivo de etiquetas](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/labels.txt), y el [archivo de vocabulario](https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/nl_classifier/vocab.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzuQcti2AG-l"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/movie_review.tflite -o movie_review.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/nl_classifier/labels.txt -o movie_review_labels.txt\n",
        "!curl -L https://storage.googleapis.com/download.tensorflow.org/models/tflite_support/nl_classifier/vocab.txt -o movie_review_vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxUtHdeAG-m"
      },
      "source": [
        "Paso 3: Cree el escritor de metadatos y rellénelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGPWzRuHAG-m"
      },
      "outputs": [],
      "source": [
        "NLClassifierWriter = nl_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"movie_review.tflite\"\n",
        "# Task Library expects label files and vocab files that are in the same formats\n",
        "# as the ones below.\n",
        "_LABEL_FILE = \"movie_review_labels.txt\"\n",
        "_VOCAB_FILE = \"movie_review_vocab.txt\"\n",
        "# NLClassifier supports tokenize input string using the regex tokenizer. See\n",
        "# more details about how to set up RegexTokenizer below:\n",
        "# https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/metadata_writers/metadata_info.py#L130\n",
        "_DELIM_REGEX_PATTERN = r\"[^\\w\\']+\"\n",
        "_SAVE_TO_PATH = \"moview_review_metadata.tflite\"\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = nl_classifier.MetadataWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH),\n",
        "    metadata_info.RegexTokenizerMd(_DELIM_REGEX_PATTERN, _VOCAB_FILE),\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv0WDnzW711f"
      },
      "source": [
        "<a name=\"audio_classifiers\"></a>\n",
        "\n",
        "### Clasificadores de audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqP7X8jww8pL"
      },
      "source": [
        "Vea los [requisitos de compatibilidad del modelo de clasificador de audio](https://www.tensorflow.org/lite/inference_with_metadata/task_library/audio_classifier#model_compatibility_requirements) para más detalles sobre el formato de modelo compatible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RToKepxw8pL"
      },
      "source": [
        "Paso 1: Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjddvTXKw8pL"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import audio_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar418rH6w8pL"
      },
      "source": [
        "Paso 2: Descargue el clasificador de audio de ejemplo, [yamnet.tflite](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_wavin_quantized_mel_relu6.tflite), y el [archivo de etiquetas](https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_521_labels.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eQY6znmw8pM"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_wavin_quantized_mel_relu6.tflite -o yamnet.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/audio_classifier/yamnet_521_labels.txt -o yamnet_labels.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TYP5w0Ew8pM"
      },
      "source": [
        "Paso 3: Cree el escritor de metadatos y rellénelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDlSczBQw8pM"
      },
      "outputs": [],
      "source": [
        "AudioClassifierWriter = audio_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"yamnet.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"yamnet_labels.txt\"\n",
        "# Expected sampling rate of the input audio buffer.\n",
        "_SAMPLE_RATE = 16000\n",
        "# Expected number of channels of the input audio buffer. Note, Task library only\n",
        "# support single channel so far.\n",
        "_CHANNELS = 1\n",
        "_SAVE_TO_PATH = \"yamnet_metadata.tflite\"\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = AudioClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), _SAMPLE_RATE, _CHANNELS, [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoRLs84yNAJR"
      },
      "source": [
        "## Crear metadatos de modelo con información semántica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxXsOBknOGJ2"
      },
      "source": [
        "Puede introducir más información descriptiva sobre el modelo y cada tensor a través de la API del escritor de metadatos para ayudar a mejorar la comprensión del modelo. Puede hacerlo a través del método 'create_from_metadata_info' de cada escritor de metadatos. En general, puede introducir los datos a través de los parámetros de 'create_from_metadata_info', es decir, `general_md`, `input_md`, y `output_md`. Vea el ejemplo siguiente para crear un modelo rico en metadatos para clasificadores de imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-LW6nrcQ9lv"
      },
      "source": [
        "Paso 1: Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsL_egYcRGw3"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import metadata_info\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support import metadata_schema_py_generated as _metadata_fb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UWck_8uRboF"
      },
      "source": [
        "Paso 2: Descargue el clasificador de imágenes de ejemplo [mobilenet_v2_1.0_224.tflite](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite), y el [archivo de etiqueta](https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqJ-jh-PRVdk"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/mobilenet_v2_1.0_224.tflite -o mobilenet_v2_1.0_224.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/image_classifier/labels.txt -o mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4I5wJMQRxzb"
      },
      "source": [
        "Paso 3: Cree el modelo y la información del tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urd7HDuaR_HC"
      },
      "outputs": [],
      "source": [
        "model_buffer = writer_utils.load_file(\"mobilenet_v2_1.0_224.tflite\")\n",
        "\n",
        "# Create general model information.\n",
        "general_md = metadata_info.GeneralMd(\n",
        "    name=\"ImageClassifier\",\n",
        "    version=\"v1\",\n",
        "    description=(\"Identify the most prominent object in the image from a \"\n",
        "                 \"known set of categories.\"),\n",
        "    author=\"TensorFlow Lite\",\n",
        "    licenses=\"Apache License. Version 2.0\")\n",
        "\n",
        "# Create input tensor information.\n",
        "input_md = metadata_info.InputImageTensorMd(\n",
        "    name=\"input image\",\n",
        "    description=(\"Input image to be classified. The expected image is \"\n",
        "                 \"128 x 128, with three channels (red, blue, and green) per \"\n",
        "                 \"pixel. Each element in the tensor is a value between min and \"\n",
        "                 \"max, where (per-channel) min is [0] and max is [255].\"),\n",
        "    norm_mean=[127.5],\n",
        "    norm_std=[127.5],\n",
        "    color_space_type=_metadata_fb.ColorSpaceType.RGB,\n",
        "    tensor_type=writer_utils.get_input_tensor_types(model_buffer)[0])\n",
        "\n",
        "# Create output tensor information.\n",
        "output_md = metadata_info.ClassificationTensorMd(\n",
        "    name=\"probability\",\n",
        "    description=\"Probabilities of the 1001 labels respectively.\",\n",
        "    label_files=[\n",
        "        metadata_info.LabelFileMd(file_path=\"mobilenet_labels.txt\",\n",
        "                                  locale=\"en\")\n",
        "    ],\n",
        "    tensor_type=writer_utils.get_output_tensor_types(model_buffer)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5aL5Uxkf4aO"
      },
      "source": [
        "Paso 4: Cree el escritor de metadatos y rellénelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iWIwdqEf_mr"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_from_metadata_info(\n",
        "    model_buffer, general_md, input_md, output_md)\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78vuu6np5sb"
      },
      "source": [
        "## Lea los metadatos con que se llenó su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWt-4oOselo"
      },
      "source": [
        "Puede visualizar los metadatos y archivos asociados en un modelo TFLite mediante el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D13YPUsp5VT"
      },
      "outputs": [],
      "source": [
        "from tflite_support import metadata\n",
        "\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(\"mobilenet_v2_1.0_224_metadata.tflite\")\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "\n",
        "print(\"Associated file(s) populated:\")\n",
        "for file_name in displayer.get_packed_associated_file_list():\n",
        "  print(\"file name: \", file_name)\n",
        "  print(\"file content:\")\n",
        "  print(displayer.get_associated_file_buffer(file_name))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Mq-riZs-TJGt"
      ],
      "name": "metadata_writer_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
