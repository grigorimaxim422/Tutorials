{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Clasificación de texto con Model Maker de TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/lite/models/modify/model_maker/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/lite/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/lite/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a>\n",
        "</td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/lite/models/modify/model_maker/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "La biblioteca [Model Maker de TensorFlow Lite](https://www.tensorflow.org/lite/models/modify/model_maker) simplifica el proceso de adaptación y conversión de un modelo TensorFlow a unos datos de entrada concretos cuando se implementa este modelo para aplicaciones de ML en dispositivos.\n",
        "\n",
        "Este bloc muestra un ejemplo de principio a fin que utiliza la biblioteca Model Maker para ilustrar la adaptación y conversión de un modelo de clasificación de texto de uso común para clasificar reseñas de películas en un dispositivo móvil. El modelo de clasificación de texto clasifica el texto en categorías predefinidas. Las entradas deben ser texto preprocesado y las salidas son las probabilidades de las categorías. El conjunto de datos usado en este tutorial son críticas de películas positivas y negativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Requisitos previos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "### Instalar los paquetes necesarios\n",
        "\n",
        "Para ejecutar este ejemplo, instale los paquetes necesarios, incluido el paquete Model Maker del repositorio [GitHub](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker\n",
        "!pip uninstall tflite_support_nightly\n",
        "!pip install tflite_support_nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lRhVK9Q_0U"
      },
      "source": [
        "Importe los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.text_classifier import AverageWordVecSpec\n",
        "from tflite_model_maker.text_classifier import DataLoader\n",
        "\n",
        "from tflite_support.task import core\n",
        "from tflite_support.task import processor\n",
        "from tflite_support.task import text\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "### Descargar los datos de entrenamiento de muestra.\n",
        "\n",
        "En este tutorial, usaremos el [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank), que es una de las tareas del banco de pruebas [GLUE](https://gluebenchmark.com/). Contiene 67,349 reseñas de películas para el entrenamiento y 872 reseñas de películas para las pruebas. El conjunto de datos tiene dos clases: críticas de películas positivas y negativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BSkxWg6Rhx"
      },
      "outputs": [],
      "source": [
        "data_dir = tf.keras.utils.get_file(\n",
        "      fname='SST-2.zip',\n",
        "      origin='https://dl.fbaipublicfiles.com/glue/data/SST-2.zip',\n",
        "      extract=True)\n",
        "data_dir = os.path.join(os.path.dirname(data_dir), 'SST-2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPYTbGrizcTC"
      },
      "source": [
        "El conjunto de datos SST-2 se almacena en formato TSV. La única diferencia entre TSV y CSV es que TSV utiliza un tabulador `\\t` como delimitador en lugar de una coma `,` en el formato CSV.\n",
        "\n",
        "Éstas son las 5 primeras líneas del conjunto de datos de entrenamiento. label=0 significa negativo, label=1 significa positivo.\n",
        "\n",
        "frase | etiqueta |  |  |\n",
        "--- | --- | --- | --- | ---\n",
        "ocultar nuevas secreciones de las unidades parentales | 0 |  |  |\n",
        "no tiene ingenio, sólo gags trabajados | 0 |  |  |\n",
        "que ama a sus personajes y comunica algo bastante hermoso sobre la naturaleza humana | 1 |  |  |\n",
        "permanece totalmente satisfecho de seguir siendo el mismo a lo largo de | 0 |  |  |\n",
        "con los peores clichés de La Venganza de los Nerds que los cineastas pudieron desenterrar | 0 |  |  |\n",
        "\n",
        "Después, cargaremos el conjunto de datos en un marco de datos Pandas y cambiaremos los nombres de las etiquetas actuales (`0` y `1`) por otros más legibles para los humanos (`negative` y `positive`) y los usaremos para el entrenamiento del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLNaOXnl3JQB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def replace_label(original_file, new_file):\n",
        "  # Load the original file to pandas. We need to specify the separator as\n",
        "  # '\\t' as the training data is stored in TSV format\n",
        "  df = pd.read_csv(original_file, sep='\\t')\n",
        "\n",
        "  # Define how we want to change the label name\n",
        "  label_map = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "  # Excute the label change\n",
        "  df.replace({'label': label_map}, inplace=True)\n",
        "\n",
        "  # Write the updated dataset to a new file\n",
        "  df.to_csv(new_file)\n",
        "\n",
        "# Replace the label name for both the training and test dataset. Then write the\n",
        "# updated CSV dataset to the current folder.\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'train.tsv')), 'train.csv')\n",
        "replace_label(os.path.join(os.path.join(data_dir, 'dev.tsv')), 'dev.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xushUyZXqP59"
      },
      "source": [
        "## Inicio rápido\n",
        "\n",
        "El entrenamiento de un modelo de clasificación de textos consta de cinco pasos:\n",
        "\n",
        "**Paso 1. Seleccione una arquitectura de modelo de clasificación de texto.**\n",
        "\n",
        "Aquí usamos la arquitectura del modelo de incorporación de palabras promedio, que producirá un modelo pequeño y rápido con una precisión decente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug6gR9qyHui"
      },
      "source": [
        "Model Maker también admite otras arquitecturas de modelos como [BERT](https://arxiv.org/abs/1810.04805). Si está interesado en conocer otras arquitecturas, consulte la sección [Elija una arquitectura de modelo para el Clasificador de texto](#scrollTo=kJ_B8fMDOhMR) más abajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5U-A3tw6Y27"
      },
      "source": [
        "**Paso 2.   Cargue los datos de entrenamiento y de prueba y, a continuación, preprocesarlos de acuerdo con un `model_spec` específico.**\n",
        "\n",
        "Model Maker puede tomar datos de entrada en formato CSV. Cargaremos el conjunto de datos de entrenamiento y de prueba con los nombres de etiquetas legibles por humanos que se crearon anteriormente.\n",
        "\n",
        "Cada arquitectura de modelo requiere que los datos de entrada se procesen de una manera determinada. `DataLoader` lee el requisito desde `model_spec` y ejecuta automáticamente el preprocesamiento necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD5BvzWe6YKa"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "**Paso 3. Entrene el modelo TensorFlow con los datos de entrenamiento.**\n",
        "\n",
        "El modelo de incorporación de palabras promedio usa `batch_size = 32` de forma predeterminada. Por lo tanto, verá que se necesitan 2104 pasos para recorrer las 67,349 frases del conjunto de datos de entrenamiento. Entrenaremos el modelo durante 10 épocas, lo que significa recorrer el conjunto de datos de entrenamiento 10 veces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=spec, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "**Paso 4. Evalúe el modelo con los datos de prueba.**\n",
        "\n",
        "Después de entrenar el modelo de clasificación de texto usando las frases del conjunto de datos de entrenamiento, usaremos las 872 frases restantes del conjunto de datos de prueba para evaluar cómo se comporta el modelo frente a nuevos datos que nunca ha visto antes.\n",
        "\n",
        "Como el tamaño predeterminado del lote es 32, se necesitarán 28 pasos para recorrer las 872 frases del conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "**Paso 5. Exporte como modelo TensorFlow Lite.**\n",
        "\n",
        "Vamos a exportar la clasificación de texto que hemos entrenado en el formato TensorFlow Lite. Especificaremos en qué carpeta exportar el modelo. De forma predeterminada, el modelo TFLite flotante se exporta para la arquitectura del modelo de incorporación de palabras Promedio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='average_word_vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxaf3x_7OfB"
      },
      "source": [
        "Puede descargar el archivo del modelo de TensorFlow Lite usando la barra lateral izquierda de Colab. Vaya a la carpeta `average_word_vec` tal y como especificamos en el parámetro `export_dir` anterior, haga clic con el botón derecho del ratón en el archivo `model.tflite` y seleccione `Descargar` para descargarlo en su computadora local.\n",
        "\n",
        "Este modelo puede integrarse en una app Android o iOS usando la [API NLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) de la [Biblioteca de tareas TensorFlow Lite](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\n",
        "\n",
        "Consulte la app de ejemplo de [Clasificación de textos de TFLite](https://github.com/tensorflow/examples/blob/master/lite/examples/text_classification/android/lib_task_api/src/main/java/org/tensorflow/lite/examples/textclassification/client/TextClassificationClient.java#L54) para obtener más detalles sobre cómo se usa el modelo en una app operativa.\n",
        "\n",
        "*Nota 1: Android Studio Model Binding aún no admite la clasificación de texto, por lo que deberá usar la biblioteca de tareas de TensorFlow Lite.*\n",
        "\n",
        "*Nota 2: Existe un archivo `model.json` en la misma carpeta que el modelo TFLite. Contiene la representación JSON de los [metadatos](https://www.tensorflow.org/lite/models/convert/metadata) incluidos en el modelo de TensorFlow Lite. Los metadatos del modelo ayudan a la biblioteca de tareas de TFLite a saber qué hace el modelo y cómo preprocesar/postprocesar los datos para el modelo. No necesita descargar el archivo `model.json` ya que sólo tiene fines informativos y su contenido ya se encuentra dentro del archivo TFLite.*\n",
        "\n",
        "*Nota 3: Si entrena un modelo de clasificación de texto utilizando la arquitectura MobileBERT o BERT-Base, tendrá que usar la [API BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) en su lugar para integrar el modelo entrenado en una app móvil.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65ctmtW7_FF"
      },
      "source": [
        "Las siguientes secciones recorren el ejemplo paso a paso para mostrar más detalles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izO7NU7unYot"
      },
      "source": [
        "**Paso 6: Utilice la `biblioteca de tareas TFLite` para hacer una demo de cómo usar los modelos entrenados.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDov6P4wppHO"
      },
      "source": [
        "Lea el archivo dev.csv en los datos de frases para predecir con el modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWwvHmIltQC2"
      },
      "outputs": [],
      "source": [
        "sentence_data = pd.read_csv('/content/dev.csv', index_col=0)\n",
        "sentence_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_-bejm5vRBf"
      },
      "source": [
        "Parámetro de configuración del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAEEs3_3vPz5"
      },
      "outputs": [],
      "source": [
        "# Name of the TFLite text classification model.\n",
        "_MODEL = '/content/average_word_vec/model.tflite'\n",
        "# Whether to run the model on EdgeTPU.\n",
        "_ENABLE_EDGETPU = False\n",
        "# Number of CPU threads to run the model.\n",
        "_NUM_THREADS = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bInGjRcOtQbn"
      },
      "source": [
        "Inicializar el modelo\n",
        "\n",
        "También podemos cambiar los parámetros como `file_name`, `use_coral`, y `num_threads` que pueden afectar a los resultados del modelo. Los parámetros que puede modificar son:\n",
        "\n",
        "- `file_name`: Nombre del modelo de clasificación de imágenes TFLite.\n",
        "- `use_coral`: Si es verdadero, la inferencia se delegará a un dispositivo TPU Coral Edge conectado.\n",
        "- `num_threads`: Número de hilos de CPU para ejecutar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Haham4qT8hmV"
      },
      "outputs": [],
      "source": [
        "# Initialize the text classification model.\n",
        "base_options = core.BaseOptions(file_name=_MODEL, use_coral=_ENABLE_EDGETPU, num_threads=_NUM_THREADS)\n",
        "options = text.NLClassifierOptions(base_options)\n",
        "\n",
        "# Create NLClassifier from options.\n",
        "classifier = text.NLClassifier.create_from_options(options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HLl9LC9oA3G"
      },
      "source": [
        "Predecir usando la `biblioteca de tareas de TFLite`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAQDHFs5tTxZ"
      },
      "outputs": [],
      "source": [
        "for idx in range(20):\n",
        "  sentence = sentence_data['sentence'].iloc[idx]\n",
        "  label = sentence_data['label'].iloc[idx]\n",
        "  text_classification_result = classifier.classify(sentence)\n",
        "  classification_list = text_classification_result.classifications[0].categories\n",
        "\n",
        "  # Sort output by probability descending.\n",
        "  predict_label = sorted(\n",
        "      classification_list, key=lambda item: item.score, reverse=True)[0]\n",
        "\n",
        "  print('truth_label: {} -----> predict_label: {}'.format(label, predict_label.category_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_B8fMDOhMR"
      },
      "source": [
        "## Seleccionar una arquitectura de modelo para el clasificador de texto\n",
        "\n",
        "Cada objeto `model_spec` representa un modelo específico para el clasificador de texto. Model Maker de TensorFlow Lite admite actualmente los modelos [MobileBERT](https://arxiv.org/pdf/2004.02984.pdf), la incorporación promedio de palabras y [BERT-Base](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "Modelos compatibles | Nombre de model_spec | Descripción del modelo | Tamaño del modelo\n",
        "--- | --- | --- | ---\n",
        "Incorporación promedio de palabras | 'average_word_vec' | Promediar las incorporaciones de palabras de texto con activación RELU. | &lt;1 MB\n",
        "MobileBERT | 'mobilebert_classifier' | 4,3 veces más pequeño y 5.5 veces más rápido que el BERT-Base al tiempo que consigue resultados competitivos, adecuado para aplicaciones en dispositivos. | 25 MB con cuantización <br> 100 MB sin cuantización\n",
        "BERT-Base | 'bert_classifier' | Proceso estándar BERT que se usa ampliamente en tareas de PNL. | 300 MB\n",
        "\n",
        "En el inicio rápido, hemos usado el modelo de incorporación promedio de palabras. Cambiemos a [MobileBERT](https://arxiv.org/pdf/2004.02984.pdf) para entrenar un modelo con mayor precisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEAWuZQ1PFiX"
      },
      "outputs": [],
      "source": [
        "mb_spec = model_spec.get('mobilebert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "## Cargar datos de entrenamiento\n",
        "\n",
        "Puede subir su propio conjunto de datos para trabajar con este tutorial. Suba su conjunto de datos usando la barra lateral izquierda en Colab.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_text_classification.png\" width=\"800\" hspace=\"100\" alt=\"Subir archivo\">\n",
        "\n",
        "Si prefiere no subir su conjunto de datos a la nube, también puede ejecutar localmente la biblioteca siguiendo la [guía](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWAusqz-WD5i"
      },
      "source": [
        "Para no complicarnos, reutilizaremos el conjunto de datos SST-2 descargado anteriormente. Usemos el método `DataLoader.from_csv` para cargar los datos.\n",
        "\n",
        "Tenga en cuenta que, como hemos cambiado la arquitectura del modelo, tendremos que volver a cargar el conjunto de datos de entrenamiento y de prueba para aplicar la nueva lógica de preprocesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlHvVvv2hw4H"
      },
      "source": [
        "La biblioteca Model Maker también admite el método `from_folder()` para cargar datos. Asume que los datos de texto de la misma clase se encuentran en el mismo subdirectorio y que el nombre de la subcarpeta es el nombre de la clase. Cada archivo de texto contiene una muestra de revisión de la película. El parámetro `class_labels` se usa para especificar cuáles son las subcarpetas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "## Entrenar un modelo TensorFlow\n",
        "\n",
        "Entrene un modelo de clasificación de texto usando los datos de entrenamiento.\n",
        "\n",
        "*Nota: Como MobileBERT es un modelo complejo, cada época de entrenamiento tardará unos 10 minutos en una GPU Colab. Asegúrese de usar un runtime de GPU.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(train_data, model_spec=mb_spec, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKI-pNc8idH"
      },
      "source": [
        "Examine la estructura detallada del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7Hs8TF8n3H"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "## Evaluar el modelo\n",
        "\n",
        "Evalúe el modelo que acabamos de entrenar usando los datos de prueba y mida el valor de pérdida y precisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBGwHE2QxE8"
      },
      "source": [
        "## Exportar como modelo TensorFlow Lite\n",
        "\n",
        "Convierta el modelo entrenado al formato de modelo TensorFlow Lite con [metadatos](https://www.tensorflow.org/lite/models/convert/metadata) para poder usarlo posteriormente en una aplicación ML en el dispositivo. El archivo de etiquetas y el archivo de vocabulario están incrustados en los metadatos. El nombre de archivo TFLite predeterminado es `model.tflite`.\n",
        "\n",
        "En muchas aplicaciones de ML en el dispositivo, el tamaño del modelo es un factor importante. Por lo tanto, se recomienda aplicar la cuantización del modelo para hacerlo más pequeño y, potencialmente, ejecutarlo más rápido. La técnica de cuantización predeterminada tras el entrenamiento es la cuantización de rango dinámico para los modelos BERT y MobileBERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w12kvDdHJIGH"
      },
      "source": [
        "El archivo modelo de TensorFlow Lite puede integrarse en una app móvil usando la [API del BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) en la [Biblioteca de tareas de TensorFlow Lite](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview). Tenga en cuenta que ésta es **diferente** de la API `NLClassifier` utilizada para integrar la clasificación de texto entrenada con la arquitectura del modelo de vectores de palabras promedio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVy0ormoMZwL"
      },
      "source": [
        "Los formatos de exportación pueden ser uno o una lista de los siguientes:\n",
        "\n",
        "- `ExportFormat.TFLITE`\n",
        "- `ExportFormat.LABEL`\n",
        "- `ExportFormat.VOCAB`\n",
        "- `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "De forma predeterminada, sólo exporta el archivo del modelo TensorFlow Lite que contiene los metadatos del modelo. También puede seleccionar exportar otros archivos relacionados con el modelo para examinarlo mejor.Por ejemplo, exportando sólo el archivo de etiquetas y el archivo de vocabulario de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbK7nzK_Mfx4"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='mobilebert/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZKYthlVrTos"
      },
      "source": [
        "Puede evaluar el modelo TFLite con el método `evaluate_tflite` para medir su precisión. Si convierte el modelo TensorFlow entrenado al formato TFLite y aplica la cuantización puede afectar su precisión, por lo que se recomienda evaluar la precisión del modelo TFLite antes de implementarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochbq95ZrVFX"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate_tflite('mobilebert/model.tflite', test_data)\n",
        "print('TFLite model accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoWiA_zX8rxE"
      },
      "source": [
        "## Uso avanzado\n",
        "\n",
        "La función `create` es la función de controlador que usa la biblioteca Model Maker para crear modelos. El parámetro `model_spec` define la especificación del modelo. Actualmente se admiten las clases `AverageWordVecSpec` y `BertClassifierSpec`. La función `create` consta de los siguientes pasos:\n",
        "\n",
        "1. Crea el modelo para el clasificador de texto según `model_spec`.\n",
        "2. Entrena el modelo clasificador. Las épocas predeterminadas y el tamaño predeterminado del lote se configuran mediante las variables `default_training_epochs` y `default_batch_size` del objeto `model_spec`.\n",
        "\n",
        "Esta sección cubre temas de uso avanzado como el ajuste del modelo y los hiperparámetros de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VxPiOLy4Gv"
      },
      "source": [
        "### Personalizar los hiperparámetros del modelo MobileBERT\n",
        "\n",
        "Los parámetros del modelo que puede ajustar son:\n",
        "\n",
        "- `seq_len`: Longitud de la secuencia a introducir en el modelo.\n",
        "- `initializer_range`: La desviación estándar del `truncated_normal_initializer` para inicializar todas las matrices de ponderación.``\n",
        "- `trainable`: Booleano que especifica si la capa preentrenada es entrenable.\n",
        "\n",
        "Los parámetros del canal de entrenamiento que puede ajustar son:\n",
        "\n",
        "- `model_dir`: La ubicación de los archivos de puntos de verificación del modelo. Si no está contigurada, se usará un directorio temporal.\n",
        "- `dropout_rate`: La tasa de abandono.\n",
        "- `learning_rate`: La tasa de aprendizaje inicial para el optimizador Adam.\n",
        "- `tpu`: Dirección TPU a la que conectarse.\n",
        "\n",
        "Por ejemplo, puede ajustar el `seq_len=256` (de forma predeterminada es 128). Esto permite al modelo clasificar textos más largos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tr9BLcjy4Sh"
      },
      "outputs": [],
      "source": [
        "new_model_spec = model_spec.get('mobilebert_classifier')\n",
        "new_model_spec.seq_len = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwtiksguDfhl"
      },
      "source": [
        "### Personalizar los hiperparámetros del modelo de incorporación de palabras Promedio\n",
        "\n",
        "Puede ajustar la infraestructura del modelo como las variables `wordvec_dim` y `seq_len` de la clase `AverageWordVecSpec`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAOd5_bzH9AQ"
      },
      "source": [
        "Por ejemplo, puede entrenar el modelo con un valor mayor de `wordvec_dim`. Tenga en cuenta que debe construir un nuevo `model_spec` si modifica el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9WBN0UTQoMN"
      },
      "outputs": [],
      "source": [
        "new_model_spec = AverageWordVecSpec(wordvec_dim=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSTdghTP0Cv"
      },
      "source": [
        "Obtenga los datos preprocesados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVZurFBORG3J"
      },
      "outputs": [],
      "source": [
        "new_train_data = DataLoader.from_csv(\n",
        "      filename='train.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD7QVVHeRZoM"
      },
      "source": [
        "Entrene el nuevo modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzpV246_JGEu"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvQuy7RSDir3"
      },
      "source": [
        "### Afinar los hiperparámetros de entrenamiento\n",
        "\n",
        "También puede ajustar los hiperparámetros de entrenamiento como `epochs` y `batch_size` para influir en el rendimiento del modelo. Por ejemplo:\n",
        "\n",
        "- `epochs`: Un mayor número de épocas podría lograr una mayor precisión, pero podría provocar un ajuste excesivo.\n",
        "- `batch_size`: el número de muestras a usar en un paso de entrenamiento.\n",
        "\n",
        "Por ejemplo, puede entrenarse con más épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnWFaYZBG6NW"
      },
      "outputs": [],
      "source": [
        "model = text_classifier.create(new_train_data, model_spec=new_model_spec, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUaKQZBQHBQR"
      },
      "source": [
        "Evalúe el modelo recién reentrenado con 20 épocas de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMPi1xflHDSY"
      },
      "outputs": [],
      "source": [
        "new_test_data = DataLoader.from_csv(\n",
        "      filename='dev.csv',\n",
        "      text_column='sentence',\n",
        "      label_column='label',\n",
        "      model_spec=new_model_spec,\n",
        "      is_training=False)\n",
        "\n",
        "loss, accuracy = model.evaluate(new_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq6B9lKMfhS6"
      },
      "source": [
        "### Cambiar la arquitectura del modelo\n",
        "\n",
        "Puede cambiar el modelo modificando el `model_spec`. A continuación se muestra cómo cambiar al modelo BERT-Base.\n",
        "\n",
        "Cambie el `model_spec` al modelo BERT-Base para el clasificador de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfFCWrwyggrT"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('bert_classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2d7yycrgu6L"
      },
      "source": [
        "Los pasos restantes son los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgiD_tkyQn7l"
      },
      "source": [
        "### Personalizar la cuantización posterior al entrenamiento en el modelo TensorFlow Lite\n",
        "\n",
        "[La cuantización posterior al entrenamiento](https://www.tensorflow.org/lite/performance/post_training_quantization) es una técnica de conversión que puede reducir el tamaño del modelo y la latencia de la inferencia, al tiempo que mejora la velocidad de inferencia de la CPU y del acelerador de hardware, con una pequeña degradación de la precisión del modelo. Por ello, se usa mucho para optimizar el modelo.\n",
        "\n",
        "La biblioteca Model Maker aplica una técnica predeterminada de cuantización postentrenamiento al exportar el modelo. Si desea personalizar la cuantización postentrenamiento, Model Maker también soporta múltiples opciones de cuantización postentrenamiento utilizando [QuantizationConfig](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig). Tomemos como ejemplo la cuantización float16. En primer lugar, defina la configuración de cuantificación.\n",
        "\n",
        "```python\n",
        "config = QuantizationConfig.for_float16()\n",
        "```\n",
        "\n",
        "A continuación, exportamos el modelo TensorFlow Lite con dicha configuración.\n",
        "\n",
        "```python\n",
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJGvMEx6VD-"
      },
      "source": [
        "# Más información\n",
        "\n",
        "Puede leer nuestro ejemplo de [clasificación de texto](https://www.tensorflow.org/lite/examples/text_classification/overview) para conocer los detalles técnicos. Para más información, consulte:\n",
        "\n",
        "- [Guía](https://www.tensorflow.org/lite/models/modify/model_maker) y [Referencia de API](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker) de Model Maker de TensorFlow Lite.\n",
        "- Biblioteca de tareas: [NLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/nl_classifier) y [BertNLClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifier) para su implementación.\n",
        "- Las apps de referencia de principio a fin: [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/android) y [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/ios)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
