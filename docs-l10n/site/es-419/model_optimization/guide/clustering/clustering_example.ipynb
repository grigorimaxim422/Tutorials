{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7hbib3bSGO9"
      },
      "source": [
        "**Copyright 2020 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# Ejemplo de agrupación de pesos en Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW3os956SGPD"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/clustering/clustering_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/model_optimization/guide/clustering/clustering_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/model_optimization/guide/clustering/clustering_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver código fuente en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/model_optimization/guide/clustering/clustering_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Le damos la bienvenida al ejemplo de principio a fin de *agrupación de pesos*, que forma parte del kit de herramientas de optimización de modelos de TensorFlow.\n",
        "\n",
        "### Otras paginas\n",
        "\n",
        "Para obtener una introducción a qué es la agrupación de pesos y determinar si debe usarla (incluido lo que se admite), consulte la [página de descripción general](https://www.tensorflow.org/model_optimization/guide/clustering).\n",
        "\n",
        "Para encontrar rápidamente las API que necesita para su caso de uso (más allá de agrupar completamente un modelo con 16 clústeres), consulte la [guía completa](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_comprehensive_guide).\n",
        "\n",
        "### Contenido\n",
        "\n",
        "En este tutorial podrá:\n",
        "\n",
        "1. Entrenar un modelo `tf.keras` para el conjunto de datos MNIST desde cero.\n",
        "2. Ajustar el modelo aplicando la API de agrupación de pesos y ver la precisión.\n",
        "3. Crear modelos de TF y TFLite 6 veces más pequeños a partir de la agrupación.\n",
        "4. Crear un modelo TFLite 8 veces más pequeño combinando la agrupación de pesos y la cuantización posentrenamiento.\n",
        "5. Ver la persistencia de la precisión desde TF a TFLite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Puede ejecutar este cuaderno Jupyter en su [virtualenv](https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) o [colab](https://colab.sandbox.google.com/) local. Para obtener detalles sobre la configuración de dependencias, consulte la [guía de instalación](https://www.tensorflow.org/model_optimization/guide/install). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## Entrenar un modelo tf.keras para MNIST sin agrupación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### Evaluar el modelo previsto y guardarlo para usarlo después"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## Ajustar el modelo preentrenado con agrupación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "Aplique la API `cluster_weights()` a todo un modelo preentrenado para demostrar su eficacia a la hora de reducir el tamaño del modelo después de aplicar la compresión y conservar una precisión aceptable. Para saber cuál es la mejor manera de equilibrar la precisión y la tasa de compresión para su caso de uso, consulte el ejemplo por capa en la [guía completa](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_comprehensive_guide).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea40z522SGPT"
      },
      "source": [
        "### Definir el modelo y aplicar la API de agrupación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aOB5vjOZMTS"
      },
      "source": [
        "Antes de pasar el modelo a la API de agrupación, asegúrese de que esté entrenado y muestre una precisión aceptable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzqKKt0mSGPT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 16,\n",
        "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
        "}\n",
        "\n",
        "# Cluster a whole model\n",
        "clustered_model = cluster_weights(model, **clustering_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning clustered model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "clustered_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "clustered_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev4MyClmSGPW"
      },
      "source": [
        "### Ajustar el modelo y evaluar la precisión con respecto a la línea de base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQoy9CcASGPX"
      },
      "source": [
        "Ajuste el modelo con agrupación durante 1 época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn29-coXSGPX"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "clustered_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  batch_size=500,\n",
        "  epochs=1,\n",
        "  validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvaZKoxtTORx"
      },
      "source": [
        "Para este ejemplo, hay una pérdida mínima en la precisión de la prueba después de la agrupación, en comparación con la línea de base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE7MxpWLTaQ1"
      },
      "outputs": [],
      "source": [
        "_, clustered_model_accuracy = clustered_model.evaluate(\n",
        "  test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Clustered test accuracy:', clustered_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXfPMa6ISGPd"
      },
      "source": [
        "## Crear modelos **6 veces** más pequeños a partir de agrupaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zr_QIhcUeuC"
      },
      "source": [
        "Tanto `strip_clustering` como la aplicación de un algoritmo de compresión estándar (por ejemplo, mediante gzip) son necesarios para ver los beneficios de la compresión de la agrupación.\n",
        "\n",
        "Primero, cree un modelo comprimible para TensorFlow. Aquí, `strip_clustering` elimina todas las variables (por ejemplo `tf.Variable` para almacenar los centroides y los índices de clúster) que la agrupación solo necesita durante el entrenamiento, que de otro modo aumentarían el tamaño del modelo durante la inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h6tSvMzSGPd"
      },
      "outputs": [],
      "source": [
        "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
        "\n",
        "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving clustered model to: ', clustered_keras_file)\n",
        "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
        "                           include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZcotzPSVBtu"
      },
      "source": [
        "Luego, cree modelos comprimibles para TFLite. Puede convertir el modelo agrupado a un formato que se pueda ejecutar en su backend de destino. TensorFlow Lite es un ejemplo que se puede usar para implementar en dispositivos móviles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2N47QW6SGPh"
      },
      "outputs": [],
      "source": [
        "clustered_tflite_file = '/tmp/clustered_mnist.tflite'\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "tflite_clustered_model = converter.convert()\n",
        "with open(clustered_tflite_file, 'wb') as f:\n",
        "  f.write(tflite_clustered_model)\n",
        "print('Saved clustered TFLite model to:', clustered_tflite_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7amG_9XV-w9"
      },
      "source": [
        "Defina una función ayudante para comprimir los modelos mediante gzip y medir el tamaño comprimido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XJ4QBMpW5JB"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INeAOWRBSGPj"
      },
      "source": [
        "Compare y vea que los modelos son **6 veces** más pequeños a aprtir de la agrupación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG1MgZCeSGPk"
      },
      "outputs": [],
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
        "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TOgpEGfSGPn"
      },
      "source": [
        "## Crear un modelo TFLite **8 veces** más pequeño combinando la agrupación de pesos y la cuantización posentrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQb50aC3SGPn"
      },
      "source": [
        "Puede aplicar la cuantización posentrenamiento al modelo agrupado para obtener beneficios adicionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyHC8euLSGPo"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
        "  f.write(tflite_quant_model)\n",
        "\n",
        "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-yBcocGSGPv"
      },
      "source": [
        "## Ver la persistencia de la precisión desde TF a TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh_pcf0XSGPv"
      },
      "source": [
        "Defina una función ayudante para evaluar el modelo de TFLite en el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ9B7pRISGPw"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0swuxbPmSGPy"
      },
      "source": [
        "Evalúe el modelo, que ha sido agrupado y cuantizado, y luego vea que la precisión de TensorFlow persiste en el backend de TFLite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFD4LXjpSGPz"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Clustered and quantized TFLite test_accuracy:', test_accuracy)\n",
        "print('Clustered TF test accuracy:', clustered_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgXTEXC7SGP1"
      },
      "source": [
        "## Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "En este tutorial, vio cómo crear modelos agrupados con la API del kit de herramientas de optimización de modelos de TensorFlow. Más específicamente, ha analizado un ejemplo de principio a fin para crear un modelo 8 veces más pequeño para MNIST con una diferencia de precisión mínima. Le recomendamos que pruebe esta nueva capacidad, que puede ser particularmente importante para la implementación en entornos con recursos limitados.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "clustering_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
