{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlE_jisTkXY4"
      },
      "source": [
        "**Copyright 2021 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J63wSeDoZZwd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/combine/pcqat_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/model_optimization/guide/combine/pcqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/model_optimization/guide/combine/pcqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/model_optimization/guide/combine/pcqat_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# Ejemplo de Keras de entrenamiento con reconocimiento de la cuantización que preserva la dispersión y los grupos (PCQAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Este es un ejemplo de principio a fin que muestra el uso de la API de **entrenamiento con reconocimiento de la cuantización que preserva la dispersión y los grupos (PCQAT)**, parte del proceso de optimización colaborativa del kit de herramientas de optimización de modelos de TensorFlow.\n",
        "\n",
        "### Otras paginas\n",
        "\n",
        "Para ver una introducción a la canalización y otras técnicas disponibles, consulte la [página de descripción general de optimización colaborativa](https://www.tensorflow.org/model_optimization/guide/combine/collaborative_optimization).\n",
        "\n",
        "### Contenido\n",
        "\n",
        "En este tutorial podrá:\n",
        "\n",
        "1. Entrenar un modelo `tf.keras` para el conjunto de datos MNIST desde cero.\n",
        "2. Ajustar el modelo con poda, ver la precisión y observar que el modelo se poda con éxito.\n",
        "3. Aplicar la dispersión que preserva la agrupación en el modelo podado y observar que la dispersión aplicada anteriormente se ha conservado.\n",
        "4. Aplicar el QAT y observar la pérdida de dispersión y grupos.\n",
        "5. Aplicar el PCQAT y observar que tanto la dispersión como la agrupación aplicada anteriormente se han conservado.\n",
        "6. Generar un modelo de TFLite y observar los efectos de la aplicación de PCQAT.\n",
        "7. Comparar los tamaños de los diferentes modelos para observar los beneficios de la compresión al aplicar la dispersión seguida de las técnicas de optimización colaborativa de la agrupación que preserva la dispersión y el PCQAT.\n",
        "8. Comparar la precisión del modelo totalmente optimizado con la precisión del modelo de referencia no optimizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Puede ejecutar este cuaderno Jupyter en su [virtualenv](https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) o [colab](https://colab.sandbox.google.com/) local. Para obtener detalles sobre la configuración de dependencias, consulte la [guía de instalación](https://www.tensorflow.org/model_optimization/guide/install)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## Entrenar un modelo tf.keras para que MNIST pueda podarse y agruparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### Evaluar el modelo previsto y guardarlo para usarlo después"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPoCr4OFkXZE"
      },
      "source": [
        "## Podar y ajustar el modelo hasta un 50 % de dispersión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mucwWWikXZE"
      },
      "source": [
        "Aplique la API `prune_low_magnitude()` para obtenere el modelo podado que se agrupará en el siguiente paso. Consulte la [guía completa de poda](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide) para obtener más información sobre la API de poda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfTFitgkXZF"
      },
      "source": [
        "### Definir el modelo y aplicar la API de dispersión\n",
        "\n",
        "Tenga en cuenta que se usa el modelo preentrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsN5tP-kXZF"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh6SzEP9kXZF"
      },
      "source": [
        "### Ajustar el modelo, verificar la dispersión y evaluar la precisión con respecto a la línea de base.\n",
        "\n",
        "Ajuste el modelo con poda durante 3 épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aBxR8uEkXZG"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALLq2ZlkXZG"
      },
      "source": [
        "Defina funciones ayudantes para calcular e imprimir la dispersión y los grupos del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL-zWoU4kXZG"
      },
      "outputs": [],
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )\n",
        "\n",
        "def print_model_weight_clusters(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            # ignore auxiliary quantization weights\n",
        "            if \"quantize_layer\" in weight.name:\n",
        "                continue\n",
        "            if \"kernel\" in weight.name:\n",
        "                unique_count = len(np.unique(weight))\n",
        "                print(\n",
        "                    f\"{layer.name}/{weight.name}: {unique_count} clusters \"\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZRAJVqWkXZG"
      },
      "source": [
        "Primero quitemos el contenedor de poda y luego verifiquemos que los núcleos del modelo se podaron correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8_p--1NkXZG"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## Aplicar la dispersión que preserva la agrupación y comprobar su efecto en la dispersión del modelo en ambos casos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "A continuación, aplique la dispersión que preserva la agrupación en el modelo podado y observe la cantidad de grupos y que se preserve la dispersión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RetnGeQnkXZH"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
        "    cluster,\n",
        ")\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "cluster_weights = cluster.cluster_weights\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS,\n",
        "  'preserve_sparsity': True\n",
        "}\n",
        "\n",
        "sparsity_clustered_model = cluster_weights(stripped_pruned_model, **clustering_params)\n",
        "\n",
        "sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train sparsity preserving clustering model:')\n",
        "sparsity_clustered_model.fit(train_images, train_labels,epochs=3, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_PNNJoQkXZH"
      },
      "source": [
        "Primero, quite el contenedor de agrupación y luego verifique que se haya podado y agrupado el modelo correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHN3NW8OkXZI"
      },
      "outputs": [],
      "source": [
        "stripped_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
        "\n",
        "print(\"Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(stripped_clustered_model)\n",
        "\n",
        "print(\"\\nModel clusters:\\n\")\n",
        "print_model_weight_clusters(stripped_clustered_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31qLY2udZIUc"
      },
      "source": [
        "## Aplicar el QAT y el PCQAT y verificar el efecto en los grupos y la dispersión del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMO-h8PgZIUc"
      },
      "source": [
        "A continuación, aplique el QAT y el PCQAT en el modelo agrupado y disperso y observe que el PCQAT preserva la dispersión de pesos y los grupos en su modelo. Tenga en cuenta que el modelo eliminado se pasa a la API de QAT y PCQAT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfp-xfHdZIUc"
      },
      "outputs": [],
      "source": [
        "# QAT\n",
        "qat_model = tfmot.quantization.keras.quantize_model(stripped_clustered_model)\n",
        "\n",
        "qat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train qat model:')\n",
        "qat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)\n",
        "\n",
        "# PCQAT\n",
        "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
        "              stripped_clustered_model)\n",
        "pcqat_model = tfmot.quantization.keras.quantize_apply(\n",
        "              quant_aware_annotate_model,\n",
        "              tfmot.experimental.combine.Default8BitClusterPreserveQuantizeScheme(preserve_sparsity=True))\n",
        "\n",
        "pcqat_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print('Train pcqat model:')\n",
        "pcqat_model.fit(train_images, train_labels, batch_size=128, epochs=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kluyg_2ZIUd"
      },
      "outputs": [],
      "source": [
        "print(\"QAT Model clusters:\")\n",
        "print_model_weight_clusters(qat_model)\n",
        "print(\"\\nQAT Model sparsity:\")\n",
        "print_model_weights_sparsity(qat_model)\n",
        "print(\"\\nPCQAT Model clusters:\")\n",
        "print_model_weight_clusters(pcqat_model)\n",
        "print(\"\\nPCQAT Model sparsity:\")\n",
        "print_model_weights_sparsity(pcqat_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Ywb9bRZIUd"
      },
      "source": [
        "## Ver los beneficios de compresión del modelo de PCQAT\n",
        "\n",
        "Defina la función ayudante para obtener el archivo del modelo comprimido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vehNHBYsZIUe"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBwp4GVmZIUe"
      },
      "source": [
        "Observe cómo la aplicación de dispersión, agrupación y PCQAT a un modelo produce importantes beneficios de compresión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbe2jMAyZIUe"
      },
      "outputs": [],
      "source": [
        "# QAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "qat_tflite_model = converter.convert()\n",
        "qat_model_file = 'qat_model.tflite'\n",
        "# Save the model.\n",
        "with open(qat_model_file, 'wb') as f:\n",
        "    f.write(qat_tflite_model)\n",
        "\n",
        "# PCQAT model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pcqat_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "pcqat_tflite_model = converter.convert()\n",
        "pcqat_model_file = 'pcqat_model.tflite'\n",
        "# Save the model.\n",
        "with open(pcqat_model_file, 'wb') as f:\n",
        "    f.write(pcqat_tflite_model)\n",
        "\n",
        "print(\"QAT model size: \", get_gzipped_model_size(qat_model_file), ' KB')\n",
        "print(\"PCQAT model size: \", get_gzipped_model_size(pcqat_model_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WBGBJU3ZIUf"
      },
      "source": [
        "## Ver la persistencia de la precisión desde TF a TFLite\n",
        "\n",
        "Defina una función ayudante para evaluar el modelo de TFLite en el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P-1dmQcZIUf"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "276omav-ZIUf"
      },
      "source": [
        "Evalúe el modelo, que ha sido podado, agrupado y cuantizado, y verá que la precisión de TensorFlow persiste hasta el backend de TFLite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p4RBECpZIUg"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(pcqat_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "pcqat_test_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Pruned, clustered and quantized TFLite test_accuracy:', pcqat_test_accuracy)\n",
        "print('Baseline TF test accuracy:', baseline_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQFbw88ykXZL"
      },
      "source": [
        "## Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "En este tutorial, aprendió cómo crear un modelo, podarlo con la API `prune_low_magnitude()` y aplicar la agrupación que preserva la dispersión con la API `cluster_weights()` para preservar la dispersión mientras se agrupan los pesos.\n",
        "\n",
        "Luego, se aplicó el entrenamiento con reconocimiento de la cuantización para preservar la dispersión y los grupos (PCQAT) para preservar la dispersión del modelo y los grupos al usar el QAT. El modelo de PCQAT final se comparó con el de QAT para mostrar que la dispersión y los grupos se conservan en el primero y se pierden en el segundo.\n",
        "\n",
        "Después, los modelos se convirtieron a TFLite para mostrar los beneficios de compresión del encadenamiento de dispersión, agrupación y técnicas de optimización de modelos de PCQAT y se evaluó el modelo de TFLite para garantizar que la precisión persista en el backend de TFLite.\n",
        "\n",
        "Por último, se comparó la precisión del modelo de PCQAT de TFLite con la precisión del modelo de referencia previo a la optimización para mostrar que las técnicas de optimización colaborativa pudieron lograr los beneficios de la compresión y mantener una precisión similar en comparación con el modelo original."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pcqat_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
