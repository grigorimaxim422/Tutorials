{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlE_jisTkXY4"
      },
      "source": [
        "**Copyright 2021 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mEE8NFIMSGO-"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyiSRgdtSGPC"
      },
      "source": [
        "# Ejemplo de Keras de agrupación que preserva la dispersión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/combine/sparse_clustering_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/model_optimization/guide/combine/sparse_clustering_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/model_optimization/guide/combine/sparse_clustering_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/model_optimization/guide/combine/sparse_clustering_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnJyAaASGPD"
      },
      "source": [
        "## Descripción general\n",
        "\n",
        "Este es un ejemplo de principio a fin que muestra el uso de la API de **agrupación que preserva la dispersión**, parte de la canalizaciónde optimización colaborativa del kit de herramientas de optimización de modelos de TensorFlow.\n",
        "\n",
        "### Otras paginas\n",
        "\n",
        "Para ver una introducción a la canalización y otras técnicas disponibles, consulte la [página de descripción general de optimización colaborativa](https://www.tensorflow.org/model_optimization/guide/combine/collaborative_optimization).\n",
        "\n",
        "### Contenido\n",
        "\n",
        "En este tutorial podrá:\n",
        "\n",
        "1. Entrenar un modelo `tf.keras` para el conjunto de datos MNIST desde cero.\n",
        "2. Ajustar el modelo con dispersión, ver la precisión y observar que el modelo se poda con éxito.\n",
        "3. Aplicar la agrupación de pesos al modelo podado y observar la pérdida de dispersión.\n",
        "4. Aplicar la dispersión que preserva la agrupación en el modelo podado y observar que la dispersión aplicada anteriormente se ha conservado.\n",
        "5. Generar un modelo de TFLite y verificar que se haya conservado la precisión en el modelo agrupado podado.\n",
        "6. Comparar los tamaños de los diferentes modelos para observar los beneficios de la compresión al aplicar la dispersión seguida de las técnicas de optimización colaborativa de la agrupación que preserva la dispersión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgcQznnZSGPE"
      },
      "source": [
        "## Preparación\n",
        "\n",
        "Puede ejecutar este cuaderno Jupyter en su [virtualenv](https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended) o [colab](https://colab.sandbox.google.com/) local. Para obtener detalles sobre la configuración de dependencias, consulte la [guía de instalación](https://www.tensorflow.org/model_optimization/guide/install). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asgXMqnSGPE"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6JiLXkSGPI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKzOfl5FSGPL"
      },
      "source": [
        "## Entrenar un modelo tf.keras para que MNIST pueda podarse y agruparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Fd6jZ7SGPL"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images  = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3),\n",
        "                         activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOQ8MeESGPO"
      },
      "source": [
        "### Evaluar el modelo previsto y guardarlo para usarlo después"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYulekocSGPP"
      },
      "outputs": [],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPoCr4OFkXZE"
      },
      "source": [
        "## Podar y ajustar el modelo hasta un 50 % de dispersión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mucwWWikXZE"
      },
      "source": [
        "Aplique la API `prune_low_magnitude()` para podar todo el modelo preentrenado para obtener el modelo que se agrupará en el siguiente paso. Para saber cuál es la mejor manera de usar la API para lograr la mejor tasa de compresión y al mismo tiempo mantener la precisión prevista, consulte la [guía completa de poda](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfTFitgkXZF"
      },
      "source": [
        "### Definir el modelo y aplicar la API de dispersión\n",
        "\n",
        "Tenga en cuenta que se usa el modelo preentrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsN5tP-kXZF"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "pruned_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh6SzEP9kXZF"
      },
      "source": [
        "### Ajustar el modelo, verificar la dispersión y evaluar la precisión con respecto a la línea de base.\n",
        "\n",
        "Ajuste el modelo con poda durante 3 épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aBxR8uEkXZG"
      },
      "outputs": [],
      "source": [
        "# Fine-tune model\n",
        "pruned_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=3,\n",
        "  validation_split=0.1,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALLq2ZlkXZG"
      },
      "source": [
        "Defina funciones ayudantes para calcular e imprimir la dispersión del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL-zWoU4kXZG"
      },
      "outputs": [],
      "source": [
        "def print_model_weights_sparsity(model):\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
        "            weights = layer.trainable_weights\n",
        "        else:\n",
        "            weights = layer.weights\n",
        "        for weight in weights:\n",
        "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
        "                continue\n",
        "            weight_size = weight.numpy().size\n",
        "            zero_num = np.count_nonzero(weight == 0)\n",
        "            print(\n",
        "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
        "                f\"({zero_num}/{weight_size})\",\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZRAJVqWkXZG"
      },
      "source": [
        "Verifique que se hayan podado los núcleos del modelo correctamente. Primero debemos quitar el contenedor de la poda. También creamos una copia en profundidad del modelo que se usará en el siguiente paso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8_p--1NkXZG"
      },
      "outputs": [],
      "source": [
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "print_model_weights_sparsity(stripped_pruned_model)\n",
        "\n",
        "stripped_pruned_model_copy = tf.keras.models.clone_model(stripped_pruned_model)\n",
        "stripped_pruned_model_copy.set_weights(stripped_pruned_model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPgcnjKSGPR"
      },
      "source": [
        "## Aplicar la agrupación y dispersión que preservan la agrupación y comprobar su efecto en la dispersión del modelo en ambos casos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wKK7w9SGPS"
      },
      "source": [
        "A continuación, aplicamos la agrupación y dispersión que preservan la agrupación en el modelo podado y observamos que el segundo preserva la dispersión en su modelo podado. Tenga en cuenta que eliminamos los contenedores de poda de su modelo podado con `tfmot.sparsity.keras.strip_pruning` antes de aplicar la API de agrupación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RetnGeQnkXZH"
      },
      "outputs": [],
      "source": [
        "# Clustering\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
        "}\n",
        "\n",
        "clustered_model = cluster_weights(stripped_pruned_model, **clustering_params)\n",
        "\n",
        "clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train clustering model:')\n",
        "clustered_model.fit(train_images, train_labels,epochs=3, validation_split=0.1)\n",
        "\n",
        "\n",
        "stripped_pruned_model.save(\"stripped_pruned_model_clustered.h5\")\n",
        "\n",
        "# Sparsity preserving clustering\n",
        "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
        "    cluster,\n",
        ")\n",
        "\n",
        "cluster_weights = cluster.cluster_weights\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 8,\n",
        "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS,\n",
        "  'preserve_sparsity': True\n",
        "}\n",
        "\n",
        "sparsity_clustered_model = cluster_weights(stripped_pruned_model_copy, **clustering_params)\n",
        "\n",
        "sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train sparsity preserving clustering model:')\n",
        "sparsity_clustered_model.fit(train_images, train_labels,epochs=3, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_PNNJoQkXZH"
      },
      "source": [
        "Verifique la dispersión para ambos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHN3NW8OkXZI"
      },
      "outputs": [],
      "source": [
        "print(\"Clustered Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(clustered_model)\n",
        "print(\"\\nSparsity preserved clustered Model sparsity:\\n\")\n",
        "print_model_weights_sparsity(sparsity_clustered_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea40z522SGPT"
      },
      "source": [
        "## Crear modelos 1,6 veces más pequeños a partir de la agrupación\n",
        "\n",
        "Defina la función ayudante para obtener el archivo del modelo comprimido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obozrEwrkXZI"
      },
      "outputs": [],
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # It returns the size of the gzipped model in kilobytes.\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTjq8zjnkXZJ"
      },
      "outputs": [],
      "source": [
        "# Clustered model\n",
        "clustered_model_file = 'clustered_model.h5'\n",
        "\n",
        "# Save the model.\n",
        "clustered_model.save(clustered_model_file)\n",
        "    \n",
        "#Sparsity Preserve Clustered model\n",
        "sparsity_clustered_model_file = 'sparsity_clustered_model.h5'\n",
        "\n",
        "# Save the model.\n",
        "sparsity_clustered_model.save(sparsity_clustered_model_file)\n",
        "    \n",
        "print(\"Clustered Model size: \", get_gzipped_model_size(clustered_model_file), ' KB')\n",
        "print(\"Sparsity preserved clustered Model size: \", get_gzipped_model_size(sparsity_clustered_model_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bNfCJrEkXZJ"
      },
      "source": [
        "## Crear un modelo de TFLite combinando la agrupación de pesos que preserva la dispersión y la cuantización posentrenamiento\n",
        "\n",
        "Elimine los contenedores de agrupación y conviértalos a TFLite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4dI7XSakXZJ"
      },
      "outputs": [],
      "source": [
        "stripped_sparsity_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_sparsity_clustered_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "sparsity_clustered_quant_model = converter.convert()\n",
        "\n",
        "_, pruned_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_and_clustered_tflite_file, 'wb') as f:\n",
        "  f.write(sparsity_clustered_quant_model)\n",
        "\n",
        "print(\"Sparsity preserved clustered Model size: \", get_gzipped_model_size(sparsity_clustered_model_file), ' KB')\n",
        "print(\"Sparsity preserved clustered and quantized TFLite model size:\",\n",
        "       get_gzipped_model_size(pruned_and_clustered_tflite_file), ' KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "konsqRkokXZK"
      },
      "source": [
        "## Ver la persistencia de la precisión desde TF a TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1HTl0x0kXZK"
      },
      "outputs": [],
      "source": [
        "def eval_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Evaluated on {i} results so far.\")\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I1gdnbCkXZK"
      },
      "source": [
        "Al evaluar el modelo, que ha sido podado, agrupado y cuantizado, y nota que la precisión de TensorFlow persiste hasta el backend de TFLite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbumQ_-0kXZL"
      },
      "outputs": [],
      "source": [
        "# Keras model evaluation\n",
        "stripped_sparsity_clustered_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "_, sparsity_clustered_keras_accuracy = stripped_sparsity_clustered_model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "# TFLite model evaluation\n",
        "interpreter = tf.lite.Interpreter(pruned_and_clustered_tflite_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "sparsity_clustered_tflite_accuracy = eval_model(interpreter)\n",
        "\n",
        "print('Pruned, clustered and quantized Keras model accuracy:', sparsity_clustered_keras_accuracy)\n",
        "print('Pruned, clustered and quantized TFLite model accuracy:', sparsity_clustered_tflite_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQFbw88ykXZL"
      },
      "source": [
        "## Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JhbpowqSGP1"
      },
      "source": [
        "En este tutorial, aprendió cómo crear un modelo, podarlo con la API `prune_low_magnitude()` y aplicar la agrupación que preserva la dispersión para preservar la dispersión mientras se agrupan los pesos. El modelo agrupado que preserva la dispersión se comparó con uno agrupado para mostrar que la dispersión se conserva en el primero y se pierde en el segundo. Lugo, el modelo agrupado podado se convirtió a TFLite para mostrar los beneficios de compresión del encadenamiento de las técnicas de optimización del modelo de agrupación que preserva la poda y la dispersión. Finalmente, se evaluó el modelo de TFLite para garantizar que la precisión persista en el backend de TFLite."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sparse_clustering_example.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
