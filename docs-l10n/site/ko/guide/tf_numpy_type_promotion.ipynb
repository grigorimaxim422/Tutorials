{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjN_IJ8mhJ-4"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sY3Ffd83hK3b"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Pw58e6mTHI"
      },
      "source": [
        "# TF-NumPy 형식 승격"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9nPKvxK-_pM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/tf_numpy_type_promotion\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/guide/tf_numpy_type_promotion.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드하기</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uma-W5v__DYh"
      },
      "source": [
        "## 개요\n",
        "\n",
        "TensorFlow의 형식 승격에는 4가지 옵션이 있습니다.\n",
        "\n",
        "- 기본적으로 TensorFlow는 혼합 형식 연산에서 형식을 승격하는 대신 오류를 발생시킵니다.\n",
        "- `tf.numpy.experimental_enable_numpy_behavior()`를 실행하면 [NumPy 형식 승격 규칙](https://www.tensorflow.org/guide/tf_numpy#type_promotion)을 사용하도록 TensorFlow를 전환합니다.\n",
        "- **이 문서**는 TensorFlow 2.15(또는 현재 `tf-nightly`)에서 사용할 수 있는 두 가지 새로운 옵션을 설명합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMvEKDFOsau7"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf_nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6hOFBfPsd3y"
      },
      "source": [
        "**참고**: `experimental_enable_numpy_behavior`는 모든 TensorFlow의 작동을 변경합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob1HNwUmYR5b"
      },
      "source": [
        "## 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR558zjAZQu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "print(\"Using TensorFlow version %s\" % tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tacoy0DU6e"
      },
      "source": [
        "### 새로운 형식 승격 활성화하기\n",
        "\n",
        "TF-Numpy에서 [JAX와 유사한 형식의 승격](https://jax.readthedocs.io/en/latest/type_promotion.html)을 사용하려면 TensorFlow에 대한 NumPy 작동을 활성화할 때 `'all'` 또는 `'safe'`를 dtype 변환 모드로 지정합니다.\n",
        "\n",
        "이 새로운 시스템(`dtype_conversion_mode=\"all\"` 사용)은 연관적이고 교환 가능하며, 최종적으로 어떤 너비의 부동 소수를 사용할지 쉽게 제어할 수 있습니다(더 넓은 부동 소수로 자동 변환되지는 않음). 오버플로우와 정밀도 손실의 위험이 있지만 `dtype_conversion_mode=\"safe\"`을 사용하면 이러한 경우를 명시적으로 처리할 수 있습니다. 이 두 가지 모드는 [다음 섹션](#two_modes)에서 더 자세히 설명됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfCyofpFDQxm"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMXK8-ZWMun"
      },
      "source": [
        "<a name=\"two_modes\">\n",
        "</a>\n",
        "\n",
        "## 두 가지 모드: ALL 모드와 SAFE 모드\n",
        "\n",
        "새로운 형식 승격 시스템에서는 `ALL` 모드와 `SAFE` 모드의 두 가지 모드를 도입합니다. `SAFE` 모드는 정밀도 손실 또는 비트 확대를 초래할 수 있는 '위험한' 승격에 대한 우려를 완화하는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ULvTWj_KnHU"
      },
      "source": [
        "### Dtypes\n",
        "\n",
        "간결하게 표현하기 위해 다음 약어를 사용하겠습니다.\n",
        "\n",
        "- `b`는 `tf.bool`을 의미합니다.\n",
        "- `u8`은 `tf.uint8`을 의미합니다.\n",
        "- `i16`은 `tf.int16`을 의미합니다.\n",
        "- `i32`는 `tf.int32`를 의미합니다.\n",
        "- `bf16`은 `tf.bfloat16`을 의미합니다.\n",
        "- `f32`는 `tf.float32`를 의미합니다.\n",
        "- `f64`는 `tf.float64`를 의미합니다.\n",
        "- `i32*`는 Python `int` 또는 약한 형식의 `i32`를 의미합니다.\n",
        "- `f32*`는 Python `float` 또는 약한 형식의 `f32`를 의미합니다.\n",
        "- `c128*`은 Python `complex` 또는 약한 형식의 `c128`을 의미합니다.\n",
        "\n",
        "별표(*)는 해당 유형이 \"약한\" 형식임을 나타냅니다. 이러한 형식은 시스템에 의해 일시적으로 추론되며 다른 형식으로 대체될 수 있습니다. 이 개념은 [여기](#weak_tensor)에서 더 자세히 설명됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXZxLCkuzzq3"
      },
      "source": [
        "### 정밀도 손실 연산의 예제\n",
        "\n",
        "다음 예제에서 `i32` + `f32`는 `ALL` 모드에서는 허용되지만 `SAFE` 모드에서는 정밀도 손실의 위험 때문에 허용되지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-yeIvstWStL"
      },
      "outputs": [],
      "source": [
        "# i32 + f32 returns a f32 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "a + b  # <tf.Tensor: shape=(), dtype=float32, numpy=15.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNNmZow2WY3G"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int32)\n",
        "b = tf.constant(5.0, dtype = tf.float32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x4Qhff0AKS"
      },
      "source": [
        "### 비트 확대 연산의 예제\n",
        "\n",
        "다음 예제에서 `i8` + `u32`는 `ALL` 모드에서 허용되지만 `SAFE` 모드에서는 입력의 비트 수보다 더 많은 비트를 사용하는 비트 확대 때문에 허용되지 않습니다. 새로운 타입 승격 의미 체계는 필요한 비트 확대만 허용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etbv-WoWzUXf"
      },
      "outputs": [],
      "source": [
        "# i8 + u32 returns an i64 result in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKRdvtvw0Lvt"
      },
      "outputs": [],
      "source": [
        "# This promotion is not allowed in SAFE mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"safe\")\n",
        "a = tf.constant(10, dtype = tf.int8)\n",
        "b = tf.constant(5, dtype = tf.uint32)\n",
        "try:\n",
        "  a + b\n",
        "except TypeError as e:\n",
        "   print(f'{type(e)}: {e}')  # TypeError: explicitly specify the dtype or switch to ALL mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2BwqUzH3C3"
      },
      "source": [
        "## 격자 기반 시스템"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHUnfTPiYVN5"
      },
      "source": [
        "### 형식 승격 격자\n",
        "\n",
        "새 형식 승격 작동은 다음 형식 승격 격자를 통해 결정됩니다.\n",
        "\n",
        "![Type Promotion Lattice](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_lattice.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QykluwRyDDle"
      },
      "source": [
        "보다 구체적으로 말하면, 두 형식 사이에서 이루어지는 승격은 두 노드(노드 자체 포함)의 첫 번째 공통 하위 항목을 찾아야 결정됩니다.\n",
        "\n",
        "예를 들어 위 다이어그램에서 `i8`과 `i32`의 첫 번째 공통 하위 항목은 `i32`입니다. 그 이유는 화살표 방향을 따라가면 두 노드가 `i32`에서 처음으로 교차하기 때문입니다.\n",
        "\n",
        "다른 예제와 마찬가지로 `u64`와 `f16` 사이의 결과 승격 형식은 `f16`입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nthziRHaDAUY"
      },
      "source": [
        "<a name=\"promotion_table\">\n",
        "</a>\n",
        "\n",
        "### 형식 승격 테이블\n",
        "\n",
        "격자를 따라가면 아래와 같은 바이너리 승격 테이블이 생성됩니다.\n",
        "\n",
        "**참고**: `SAFE` 모드에서는 강조 표시된 셀이 허용되지 않습니다. `ALL` 모드는 모든 경우를 허용합니다.\n",
        "\n",
        "![Type Promotion Table](https://tensorflow.org/guide/images/new_type_promotion/type_promotion_table.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPDt5QTkucSC"
      },
      "source": [
        "## 새 형식 승격의 장점\n",
        "\n",
        "우리는 새로운 형식 승격을 위해 JAX와 유사한 격자 기반 시스템을 채택했으며 이 시스템의 장점은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUS_b13nue1p"
      },
      "source": [
        "<a name=\"lattice_system_design\">\n",
        "</a>\n",
        "\n",
        "#### 격자 기반 시스템의 장점\n",
        "\n",
        "먼저, 격자 기반 시스템을 사용하면 세 가지 매우 중요한 속성이 보장됩니다.\n",
        "\n",
        "- 존재(Existence): 모든 형식의 조합에 대해 고유한 결과 승격 형식이 있습니다.\n",
        "- 교환 가능성(Commutativity): `a + b = b + a`\n",
        "- 연관성(Associativity): `a + (b + c) = (a + b) = c`\n",
        "\n",
        "이 세 가지 속성은 일관되고 예측 가능한 형식 승격 의미 체계를 구성하는 데 매우 중요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz88hRR6uhls"
      },
      "source": [
        "#### JAX와 유사한 격자 시스템의 장점\n",
        "\n",
        "JAX와 유사한 격자 시스템의 또 다른 중요한 장점은 서명되지 않은 인트를 제외하고는 필요 이상의 넓은 승격을 피할 수 있다는 것입니다. 즉, 64비트 입력 없이는 64비트 결과를 얻을 수 없습니다. 기존 형식 승격에서 빈번하게 발생했던 불필요한 64비트 값을 피할 수 있기에 이러한 장점은 가속기 작업에 매우 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlylb7ieOVbJ"
      },
      "source": [
        "그러나 이 시스템에도 단점은 있습니다. 부동 소수/정수 혼합 승격으로 인해 정밀도 손실이 발생할 가능성이 매우 높습니다. 예를 들어, 아래 예제에서 `i64` + `f16`을 사용하면 `i64`가 `f16`으로 승격됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abqIkV02OXEF"
      },
      "outputs": [],
      "source": [
        "# The first input is promoted to f16 in ALL mode.\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "tf.constant(1, tf.int64) + tf.constant(3.2, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnh1gZdObfI"
      },
      "source": [
        "이러한 우려를 해소하기 위해 우리는 이렇게 '위험한' 승격을 허용하지 않는 `SAFE` 모드를 도입했습니다.\n",
        "\n",
        "**참고**: 격자 시스템을 구성할 때 고려해야 할 디자인 고려 사항에 대한 자세한 내용은 [JAX용 형식 승격 의미 체계 디자인](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)을 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAc7LFV0S2dP"
      },
      "source": [
        "<a name=\"weak_tensor\">\n",
        "</a>\n",
        "\n",
        "## WeakTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olQ2gsFlS9BH"
      },
      "source": [
        "### 개요\n",
        "\n",
        "*약한 텐서*는 [JAX](https://jax.readthedocs.io/en/latest/type_promotion.html#weakly-typed-values-in-jax)의 개념과 유사한 \"약한 형식\"의 텐서입니다.\n",
        "\n",
        "`WeakTensor`의 dtype은 시스템에 의해 일시적으로 추론되며, 다른 dtype을 따를 수 있습니다. 이 개념은 Python 스칼라 리터럴과 같이 명시적으로 사용자가 지정한 형식이 없는 TF 값과 값 사이의 이진 연산 내에서 원치 않는 형식 승격을 방지하기 위해 새로운 형식 승격에 도입되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYmoFIqZTFtw"
      },
      "source": [
        "예를 들어, 아래 예제에서 `tf.constant(1.2)`에는 특정 dtype이 없으므로 \"약한\" 형식으로 간주됩니다. 따라서 `tf.constant(1.2)`은 `tf.constant(3.1, tf.float16)`의 형식을 따라가며 그 결과로 `f16`을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSBv_mzyTE97"
      },
      "outputs": [],
      "source": [
        "tf.constant(1.2) + tf.constant(3.1, tf.float16)  # <tf.Tensor: shape=(), dtype=float16, numpy=4.3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxuqBIFuTm5Z"
      },
      "source": [
        "### WeakTensor 구성\n",
        "\n",
        "WeakTensor는 dtype을 지정하지 않고 텐서를 생성할 때 생성됩니다. 텐서의 문자열 표현 끝에서 약한 속성을 확인하면 텐서가 \"약한\" 텐서인지 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmunnJ8Tru3"
      },
      "source": [
        "**첫 번째 사례**: 사용자가 특정한 dtype이 없는 입력으로 `tf.constant`을 호출한 경우."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLEtMluNTsI5"
      },
      "outputs": [],
      "source": [
        "tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQX6MBWHTt__"
      },
      "outputs": [],
      "source": [
        "tf.constant([5.0, 10.0, 3])  # <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 5., 10.,  3.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftsKSC5BTweP"
      },
      "outputs": [],
      "source": [
        "# A normal Tensor is created when dtype arg is specified.\n",
        "tf.constant(5, tf.int32)  # <tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqhoRy5iTyag"
      },
      "source": [
        "**두 번째 사례**: 사용자가 특정한 dtype이 없는 입력이 [WeakTensor 지원 API](#weak_tensor_apis)로 전달되는 경우."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuwpgoQJTzE-"
      },
      "outputs": [],
      "source": [
        "tf.math.abs([100.0, 4.0])  # <tf.Tensor: shape=(2,), dtype=float32, numpy=array([100., 4.], dtype=float32), weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTcoR1xvR39k"
      },
      "source": [
        "##새 형식 승격 사용 효과\n",
        "\n",
        "다음은 새 형식 승격을 사용한 결과로 발생하는 변경 사항의 대략적인 목록입니다.\n",
        "\n",
        "- 보다 일관되고 예측 가능한 프로모션 결과.\n",
        "- 비트 확대 위험의 감소.\n",
        "- `tf.Tensor` 수학적 더블 언더 메서드는 새로운 형식 승격을 사용.\n",
        "- `tf.constant`는 `WeakTensor` 반환  가능.\n",
        "- `tf.constant`는 `dtype` 인수와 다른 dtype을 가진 텐서 입력이 전달될 때 암시적 변환을 허용.\n",
        "- `tf.Variable` 인플레이스 연산(`assign`, `assign-add`, `assign-sub`)의 경우 암시적 변환 허용.\n",
        "- `tnp.array(1)` 및 `tnp.array(1.0)`은 32비트 WeakTensor를 반환.\n",
        "- `WeakTensor`가 생성되어 [WeakTensor 지원 단항 및 바이너리 API](#weak_tensor_apis)에 사용됨.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyvonwYcsFX2"
      },
      "source": [
        "### 보다 일관되고 예측 가능한 승격 결과\n",
        "\n",
        "[격자 기반 시스템](#lattice_system_design)을 사용하면 새로운 형식 승격으로 일관성 있고 예측 가능한 형식 승격 결과를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Z1njfb7lRa"
      },
      "source": [
        "#### 기존 형식 승격\n",
        "\n",
        "연산 순서를 변경하면 이전 형식 승격을 사용하는 일관되지 않은 결과가 나타납니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Ca9v4m7z8e"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwhTzJ-a4rTc"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c throws an InvalidArgumentError.\n",
        "try:\n",
        "  tf.add(tf.add(a, b), c)\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  print(f'{type(e)}: {e}')  # InvalidArgumentError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3qDgVYn7ezT"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c returns an i32 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMH1skEs7oI5"
      },
      "source": [
        "#### 새 형식 승격\n",
        "\n",
        "새 형식 승격은 순서에 관계 없이 일관된 결과를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOHyJJ8z8uCN"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = np.array(1, dtype=np.int8)\n",
        "b = tf.constant(1)\n",
        "c = np.array(1, dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUKU70jf7E1l"
      },
      "outputs": [],
      "source": [
        "# (a + b) + c returns a f16 result.\n",
        "tf.add(tf.add(a, b), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOEycjFx7qDn"
      },
      "outputs": [],
      "source": [
        "# (b + a) + c also returns a f16 result.\n",
        "tf.add(tf.add(b, a), c)  # <tf.Tensor: shape=(), dtype=float16, numpy=3.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpGMkm6aJsn6"
      },
      "source": [
        "### 비트 확대 위험의 감소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxV2AL-U9Grg"
      },
      "source": [
        "#### 기존 형식 승격\n",
        "\n",
        "기존 형식 승격은 종종 64비트 결과를 생성했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L1pxyvn9MlP"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"legacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMJVFdWf4XHp"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float64, numpy=54.19921875>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBhUH_wD9Is7"
      },
      "source": [
        "#### 새 형식 승격\n",
        "\n",
        "새 형식 승격은 필요로 하는 최소 비트 수의 결과를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJsj2ZyI9T9Y"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj0N_Plp4X9l"
      },
      "outputs": [],
      "source": [
        "np.array(3.2, np.float16) + tf.constant(1, tf.int8) + tf.constant(50)  # <tf.Tensor: shape=(), dtype=float16, numpy=54.2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKUx7xe-KZ5O"
      },
      "source": [
        "### tf.Tensor 수학적 더블 언더 메서드\n",
        "\n",
        "모든 `tf.Tensor` 수학적 더블 언더 메서드는 새로운 형식 승격을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c3icBUX4wNl"
      },
      "outputs": [],
      "source": [
        "-tf.constant(5)  # <tf.Tensor: shape=(), dtype=int32, numpy=-5, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydJHQjid45s7"
      },
      "outputs": [],
      "source": [
        "tf.constant(5, tf.int16) - tf.constant(1, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbIjIvbKqcU"
      },
      "source": [
        "### tf.Variable 인플레이스 연산\n",
        "\n",
        "`tf.Variable` 인플레이스 연산에서는 암시적 변환이 허용됩니다.\n",
        "\n",
        "**참고**: 변수의 원래 dtype과 다른 dtype을 초래하는 모든 승격은 허용되지 않습니다. 이는 `tf.Variable`이 dtype을 변경할 수 없기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsXhyK1h-i5S"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.Variable(10, tf.int32)\n",
        "a.assign_add(tf.constant(5, tf.int16))  # <tf.Variable shape=() dtype=int32, numpy=15>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiA4H-otLDit"
      },
      "source": [
        "### tf.constant 암시적 변환\n",
        "\n",
        "이전 형식 승격에서 `tf.constant`의 입력 텐서는 dtype 인수와 동일한 dtype을 가져야 했습니다. 그러나 새로운 형식 승격에서는 암시적으로 텐서를 지정된 dtype으로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArrQ9Dj0_OR8"
      },
      "outputs": [],
      "source": [
        "tnp.experimental_enable_numpy_behavior(dtype_conversion_mode=\"all\")\n",
        "a = tf.constant(10, tf.int16)\n",
        "tf.constant(a, tf.float32)  # <tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAcK_-XnLWaP"
      },
      "source": [
        "### TF-NumPy 배열\n",
        "\n",
        "새 형식 승격을 사용하는 Python 입력의 경우 `tnp.array`의 기본값은 `i32*` 및 `f32*`입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1pZnYNh_ahm"
      },
      "outputs": [],
      "source": [
        "tnp.array(1)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoQl2PYP_fMT"
      },
      "outputs": [],
      "source": [
        "tnp.array(1.0)  # <tf.Tensor: shape=(), dtype=int32, numpy=1, weak=True>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK5DpQ3Pz3k5"
      },
      "source": [
        "##입력 형식 추론\n",
        "\n",
        "새 형식 승격에서 다양한 입력 형식이 추론되는 방식입니다.\n",
        "\n",
        "- `tf.Tensor`: `tf.Tensor`에는 dtype 속성이 있으므로 더 이상 추론을 수행하지 않습니다.\n",
        "- NumPy 형식: 여기에는 `np.array(1)`, `np.int16(1)`, `np.float`와 같은 형식이 포함됩니다. NumPy 입력에도 dtype 속성이 있으므로 결과 추론 형식으로 dtype 속성을 사용합니다. NumPy의 기본값은 `i64` 및 `f64`입니다.\n",
        "- Python 스칼라/중첩 형식: 여기에는 `1`, `[1, 2, 3]`, `(1.0, 2.0)`와 같은 형식이 포함됩니다.\n",
        "    - Python `int`는 `i32*`로 추론됩니다.\n",
        "    - Python `float`은 `f32*`로 추론됩니다.\n",
        "    - Python `complex`는 `c128*`로 추론됩니다.\n",
        "- 입력이 위 범주에 속하지 않지만 dtype 속성이 있는 경우 dtype 속성을 결과 추론 형식으로 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_SPfalfSPgg"
      },
      "source": [
        "# 추가 자료\n",
        "\n",
        "새 형식 승격은 JAX-NumPy의 형식 승겨과 매우 유사합니다. 새 형식 승격과 디자인 선택에 대한 자세한 내용을 알고 싶다면 아래 리소스를 확인해 주세요.\n",
        "\n",
        "- [JAX 형식 승격 의미 체계](https://jax.readthedocs.io/en/latest/type_promotion.html)\n",
        "- [JAX용 형식 승격 의미 체계 디자인](https://jax.readthedocs.io/en/latest/jep/9407-type-promotion.html)\n",
        "- [기존 TF-NumPy 승격 의미 체계](https://www.tensorflow.org/guide/tf_numpy#type_promotion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5xBbImT31S"
      },
      "source": [
        "# 참고 자료"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjB0CVhVXBfW"
      },
      "source": [
        "<a name=\"weak_tensor_apis\">\n",
        "</a>\n",
        "\n",
        "## WeakTensor 지원 API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GVbqlN9aBS2"
      },
      "source": [
        "아래는 `WeakTensor`를 지원하는 API 목록입니다.\n",
        "\n",
        "단항 연산의 경우 사용자가 지정한 형식이 없는 입력이 전달되면 `WeakTensor`를 반환함을 의미합니다.\n",
        "\n",
        "바이너리 연산은 [이곳](#promotion_table)의 승격 테이블 를 따릅니다. 두 입력의 승격 결과에 따라 `WeakTensor`를 반환할 수도 있고 반환하지 않을 수도 있습니다.\n",
        "\n",
        "**참고**: 모든 계산 연산(`+`, `-`, `*`, ...)이 지원됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi-G68Z8WN2P"
      },
      "source": [
        "- `tf.bitwise.invert`\n",
        "- `tf.clip_by_value`\n",
        "- `tf.debugging.check_numerics`\n",
        "- `tf.expand_dims`\n",
        "- `tf.identity`\n",
        "- `tf.image.adjust_brightness`\n",
        "- `tf.image.adjust_gamma`\n",
        "- `tf.image.extract_patches`\n",
        "- `tf.image.random_brightness`\n",
        "- `tf.image.stateless_random_brightness`\n",
        "- `tf.linalg.diag`\n",
        "- `tf.linalg.diag_part`\n",
        "- `tf.linalg.matmul`\n",
        "- `tf.linalg.matrix_transpose`\n",
        "- `tf.linalg.tensor_diag_part`\n",
        "- `tf.linalg.trace`\n",
        "- `tf.math.abs`\n",
        "- `tf.math.acos`\n",
        "- `tf.math.acosh`\n",
        "- `tf.math.add`\n",
        "- `tf.math.angle`\n",
        "- `tf.math.asin`\n",
        "- `tf.math.asinh`\n",
        "- `tf.math.atan`\n",
        "- `tf.math.atanh`\n",
        "- `tf.math.ceil`\n",
        "- `tf.math.conj`\n",
        "- `tf.math.cos`\n",
        "- `tf.math.cosh`\n",
        "- `tf.math.digamma`\n",
        "- `tf.math.divide_no_nan`\n",
        "- `tf.math.divide`\n",
        "- `tf.math.erf`\n",
        "- `tf.math.erfc`\n",
        "- `tf.math.erfcinv`\n",
        "- `tf.math.erfinv`\n",
        "- `tf.math.exp`\n",
        "- `tf.math.expm1`\n",
        "- `tf.math.floor`\n",
        "- `tf.math.floordiv`\n",
        "- `tf.math.floormod`\n",
        "- `tf.math.imag`\n",
        "- `tf.math.lgamma`\n",
        "- `tf.math.log1p`\n",
        "- `tf.math.log_sigmoid`\n",
        "- `tf.math.log`\n",
        "- `tf.math.multiply_no_nan`\n",
        "- `tf.math.multiply`\n",
        "- `tf.math.ndtri`\n",
        "- `tf.math.negative`\n",
        "- `tf.math.pow`\n",
        "- `tf.math.real`\n",
        "- `tf.math.real`\n",
        "- `tf.math.reciprocal_no_nan`\n",
        "- `tf.math.reciprocal`\n",
        "- `tf.math.reduce_euclidean_norm`\n",
        "- `tf.math.reduce_logsumexp`\n",
        "- `tf.math.reduce_max`\n",
        "- `tf.math.reduce_mean`\n",
        "- `tf.math.reduce_min`\n",
        "- `tf.math.reduce_prod`\n",
        "- `tf.math.reduce_std`\n",
        "- `tf.math.reduce_sum`\n",
        "- `tf.math.reduce_variance`\n",
        "- `tf.math.rint`\n",
        "- `tf.math.round`\n",
        "- `tf.math.rsqrt`\n",
        "- `tf.math.scalar_mul`\n",
        "- `tf.math.sigmoid`\n",
        "- `tf.math.sign`\n",
        "- `tf.math.sin`\n",
        "- `tf.math.sinh`\n",
        "- `tf.math.softplus`\n",
        "- `tf.math.special.bessel_i0`\n",
        "- `tf.math.special.bessel_i0e`\n",
        "- `tf.math.special.bessel_i1`\n",
        "- `tf.math.special.bessel_i1e`\n",
        "- `tf.math.special.bessel_j0`\n",
        "- `tf.math.special.bessel_j1`\n",
        "- `tf.math.special.bessel_k0`\n",
        "- `tf.math.special.bessel_k0e`\n",
        "- `tf.math.special.bessel_k1`\n",
        "- `tf.math.special.bessel_k1e`\n",
        "- `tf.math.special.bessel_y0`\n",
        "- `tf.math.special.bessel_y1`\n",
        "- `tf.math.special.dawsn`\n",
        "- `tf.math.special.expint`\n",
        "- `tf.math.special.fresnel_cos`\n",
        "- `tf.math.special.fresnel_sin`\n",
        "- `tf.math.special.spence`\n",
        "- `tf.math.sqrt`\n",
        "- `tf.math.square`\n",
        "- `tf.math.subtract`\n",
        "- `tf.math.tan`\n",
        "- `tf.math.tanh`\n",
        "- `tf.nn.depth_to_space`\n",
        "- `tf.nn.elu`\n",
        "- `tf.nn.gelu`\n",
        "- `tf.nn.leaky_relu`\n",
        "- `tf.nn.log_softmax`\n",
        "- `tf.nn.relu6`\n",
        "- `tf.nn.relu`\n",
        "- `tf.nn.selu`\n",
        "- `tf.nn.softsign`\n",
        "- `tf.nn.space_to_depth`\n",
        "- `tf.nn.swish`\n",
        "- `tf.ones_like`\n",
        "- `tf.realdiv`\n",
        "- `tf.reshape`\n",
        "- `tf.squeeze`\n",
        "- `tf.stop_gradient`\n",
        "- `tf.transpose`\n",
        "- `tf.truncatediv`\n",
        "- `tf.truncatemod`\n",
        "- `tf.zeros_like`\n",
        "- `tf.experimental.numpy.abs`\n",
        "- `tf.experimental.numpy.absolute`\n",
        "- `tf.experimental.numpy.amax`\n",
        "- `tf.experimental.numpy.amin`\n",
        "- `tf.experimental.numpy.angle`\n",
        "- `tf.experimental.numpy.arange`\n",
        "- `tf.experimental.numpy.arccos`\n",
        "- `tf.experimental.numpy.arccosh`\n",
        "- `tf.experimental.numpy.arcsin`\n",
        "- `tf.experimental.numpy.arcsinh`\n",
        "- `tf.experimental.numpy.arctan`\n",
        "- `tf.experimental.numpy.arctanh`\n",
        "- `tf.experimental.numpy.around`\n",
        "- `tf.experimental.numpy.array`\n",
        "- `tf.experimental.numpy.asanyarray`\n",
        "- `tf.experimental.numpy.asarray`\n",
        "- `tf.experimental.numpy.ascontiguousarray`\n",
        "- `tf.experimental.numpy.average`\n",
        "- `tf.experimental.numpy.bitwise_not`\n",
        "- `tf.experimental.numpy.cbrt`\n",
        "- `tf.experimental.numpy.ceil`\n",
        "- `tf.experimental.numpy.conj`\n",
        "- `tf.experimental.numpy.conjugate`\n",
        "- `tf.experimental.numpy.copy`\n",
        "- `tf.experimental.numpy.cos`\n",
        "- `tf.experimental.numpy.cosh`\n",
        "- `tf.experimental.numpy.cumprod`\n",
        "- `tf.experimental.numpy.cumsum`\n",
        "- `tf.experimental.numpy.deg2rad`\n",
        "- `tf.experimental.numpy.diag`\n",
        "- `tf.experimental.numpy.diagflat`\n",
        "- `tf.experimental.numpy.diagonal`\n",
        "- `tf.experimental.numpy.diff`\n",
        "- `tf.experimental.numpy.empty_like`\n",
        "- `tf.experimental.numpy.exp2`\n",
        "- `tf.experimental.numpy.exp`\n",
        "- `tf.experimental.numpy.expand_dims`\n",
        "- `tf.experimental.numpy.expm1`\n",
        "- `tf.experimental.numpy.fabs`\n",
        "- `tf.experimental.numpy.fix`\n",
        "- `tf.experimental.numpy.flatten`\n",
        "- `tf.experimental.numpy.flip`\n",
        "- `tf.experimental.numpy.fliplr`\n",
        "- `tf.experimental.numpy.flipud`\n",
        "- `tf.experimental.numpy.floor`\n",
        "- `tf.experimental.numpy.full_like`\n",
        "- `tf.experimental.numpy.imag`\n",
        "- `tf.experimental.numpy.log10`\n",
        "- `tf.experimental.numpy.log1p`\n",
        "- `tf.experimental.numpy.log2`\n",
        "- `tf.experimental.numpy.log`\n",
        "- `tf.experimental.numpy.max`\n",
        "- `tf.experimental.numpy.mean`\n",
        "- `tf.experimental.numpy.min`\n",
        "- `tf.experimental.numpy.moveaxis`\n",
        "- `tf.experimental.numpy.nanmean`\n",
        "- `tf.experimental.numpy.negative`\n",
        "- `tf.experimental.numpy.ones_like`\n",
        "- `tf.experimental.numpy.positive`\n",
        "- `tf.experimental.numpy.prod`\n",
        "- `tf.experimental.numpy.rad2deg`\n",
        "- `tf.experimental.numpy.ravel`\n",
        "- `tf.experimental.numpy.real`\n",
        "- `tf.experimental.numpy.reciprocal`\n",
        "- `tf.experimental.numpy.repeat`\n",
        "- `tf.experimental.numpy.reshape`\n",
        "- `tf.experimental.numpy.rot90`\n",
        "- `tf.experimental.numpy.round`\n",
        "- `tf.experimental.numpy.signbit`\n",
        "- `tf.experimental.numpy.sin`\n",
        "- `tf.experimental.numpy.sinc`\n",
        "- `tf.experimental.numpy.sinh`\n",
        "- `tf.experimental.numpy.sort`\n",
        "- `tf.experimental.numpy.sqrt`\n",
        "- `tf.experimental.numpy.square`\n",
        "- `tf.experimental.numpy.squeeze`\n",
        "- `tf.experimental.numpy.std`\n",
        "- `tf.experimental.numpy.sum`\n",
        "- `tf.experimental.numpy.swapaxes`\n",
        "- `tf.experimental.numpy.tan`\n",
        "- `tf.experimental.numpy.tanh`\n",
        "- `tf.experimental.numpy.trace`\n",
        "- `tf.experimental.numpy.transpose`\n",
        "- `tf.experimental.numpy.triu`\n",
        "- `tf.experimental.numpy.vander`\n",
        "- `tf.experimental.numpy.var`\n",
        "- `tf.experimental.numpy.zeros_like`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tf_numpy_type_promotion.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
