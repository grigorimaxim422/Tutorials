{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::relu(Tensor input) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::relu_(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sigmoid(Tensor input) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sigmoid_(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::tanh(Tensor input) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::tanh_(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::hardtanh(Tensor self, Scalar min_val, Scalar max_val) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::hardtanh_(Tensor self, Scalar min_val, Scalar max_val) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::prelu(Tensor self, Tensor weight) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::leaky_relu(Tensor self, Scalar negative_slope) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::leaky_relu_(Tensor self, Scalar negative_slope) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::elu(Tensor self, Scalar alpha, Scalar scale, Scalar input_scale) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::batch_norm(Tensor input, Tensor? gamma, Tensor? beta, Tensor? mean, Tensor? var, bool training, float momentum, float eps, bool cudnn_enabled) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::instance_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool use_input_stats, float momentum, float eps, bool cudnn_enabled) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::bitwise_not(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::to(Tensor self, int dtype, bool non_blocking, bool copy, int? memory_format) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::to(Tensor self, Device device, int dtype, bool non_blocking, bool copy, int? memory_format) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::to(Tensor self, Tensor other, bool non_blocking, bool copy, int? memory_format) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::to(Tensor self, Device? device, int? dtype, bool non_blocking, bool copy) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::chunk(Tensor self, int chunks, int dim) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::cat(Tensor[] tensors, int dim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for trt::const(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::constant_pad_nd(Tensor self, int[] pad, Scalar value) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::cumsum(Tensor self, int dim, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::einsum(str equation, Tensor[] tensors, *, int[]? path) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::add(Tensor self, Tensor other, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::add_(Tensor self, Tensor other, *, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::add(Tensor self, Scalar other, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::clamp(Tensor self, Scalar? min, Scalar? max) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::clamp_min(Tensor self, Scalar min) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::clamp_max(Tensor self, Scalar max) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sub(Tensor self, Tensor other, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sub(Tensor self, Scalar other, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sub_(Tensor self, Tensor other, *, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::rsub(Tensor self, Scalar other, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::rsub(Tensor self, Tensor other, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::div(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::div(Tensor self, Tensor other, *, str? rounding_mode) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::div(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::div_(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::div_(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::square(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::mul(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::mul(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::mul_(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::ne(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::ne(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::pow(Tensor self, Tensor exponent) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::pow(Tensor self, Scalar exponent) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::floor_divide(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::floor_divide(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::max(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::min(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::gt(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::gt(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::lt(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::lt(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::eq(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::eq(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::ge(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::ge(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::le(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::le(Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::logical_and(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::atan2(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::expand(Tensor self, int[] size, *, bool implicit) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::expand_as(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::repeat(Tensor self, int[] repeats) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::repeat_interleave(Tensor self, int repeats, int? dim, *, int? output_size) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::meshgrid(Tensor[] tensors) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for trt::attn_bias_from_attn_mask(Tensor attn_mask) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_nearest1d(Tensor self, int[] output_size, float? scales) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_nearest1d(Tensor input, int[]? output_size, float[]? scale_factors) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_nearest2d(Tensor self, int[] output_size, float? scales_h, float? scales_w) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_nearest2d(Tensor input, int[]? output_size, float[]? scale_factors) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_nearest3d(Tensor self, int[] output_size, float? scales_d, float? scales_h, float? scales_w) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_nearest3d(Tensor input, int[]? output_size, float[]? scale_factors) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_linear1d(Tensor self, int[] output_size, bool align_corners, float? scales) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_linear1d(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_bilinear2d(Tensor self, int[] output_size, bool align_corners, float? scales_h, float? scales_w) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_bilinear2d(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_trilinear3d(Tensor self, int[] output_size, bool align_corners, float? scales_d, float? scales_h, float? scales_w) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::upsample_trilinear3d(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::grid_sampler(Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::layer_norm(Tensor input, int[] normalized_shape, Tensor? gamma, Tensor? beta, float eps, bool cudnn_enabled) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::linear(Tensor input, Tensor weight, Tensor? bias) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::gru_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor? b_ih, Tensor? b_hh) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::lstm_cell(Tensor input, Tensor[] hx, Tensor w_ih, Tensor w_hh, Tensor? b_ih, Tensor? b_hh) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::matmul(Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::bmm(Tensor self, Tensor mat2) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta, Scalar alpha) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::max(Tensor self, int dim, bool keepdim) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::min(Tensor self, int dim, bool keepdim) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::argmax(Tensor self, int dim, bool keepdim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::argmin(Tensor self, int dim, bool keepdim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::norm(Tensor self, Scalar? p, int[] dim, bool keepdim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::frobenius_norm(Tensor self, int[] dim, bool keepdim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::linalg_norm(Tensor self, Scalar? ord, int[]? dim, bool keepdim, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::max_pool1d(Tensor self, int[] kernel_size, int[] stride, int[] padding, int[] dilation, bool ceil_mode) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::avg_pool1d(Tensor self, int[] kernel_size, int[] stride, int[] padding, bool ceil_mode, bool count_include_pad) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::max_pool2d(Tensor self, int[] kernel_size, int[] stride, int[] padding, int[] dilation, bool ceil_mode) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::avg_pool2d(Tensor self, int[] kernel_size, int[] stride, int[] padding, bool ceil_mode, bool count_include_pad, int? divisor_override) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::max_pool3d(Tensor self, int[] kernel_size, int[] stride, int[] padding, int[] dilation, bool ceil_mode) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::avg_pool3d(Tensor self, int[] kernel_size, int[] stride, int[] padding, bool ceil_mode, bool count_include_pad, int? divisor_override) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::adaptive_avg_pool1d(Tensor self, int[] output_size) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::adaptive_max_pool1d(Tensor self, int[] output_size) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::adaptive_avg_pool2d(Tensor self, int[] output_size) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::adaptive_max_pool2d(Tensor self, int[] output_size) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::adaptive_avg_pool3d(Tensor self, int[] output_size) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::adaptive_max_pool3d(Tensor self, int[] output_size) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::fake_quantize_per_tensor_affine(Tensor self, float scale, int zero_point, int quant_min, int quant_max) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::fake_quantize_per_tensor_affine(Tensor self, Tensor scale, Tensor zero_point, int quant_min, int quant_max) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::fake_quantize_per_channel_affine(Tensor self, Tensor scale, Tensor zero_point, int axis, int quant_min, int quant_max) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::mean(Tensor self, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::mean(Tensor self, int[] dim, bool keepdim, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sum(Tensor self, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sum(Tensor self, int[] dim, bool keepdim, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::prod(Tensor self, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::prod(Tensor self, int dim, bool keepdim, *, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::max(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::min(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::any(Tensor self, int dim, bool keepdim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::all(Tensor self, int dim, bool keepdim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::reflection_pad2d(Tensor self, int[] padding) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::reflection_pad1d(Tensor self, int[] padding) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::replication_pad1d(Tensor self, int[] padding) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::replication_pad2d(Tensor self, int[] padding) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::replication_pad3d(Tensor self, int[] padding) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::select(Tensor self, int dim, int index) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::index_select(Tensor self, int dim, Tensor index) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::narrow(Tensor self, int dim, int start, int length) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::narrow(Tensor self, int dim, Tensor start, int length) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::embedding(Tensor weight, Tensor indices, int padding_idx, bool scale_grad_by_freq, bool sparse) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::roll(Tensor self, int[] shifts, int[] dims) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::index(Tensor self, Tensor?[] indices) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::slice(Tensor self, int dim, int? start, int? end, int step) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::split(Tensor self, int[] split_sizes, int dim) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::split(Tensor self, int[] split_size, int dim) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::split(Tensor self, int split_size, int dim) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::split_with_sizes(Tensor self, int[] split_sizes, int dim) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::unbind(Tensor self, int dim) -> Tensor[]\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::masked_fill(Tensor self, Tensor mask, Scalar value) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::scatter(Tensor self, int dim, Tensor index, Scalar value) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::scatter(Tensor self, int dim, Tensor index, Tensor src) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::where(Tensor condition, Tensor self, Tensor other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::where(Tensor condition, Tensor self, Scalar other) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::flip(Tensor self, int[] dims) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::flatten(Tensor self, int start_dim, int end_dim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::unflatten(Tensor self, int dim, int[] sizes) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::reshape(Tensor self, int[] shape) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::view(Tensor self, int[] size) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::permute(Tensor self, int[] dims) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::transpose(Tensor self, int dim0, int dim1) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::t(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::pixel_shuffle(Tensor self, int upscale_factor) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::softmax(Tensor self, int dim, int? dtype) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::squeeze(Tensor self, int dim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::squeeze(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::stack(Tensor[] tensors, int dim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::topk(Tensor self, int k, int dim, bool largest, bool sorted) -> (Tensor, Tensor)\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::abs(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::reciprocal(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::log2(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::logical_not(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sqrt(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::isfinite(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::cos(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::acos(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::cosh(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sin(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::asin(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sinh(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::tan(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::atan(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::floor(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::log(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::ceil(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::exp(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::neg(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::erf(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::sign(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::asinh(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::acosh(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::atanh(Tensor self) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering converter for aten::unsqueeze(Tensor self, int dim) -> Tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::eq\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::ne\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::lt\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::gt\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::le\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::ge\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::pow\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__and__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__or__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__xor__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__round_to_zero_floordiv\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::zeros\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::ones\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::new_zeros\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::new_ones\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::zeros_like\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::ones_like\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::fill_\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::full\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::full_like\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::slice\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::len\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::size\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__getitem__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::append\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::extend\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::neg\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::add\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::add_\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::mul\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::sub\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::Bool\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::Float\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::Int\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__not__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__is__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__isnot__\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::numel\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::dim\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::div\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::floordiv\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::floor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::sqrt\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::warn\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::is_floating_point\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::tensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::arange\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::clone\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::copy_\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::format\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__range_length\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::__derive_index\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for aten::list\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::Constant\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::NumToTensor\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::ListUnpack\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::ListConstruct\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::dtype\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::min\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::max\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::shape\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::TupleConstruct\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::TupleIndex\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::TupleUnpack\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::unchecked_cast\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::Uninitialized\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Registering evaluator for prim::RaiseException\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT - Debug Build] - Runtime:\n",
      " Available CUDA Devices: \n",
      "    Device(ID: 0, Name: NVIDIA TITAN V, SM Capability: 7.0, Type: GPU)\n",
      "\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CaskDeconvV2RunnerWeightsTransformerPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CaskDeconvV1RunnerWeightsTransformerPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CaskConvolutionRunnerWeightsTransformerPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CaskFlattenConvolutionRunnerWeightsTransformerPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CaskConvActPoolWeightsTransformerPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CaskDepSepConvWeightsTransformerPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - MyelinWeightsTransformPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - DisentangledAttention_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomEmbLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomEmbLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomEmbLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomFCPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomGeluPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - GroupNormalizationPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomSkipLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomSkipLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomSkipLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomSkipLayerNormPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RnRes2Br1Br2c_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RnRes2Br1Br2c_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RnRes2Br2bBr2c_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RnRes2Br2bBr2c_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RnRes2FullFusion_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - SingleStepLSTMPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomQKVToContextPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomQKVToContextPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CustomQKVToContextPluginDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - DLRM_BOTTOM_MLP_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - SmallTileGEMM_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RNNTEncoderPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Interpolate, Namespace: torch_tensorrt\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - NormalizePlugin, Namespace: torch_tensorrt\n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - BatchedNMSDynamic_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - BatchedNMS_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - BatchTilePlugin_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Clip_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CoordConvAC, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CropAndResizeDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - CropAndResize, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - DecodeBbox3DPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - DetectionLayer_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - EfficientNMS_Explicit_TF_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - EfficientNMS_Implicit_TF_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - EfficientNMS_ONNX_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - EfficientNMS_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - FlattenConcat_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - GenerateDetection_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - GridAnchor_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - GridAnchorRect_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - InstanceNormalization_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - InstanceNormalization_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - LReLU_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ModulatedDeformConv2d, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - MultilevelCropAndResize_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - MultilevelProposeROI_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - MultiscaleDeformableAttnPlugin_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - NMSDynamic_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - NMS_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Normalize_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - PillarScatterPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - PriorBox_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ProposalDynamic, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ProposalLayer_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Proposal, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - PyramidROIAlign_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Region_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Reorg_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Reorg_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ResizeNearest_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ROIAlign_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - RPROI_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ScatterElements, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - ScatterND, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - SpecialSlice_TRT, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - Split, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Registered plugin creator - VoxelGeneratorPlugin, Namespace: \n",
      "\u001b[1;35mDEBUG: \u001b[0m[Torch-TensorRT Plugins Context] - Total number of plugins registered: 76\n",
      "WARNING:torch_tensorrt.dynamo.conversion.aten_ops_converters:Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models\n"
     ]
    }
   ],
   "source": [
    "import torch_tensorrt\n",
    "from torch_tensorrt.dynamo.tools.opset_coverage import ATEN_COVERAGE, PRIMS_COVERAGE, PY_OVERLOAD_COVERAGE, SupportStatus, OpsetCoverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported Ops:\n",
      "aten.nonzero(Tensor self) -> Tensor\n",
      "aten.resize_(Tensor(a!) self, SymInt[] size, \\*, MemoryFormat? memory_format=None) -> Tensor(a!)\n",
      "aten.empty_strided(SymInt[] size, SymInt[] stride, \\*, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor\n",
      "aten.index_put(Tensor self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor\n",
      "aten.max_pool3d_with_indices(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)\n",
      "aten.gather(Tensor self, int dim, Tensor index, \\*, bool sparse_grad=False) -> Tensor\n",
      "aten.max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)\n",
      "aten.sym_stride.int(Tensor self, int dim) -> SymInt\n",
      "aten.scatter_reduce.two(Tensor self, int dim, Tensor index, Tensor src, str reduce, \\*, bool include_self=True) -> Tensor\n",
      "aten.scatter_add(Tensor self, int dim, Tensor index, Tensor src) -> Tensor\n",
      "aten.empty.memory_format(SymInt[] size, \\*, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor\n",
      "aten.native_dropout(Tensor input, float p, bool? train) -> (Tensor, Tensor)\n",
      "aten.sym_storage_offset(Tensor self) -> SymInt\n",
      "aten._local_scalar_dense(Tensor self) -> Scalar\n",
      "\n",
      "Backwards Ops:\n",
      "aten.avg_pool2d_backward(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, bool ceil_mode, bool count_include_pad, int? divisor_override) -> Tensor\n",
      "aten._adaptive_avg_pool2d_backward(Tensor grad_output, Tensor self) -> Tensor\n",
      "aten.convolution_backward(Tensor grad_output, Tensor input, Tensor weight, SymInt[]? bias_sizes, SymInt[] stride, SymInt[] padding, SymInt[] dilation, bool transposed, SymInt[] output_padding, SymInt groups, bool[3] output_mask) -> (Tensor, Tensor, Tensor)\n",
      "aten.max_pool2d_with_indices_backward(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, bool ceil_mode, Tensor indices) -> Tensor\n"
     ]
    }
   ],
   "source": [
    "unsupported_ops = {}\n",
    "backwards_ops = {}\n",
    "\n",
    "for target, info in ATEN_COVERAGE.support_status.items():\n",
    "    if info[\"status\"] == \"FALLBACK\":\n",
    "        if \"backward\" not in target:\n",
    "            unsupported_ops.update({target : info[\"schema\"]})\n",
    "        else:\n",
    "            backwards_ops.update({target : info[\"schema\"]})\n",
    "\n",
    "print(\"Unsupported Ops:\")\n",
    "for _, schema in unsupported_ops.items():\n",
    "    print(schema)\n",
    "\n",
    "print(\"\\nBackwards Ops:\")\n",
    "for _, schema in backwards_ops.items():\n",
    "    print(schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported Ops:\n",
      "prims.(Tensor a, int[] dims) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor a, SymInt[] stride) -> Tensor\n",
      "prims.(Tensor(a!) a, SymInt[] shape) -> Tensor(a!)\n",
      "prims.(Tensor[] tensors, int dim) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor(a) self) -> Tensor(a)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, \\*, int[] dim, bool forward) -> Tensor\n",
      "prims.(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt storage_offset) -> Tensor\n",
      "prims.(Tensor(a) a, ScalarType dtype) -> Tensor(a)\n",
      "prims.(Tensor(a) a, int dim, SymInt outer_length) -> Tensor(a)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor a, Device device) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Scalar s, \\*, ScalarType? dtype=None, Device? device=None) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(SymInt[] shape, \\*, Scalar low, Scalar high, ScalarType dtype, Device device, Generator? generator=None) -> Tensor\n",
      "prims.(Tensor A, \\*, bool full_matrices) -> (Tensor U, Tensor S, Tensor Vh)\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, \\*, int[] dim, SymInt last_dim_size) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor a, ScalarType dtype) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> (Tensor mantissa, Tensor exponent)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, Scalar value) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, \\*, int[] dim, bool onesided) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(ScalarType dtype) -> Scalar\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, \\*, MemoryFormat? memory_format=None) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(SymInt[] shape, int[] physical_layout, \\*, ScalarType dtype, Device device, bool requires_grad) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor(a) a, int start, int end) -> Tensor(a)\n",
      "prims.(Tensor(a) a, int[] dimensions) -> Tensor(a)\n",
      "prims.(ScalarType dtype) -> Scalar\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor(a) a, SymInt[] start_indices, SymInt[] limit_indices, SymInt[]? strides=None) -> Tensor(a)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor(a) a, int[] permutation) -> Tensor(a)\n",
      "prims.(SymInt[] shape, \\*, Scalar mean, Scalar std, ScalarType dtype, Device device, bool requires_grad, Generator? generator=None) -> Tensor\n",
      "prims.(Tensor a, SymInt[] shape) -> Tensor\n",
      "prims.(SymInt length, \\*, SymInt start, SymInt step, ScalarType dtype, Device device, bool requires_grad) -> Tensor\n",
      "prims.(Tensor(a!) a, Tensor b) -> Tensor(a!)\n",
      "prims.() -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor pred, Tensor a, Tensor b) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor inp, int[]? dims, \\*, ScalarType? output_dtype=None) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(SymInt[] shape, SymInt[] strides, \\*, ScalarType dtype, Device device, bool requires_grad) -> Tensor\n",
      "prims.(Tensor a) -> Scalar\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor a, int start, int end) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor(a) a) -> Tensor(a)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor[] tokens) -> ()\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor inp, int[]? dims, \\*, ScalarType? output_dtype=None) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor(a) self) -> Tensor(a)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor inp, int[]? dims, \\*, ScalarType? output_dtype=None) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor(a!) a, SymInt[] size, SymInt[] stride, SymInt storage_offset) -> Tensor(a!)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor inp, int[]? dims, \\*, ScalarType? output_dtype=None) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor(a) a, SymInt start_index, SymInt limit_index, int stride=1, int axis=0) -> Tensor(a)\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor(a) a) -> Tensor(a)\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "prims.(Tensor self, Tensor other) -> Tensor\n",
      "prims.(Tensor self) -> Tensor\n",
      "\n",
      "Backwards Ops:\n"
     ]
    }
   ],
   "source": [
    "unsupported_ops = {}\n",
    "backwards_ops = {}\n",
    "\n",
    "for target, info in PRIMS_COVERAGE.support_status.items():\n",
    "    if info[\"status\"] == \"FALLBACK\":\n",
    "        if \"backward\" not in target:\n",
    "            unsupported_ops.update({target : info[\"schema\"]})\n",
    "        else:\n",
    "            backwards_ops.update({target : info[\"schema\"]})\n",
    "\n",
    "print(\"Unsupported Ops:\")\n",
    "for _, schema in unsupported_ops.items():\n",
    "    print(schema)\n",
    "\n",
    "print(\"\\nBackwards Ops:\")\n",
    "for _, schema in backwards_ops.items():\n",
    "    print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch230cu121py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
